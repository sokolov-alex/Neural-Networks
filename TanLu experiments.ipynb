{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys, os\n",
    "sys.path.insert(0, os.getcwd()+'/../deepx/')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from IPython.display import display, clear_output\n",
    "#%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "from deepx.helper.helper import load_mnist, load_cifar10, load_cifar100, plot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv(os.getcwd()+'/../deepx/examples/results 10 l:3, e:70')\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twiny()\n",
    "ax3 = ax1.twinx()\n",
    "    \n",
    "plot_results(results, plt, ax1, ax2, ax3)\n",
    "plt.show(block = True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/nvcc_compiler.py:224: UserWarning: You have the cuda library directory in your lib_dirs. This has been known to cause problems and should not be done.\n",
      "  warnings.warn(\"You have the cuda library directory in your \"\n",
      "Using gpu device 0: GeForce GTX 860M (CNMeM is enabled with initial size: 80.0% of memory, CuDNN 4004)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting cifar10...\n",
      "\n",
      " Iteration  Time  Loss Tanlu  Loss Optimal  Error Tanlu  Error Optimal  alpha_1  alpha_2  alpha_3\n",
      "         0     2      2.3002        2.2907          0.9          0.894      0.5      0.5      0.5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/alex/anaconda2/lib/python2.7/site-packages/matplotlib/backend_bases.py:2437: MatplotlibDeprecationWarning: Using default event loop until function specific to this GUI is implemented\n",
      "  warnings.warn(str, mplDeprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Iteration   Time  Loss Tanlu  Loss Optimal  Error Tanlu  Error Optimal  alpha_1  alpha_2  alpha_3\n",
      "      1000  123.4      1.1299         1.186        0.411          0.406     0.51     0.36     0.71\n",
      " Iteration   Time  Loss Tanlu  Loss Optimal  Error Tanlu  Error Optimal  alpha_1  alpha_2  alpha_3\n",
      "      2000  245.9      0.6294        0.7055         0.35           0.35     0.58     0.38     0.71"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys, os\n",
    "sys.path.insert(0, os.getcwd()+'/..')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from IPython.display import display, clear_output\n",
    "#%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "from deepx.helper.helper import load_mnist, load_cifar, load_cifar10, plot_results\n",
    "from deepx.nn import *\n",
    "from deepx.loss import *\n",
    "from deepx.optimize import *\n",
    "\n",
    "#np.random.seed(0)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twiny()\n",
    "ax3 = ax1.twinx()\n",
    "\n",
    "def pipeline(Xtrain, ytrain, Xtest, ytest, rms_tanlu, rms_opt, epochs):\n",
    "    def train(n_iter, lr=1):\n",
    "        alphas = [a for a in rms_tanlu.parameters if str(a) == 'alpha']\n",
    "        results = pd.DataFrame(columns = ['Iteration', 'Time', 'Loss Tanlu', 'Loss Optimal', \\\n",
    "            'Error Tanlu', 'Error Optimal'] + ['alpha_'+str(j+1) for j in range(len(alphas))])\n",
    "\n",
    "        def compare_archs(rms):\n",
    "            losses = []\n",
    "            errors = []\n",
    "            def test_alphas(net):\n",
    "                loss_buf = net.train(Xtrain[u:u+minibatch], ytrain[u:u+minibatch], lr)\n",
    "                error_buf = test(net.model, stride = 10)\n",
    "                return loss_buf, error_buf\n",
    "\n",
    "            loss, err = test_alphas(rms)\n",
    "            loss_opt, err_opt = test_alphas(rms_opt)\n",
    "\n",
    "            r = (i, round((time() - t0)/60.0,1))\n",
    "            r += tuple([round(x,4) for x in [loss.max(), loss_opt.max(), err, err_opt]])\n",
    "            r += tuple([round(a.get_value().item(),2) for a in rms.parameters if str(a) == 'alpha'])\n",
    "            results.loc[results.shape[0]] = r\n",
    "            print(results.tail(1).to_string(index=False))\n",
    "            plot_results(results, plt, ax1, ax2, ax3)\n",
    "\n",
    "\n",
    "        t0 = time()\n",
    "        minibatch = 128\n",
    "        freq = 1000\n",
    "\n",
    "        for i in range(n_iter):\n",
    "            u = np.random.choice(np.arange(Xtrain.shape[0]))\n",
    "            rms_tanlu.train(Xtrain[u:u+minibatch], ytrain[u:u+minibatch], lr)\n",
    "            rms_opt.train(Xtrain[u:u+minibatch], ytrain[u:u+minibatch], lr)\n",
    "            if (i) % freq == 0:\n",
    "                compare_archs(rms_tanlu)\n",
    "        fig.savefig(\"../deepx/helper/Results/tanlu vs tanh+relu \"+str(n_iter), dpi=100)\n",
    "        return results\n",
    "\n",
    "    def test(model, stride = 1):\n",
    "        preds = model.predict(Xtest[::stride]).argmax(axis=1)\n",
    "        return 1 - np.mean(preds == ytest[::stride].argmax(axis=1))\n",
    "\n",
    "    n_iter = 1000*epochs\n",
    "    results = train(n_iter)\n",
    "\n",
    "    print(\"Error: \", test(rms_tanlu.model))\n",
    "    print('Test complete.')\n",
    "    plt.show(block = True) # workaround to avoid freezing after closing plot\n",
    "    return results\n",
    "\n",
    "    \n",
    "def run_cifar10(epochs = 20):\n",
    "    print('\\nStarting cifar10...\\n')\n",
    "    Xtrain, ytrain, Xtest, ytest = load_cifar10()\n",
    "    \n",
    "    cifar10_tanlu = Image((3, 32, 32)) >>\\\n",
    "    Conv((3, 32, 32), (64, 4, 4), activation=Tanlu) >> \\\n",
    "    Conv((64, 16, 16), (42, 4, 4), activation=Tanlu) >> \\\n",
    "    Conv((42, 8, 8), (64, 2, 2), activation=Tanlu) >> \\\n",
    "    Flatten() >> \\\n",
    "    Flatten() >> \\\n",
    "    Softmax(10)\n",
    "    alphas_opt = [1, 1, 1]\n",
    "    rms_tanlu = RMSProp(cifar10_tanlu, CrossEntropy())\n",
    "\n",
    "\n",
    "    cifar10_opt = Image((3, 32, 32)) >>\\\n",
    "    Conv((3, 32, 32), (64, 4, 4), activation=Relu) >> \\\n",
    "    Conv((64, 16, 16), (42, 4, 4), activation=Relu) >> \\\n",
    "    Conv((42, 8, 8), (64, 2, 2), activation=Relu) >> \\\n",
    "    Flatten() >> \\\n",
    "    Flatten() >> \\\n",
    "    Softmax(10)\n",
    "    rms_opt = RMSProp(cifar10_opt, CrossEntropy())\n",
    "\n",
    "    return pipeline(Xtrain, ytrain, Xtest, ytest, rms_tanlu, rms_opt, epochs)\n",
    "\n",
    "def run_cifar100(epochs = 20):\n",
    "    print('\\nStarting cifar100...\\n')\n",
    "    Xtrain, ytrain, Xtest, ytest = load_cifar100()\n",
    "    \n",
    "    cifar100_tanlu = Image((3, 32, 32)) >>\\\n",
    "    Conv((3, 32, 32), (64, 4, 4), activation=Tanlu) >> \\\n",
    "    Conv((64, 16, 16), (42, 4, 4), activation=Tanlu) >> \\\n",
    "    Conv((42, 8, 8), (64, 2, 2), activation=Tanlu) >> \\\n",
    "    Flatten() >> \\\n",
    "    Flatten() >> \\\n",
    "    Softmax(100)\n",
    "    alphas_opt = [1, 1, 1]\n",
    "    rms_tanlu = RMSProp(cifar10_tanlu, CrossEntropy())\n",
    "\n",
    "\n",
    "    cifar100_opt = Image((3, 32, 32)) >>\\\n",
    "    Conv((3, 32, 32), (64, 4, 4), activation=Relu) >> \\\n",
    "    Conv((64, 16, 16), (42, 4, 4), activation=Relu) >> \\\n",
    "    Conv((42, 8, 8), (64, 2, 2), activation=Relu) >> \\\n",
    "    Flatten() >> \\\n",
    "    Softmax(100) # Flatten() >> \\\n",
    "    rms_opt = RMSProp(cifar10_opt, CrossEntropy())\n",
    "\n",
    "    return pipeline(Xtrain, ytrain, Xtest, ytest, rms_tanlu, rms_opt, epochs)\n",
    "\n",
    "\n",
    "def run_mnist(epochs = 20):\n",
    "    print('\\nStarting mnist...\\n')\n",
    "    Xtrain, ytrain, Xtest, ytest = load_mnist()\n",
    "    \n",
    "    mnist_tanlu = Image((1, 28, 28)) >> Conv((1, 28, 28), (10, 2, 2), activation=Tanlu) >> \\\n",
    "    Conv((10, 14, 14), (20, 2, 2), activation=Tanlu) >> Flatten() >> Softmax(10)\n",
    "\n",
    "    rms_tanlu = RMSProp(mnist_tanlu, CrossEntropy())\n",
    "\n",
    "    mnist_opt = Image((1, 28, 28)) >> Conv((1, 28, 28), (10, 2, 2), activation=Relu) >> \\\n",
    "    Conv((10, 14, 14), (20, 2, 2), activation=Tanh) >> Flatten() >> Softmax(10)\n",
    "\n",
    "    rms_opt = RMSProp(mnist_opt, CrossEntropy())\n",
    "\n",
    "    return pipeline(Xtrain, ytrain, Xtest, ytest, rms_tanlu, rms_opt, epochs)\n",
    "\n",
    "#results_m = run_mnist(50)\n",
    "results_10 = run_cifar10(70)\n",
    "results_100 = run_cifar100(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
