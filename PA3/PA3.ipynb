{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.getcwd()+'/..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import caffe\n",
    "from DataLoader import load_cifar\n",
    "%matplotlib inline\n",
    "\n",
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(0)\n",
    "\n",
    "load_cifar(datapath = '../Data')\n",
    "print 'ok'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers' features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('data', (128, 3, 32, 32)),\n",
       " ('label_coarse', (128,)),\n",
       " ('label_fine', (128,)),\n",
       " ('label_coarse_data_1_split_0', (128,)),\n",
       " ('label_coarse_data_1_split_1', (128,)),\n",
       " ('label_fine_data_2_split_0', (128,)),\n",
       " ('label_fine_data_2_split_1', (128,)),\n",
       " ('conv1', (128, 64, 29, 29)),\n",
       " ('cccp1a', (128, 42, 29, 29)),\n",
       " ('cccp1b', (128, 32, 29, 29)),\n",
       " ('pool1', (128, 32, 14, 14)),\n",
       " ('conv2', (128, 42, 11, 11)),\n",
       " ('pool2', (128, 42, 5, 5)),\n",
       " ('conv3', (128, 64, 4, 4)),\n",
       " ('pool3', (128, 64, 2, 2)),\n",
       " ('ip1', (128, 768)),\n",
       " ('ip1_sig1_0_split_0', (128, 768)),\n",
       " ('ip1_sig1_0_split_1', (128, 768)),\n",
       " ('ip_c', (128, 20)),\n",
       " ('ip_c_ip_c_0_split_0', (128, 20)),\n",
       " ('ip_c_ip_c_0_split_1', (128, 20)),\n",
       " ('accuracy_c', ()),\n",
       " ('loss_c', ()),\n",
       " ('ip_f', (128, 100)),\n",
       " ('ip_f_ip_f_0_split_0', (128, 100)),\n",
       " ('ip_f_ip_f_0_split_1', (128, 100)),\n",
       " ('accuracy_f', ()),\n",
       " ('loss_f', ())]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import caffe\n",
    "from caffe import layers as L\n",
    "from caffe import params as P\n",
    "\n",
    "\n",
    "def cnn(hdf5, batch_size):\n",
    "    n = caffe.NetSpec()\n",
    "    n.data, n.label_coarse, n.label_fine = L.HDF5Data(batch_size=batch_size, source=hdf5, ntop=3)\n",
    "    \n",
    "    n.conv1 = L.Convolution(n.data, kernel_size=4, num_output=64, weight_filler=dict(type='xavier'))\n",
    "    n.cccp1a = L.Convolution(n.conv1, kernel_size=1, num_output=42, weight_filler=dict(type='xavier'))\n",
    "    n.relu1a = L.ReLU(n.cccp1a, in_place=True)\n",
    "    n.cccp1b = L.Convolution(n.relu1a, kernel_size=1, num_output=32, weight_filler=dict(type='xavier'))\n",
    "    n.pool1 = L.Pooling(n.cccp1b, kernel_size=3, stride=2, pool=P.Pooling.MAX)\n",
    "    n.drop1 = L.Dropout(n.pool1, in_place=True)\n",
    "    n.relu1b = L.ReLU(n.drop1, in_place=True)\n",
    "    \n",
    "    n.conv2 = L.Convolution(n.relu1b, kernel_size=4, num_output=42, weight_filler=dict(type='xavier'))\n",
    "    n.pool2 = L.Pooling(n.conv2, kernel_size=3, stride=2, pool=P.Pooling.MAX)\n",
    "    n.drop2 = L.Dropout(n.pool2, in_place=True)\n",
    "    n.relu2 = L.ReLU(n.drop2, in_place=True)\n",
    "    \n",
    "    n.conv3 = L.Convolution(n.relu2, kernel_size=2, num_output=64, weight_filler=dict(type='xavier'))\n",
    "    n.pool3 = L.Pooling(n.conv3, kernel_size=2, stride=2, pool=P.Pooling.AVE)\n",
    "    n.relu3 = L.ReLU(n.pool3, in_place=True)\n",
    "    \n",
    "    n.ip1 = L.InnerProduct(n.relu3, num_output=768, weight_filler=dict(type='xavier'))\n",
    "    n.sig1 = L.Sigmoid(n.ip1, in_place=True)\n",
    "    \n",
    "    n.ip_c = L.InnerProduct(n.sig1, num_output=20, weight_filler=dict(type='xavier'))\n",
    "    n.accuracy_c = L.Accuracy(n.ip_c, n.label_coarse)\n",
    "    n.loss_c = L.SoftmaxWithLoss(n.ip_c, n.label_coarse)\n",
    "    \n",
    "    n.ip_f = L.InnerProduct(n.sig1, num_output=100, weight_filler=dict(type='xavier'))\n",
    "    n.accuracy_f = L.Accuracy(n.ip_f, n.label_fine)\n",
    "    n.loss_f = L.SoftmaxWithLoss(n.ip_f, n.label_fine)\n",
    "    \n",
    "    return n.to_proto()\n",
    "    \n",
    "\n",
    "def lenet(hdf5, batch_size):\n",
    "    n = caffe.NetSpec()\n",
    "    n.data, n.label_coarse, n.label_fine = L.HDF5Data(batch_size=batch_size, source=hdf5, ntop=3)\n",
    "    \n",
    "    \n",
    "    n.conv1 = L.Convolution(n.data, kernel_size=3, num_output=48, weight_filler=dict(type='xavier'))\n",
    "    n.cccp1a = L.Convolution(n.conv1, kernel_size=1, num_output=42, weight_filler=dict(type='xavier'))\n",
    "    n.relu1a = L.ReLU(n.cccp1a, in_place=True)\n",
    "    n.cccp1b = L.Convolution(n.relu1a, kernel_size=1, num_output=32, weight_filler=dict(type='xavier'))\n",
    "    n.pool1 = L.Pooling(n.relu1a, kernel_size=2, stride=2, pool=P.Pooling.MAX)\n",
    "    n.drop1 = L.Dropout(n.pool1, in_place=True)\n",
    "    #n.relu1b = L.ReLU(n.drop1, in_place=True)\n",
    "    \n",
    "    n.conv2 = L.Convolution(n.drop1, kernel_size=4, num_output=42, weight_filler=dict(type='xavier'))\n",
    "    n.pool2 = L.Pooling(n.conv2, kernel_size=3, stride=2, pool=P.Pooling.MAX)\n",
    "    #n.drop2 = L.Dropout(n.pool2, in_place=True)\n",
    "    n.relu2 = L.ReLU(n.pool2, in_place=True)\n",
    "    \n",
    "    n.conv3 = L.Convolution(n.relu2, kernel_size=2, num_output=64, weight_filler=dict(type='xavier'))\n",
    "    n.pool3 = L.Pooling(n.conv3, kernel_size=2, stride=2, pool=P.Pooling.AVE)\n",
    "    #n.relu3 = L.ReLU(n.pool3, in_place=True)\n",
    "    \n",
    "    n.ip1 = L.InnerProduct(n.pool3, num_output=350, weight_filler=dict(type='xavier'))\n",
    "    n.sig1 = L.Sigmoid(n.ip1, in_place=True)\n",
    "    \n",
    "    #n.ip_c = L.InnerProduct(n.sig1, num_output=20, weight_filler=dict(type='xavier'))\n",
    "    #n.accuracy_c = L.Accuracy(n.ip_c, n.label_coarse)\n",
    "    #n.loss_c = L.SoftmaxWithLoss(n.ip_c, n.label_coarse)\n",
    "    \n",
    "    n.ip_f = L.InnerProduct(n.sig1, num_output=100, weight_filler=dict(type='xavier'))\n",
    "    n.accuracy_f = L.Accuracy(n.ip_f, n.label_fine)\n",
    "    n.loss_f = L.SoftmaxWithLoss(n.ip_f, n.label_fine)\n",
    "    \n",
    "    \n",
    "    return n.to_proto()\n",
    "\n",
    "\n",
    "\n",
    "import h5py\n",
    "def balance_data(dataset = '../Data/cifar-100/train.h5', num_per_class = 100):\n",
    "    h5 = h5py.File(dataset, 'r')\n",
    "    data = h5['data'][:]\n",
    "    labels = h5['label_fine'][:]\n",
    "    coarse = h5['label_coarse'][:]\n",
    "    sorted_labels = np.sort(labels)\n",
    "    indices = np.argsort(labels)\n",
    "    old_class = sorted_labels[0]\n",
    "    counter=0\n",
    "    idx=0\n",
    "    new_data = np.zeros([100*num_per_class, 3, 32, 32], np.float64)\n",
    "    new_labels = np.zeros(100*num_per_class, np.float64)\n",
    "    new_coarse = np.zeros(100*num_per_class, np.float64)\n",
    "    for i in range (1, np.size(labels)):\n",
    "        current_class = sorted_labels[i]\n",
    "        if (counter < num_per_class):\n",
    "            new_data[idx,:, :, :] = data[indices[i], :, :, :]\n",
    "            new_labels[idx] = labels[indices[i]]\n",
    "            new_coarse[idx] = coarse[indices[i]]\n",
    "            counter = counter + 1\n",
    "            idx += 1\n",
    "        if current_class != old_class:\n",
    "            counter = 0\n",
    "        old_class = current_class\n",
    "    new_path = dataset+str(num_per_class)\n",
    "    print new_path\n",
    "    with h5py.File(new_path, 'w') as hf:\n",
    "        hf.create_dataset('data', data=new_data)\n",
    "        hf.create_dataset('label_fine', data=new_labels)\n",
    "        hf.create_dataset('label_coarse', data=new_coarse)\n",
    "\n",
    "def feed_data(num_per_class):\n",
    "    with open('cnn_train.prototxt', 'w') as f:\n",
    "        f.write(str(cnn('train{}.txt'.format(num_per_class), 128)))\n",
    "    \n",
    "    with open('cnn_test.prototxt', 'w') as f:\n",
    "        f.write(str(cnn('test{}.txt'.format(num_per_class), 128)))\n",
    "        \n",
    "#balance_data(dataset = '../Data/cifar-100/train.h5', num_per_class = 100)\n",
    "#balance_data(dataset = '../Data/cifar-100/test.h5', num_per_class = 100)\n",
    "\n",
    "#balance_data(dataset = '../Data/cifar-100/train.h5', num_per_class = 300)\n",
    "#balance_data(dataset = '../Data/cifar-100/test.h5', num_per_class = 300)\n",
    "\n",
    "\n",
    "    \n",
    "with open('cnn_train.prototxt', 'w') as f:\n",
    "    f.write(str(cnn('train.txt', 128)))\n",
    "    \n",
    "with open('cnn_test.prototxt', 'w') as f:\n",
    "    f.write(str(cnn('test.txt', 128)))\n",
    "\n",
    "solver = caffe.get_solver('cnn_solver_rms.prototxt')\n",
    "\n",
    "print(\"Layers' features:\")\n",
    "[(k, v.data.shape) for k, v in solver.net.blobs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters and shape:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('conv1', (64, 3, 4, 4)),\n",
       " ('cccp1a', (42, 64, 1, 1)),\n",
       " ('cccp1b', (32, 42, 1, 1)),\n",
       " ('conv2', (42, 32, 4, 4)),\n",
       " ('conv3', (64, 42, 2, 2)),\n",
       " ('ip1', (768, 256)),\n",
       " ('ip_c', (20, 768)),\n",
       " ('ip_f', (100, 768))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Parameters and shape:\")\n",
    "[(k, v[0].data.shape) for k, v in solver.net.params.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_net: \"cnn_train.prototxt\"\r\n",
      "test_net: \"cnn_test.prototxt\"\r\n",
      "\r\n",
      "test_iter: 0\r\n",
      "test_interval: 21000\r\n",
      "\r\n",
      "base_lr: 0.0006\r\n",
      "momentum: 0.0\r\n",
      "weight_decay: 0.001\r\n",
      "\r\n",
      "lr_policy: \"inv\"\r\n",
      "gamma: 0.0001\r\n",
      "power: 0.75\r\n",
      "\r\n",
      "display: 0\r\n",
      "\r\n",
      "max_iter: 20000\r\n",
      "\r\n",
      "snapshot: 10000\r\n",
      "snapshot_prefix: \"snapshots/cnn_snapshot\"\r\n",
      "solver_mode: GPU\r\n",
      "\r\n",
      "type: \"RMSProp\"\r\n",
      "rms_decay: 0.98\r\n"
     ]
    }
   ],
   "source": [
    "!cat cnn_solver_rms.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "def change_solver(optimizer='RMSProp', max_iter = 100, momentum = 0, solution_id = ''):\n",
    "    global solver\n",
    "    call(\n",
    "'''echo \"train_net: 'cnn_train.prototxt'\n",
    "test_net: 'cnn_test.prototxt'\n",
    "\n",
    "test_iter: 0\n",
    "test_interval: {1}0\n",
    "\n",
    "base_lr: 0.0006\n",
    "momentum: {3}\n",
    "weight_decay: 0.001\n",
    "\n",
    "lr_policy: 'inv'\n",
    "gamma: 0.0001\n",
    "power: 0.75\n",
    "\n",
    "display: 0\n",
    "\n",
    "max_iter: {1}\n",
    "\n",
    "snapshot: {2}\n",
    "snapshot_prefix: 'snapshots/cnn_snapshot{4}'\n",
    "solver_mode: GPU\n",
    "\n",
    "type: '{0}'\n",
    "rms_decay: 0.98\" > new_solver.prototxt'''.format(optimizer, max_iter, max_iter-1, momentum, solution_id),\n",
    "            shell=True\n",
    "        )\n",
    "    solver = caffe.get_solver('new_solver.prototxt')\n",
    "#base_lr: 0.01\n",
    "#momentum: 0.9\n",
    "#weight_decay: 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#!$CAFFE_ROOT/build/tools/caffe train -solver cnn_solver_rms.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#!$CAFFE_ROOT/build/tools/caffe test -model cnn_test.prototxt -weights cnn_snapshot_iter_10000.caffemodel -iterations 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import mpl_toolkits.axisartist as AA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_accuracy_loss(train_loss, test_loss, test_acc, solution_id, test_interval):  \n",
    "    host = host_subplot(111, axes_class=AA.Axes)\n",
    "    plt.subplots_adjust(right=0.75)\n",
    "\n",
    "    par2 = host.twinx()\n",
    "\n",
    "    offset = 0\n",
    "    new_fixed_axis = par2.get_grid_helper().new_fixed_axis\n",
    "    par2.axis[\"right\"] = new_fixed_axis(loc=\"right\",\n",
    "                                        axes=par2)\n",
    "\n",
    "    par2.axis[\"right\"].toggle(all=True)\n",
    "    \n",
    "    host.set_xlabel(\"Iterations\")\n",
    "    host.set_ylabel(\"Test accuracy\")\n",
    "    par2.set_ylabel(\"Loss\")\n",
    "    xs = np.array(range(len(test_acc)))*test_interval\n",
    "    p1, = host.plot(xs, test_acc, label=\"Test accuracy\")\n",
    "    p2, = par2.plot(xs, train_loss, label=\"Train loss\")\n",
    "    p3, = par2.plot(xs, test_loss, label=\"Test loss\")\n",
    "    \n",
    "    host.set_ylim(0,1)\n",
    "    #par1.set_ylim(0, 4)\n",
    "    #par2.set_ylim(1, 65)\n",
    "    host.legend()\n",
    "\n",
    "    host.axis[\"left\"].label.set_color(p1.get_color())\n",
    "    #par1.axis[\"left\"].label.set_color(p2.get_color())\n",
    "    #par2.axis[\"right\"].label.set_color(p2.get_color())\n",
    "    \n",
    "    fig1 = plt.gcf()\n",
    "    plt.show()\n",
    "    plt.draw()\n",
    "    fig1.savefig(\"figures/{}\".format(solution_id), dpi=100)\n",
    "\n",
    "\n",
    "def run_solver(niter, solution_id):\n",
    "    test_interval = int(niter/100.0)\n",
    "    output_len = int(np.ceil(niter * 1.0 / test_interval))\n",
    "\n",
    "    train_loss = np.zeros(output_len)\n",
    "    test_loss = np.zeros(output_len)\n",
    "    test_acc = np.zeros(output_len)\n",
    "\n",
    "    for it in range(niter):\n",
    "        solver.step(1)\n",
    "        \n",
    "        if it % test_interval == 0:\n",
    "            st = it // test_interval\n",
    "            train_loss[st] = solver.net.blobs['loss_f'].data\n",
    "            # store the output on the first test batch\n",
    "            # (start the forward pass at conv1 to avoid loading new data)\n",
    "            solver.test_nets[0].forward(start='conv1')\n",
    "\n",
    "            #print 'Iteration', it*test_interval, 'testing...'\n",
    "            correct = 0\n",
    "            for test_it in range(100):\n",
    "                solver.test_nets[0].forward()\n",
    "                correct += sum(solver.test_nets[0].blobs['ip_f'].data.argmax(axis=1)\n",
    "                               == solver.test_nets[0].blobs['label_fine'].data)\n",
    "            test_acc[st] = correct / 1e4\n",
    "            test_loss[st] = solver.test_nets[0].blobs['loss_f'].data\n",
    "    plot_accuracy_loss(train_loss, test_loss, test_acc, solution_id, test_interval)\n",
    "    return train_loss, test_loss, test_acc, solution_id, test_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iter = 1000\n",
    "\n",
    "solution_id = randint(1,100000)\n",
    "change_solver(optimizer='AdaGrad', max_iter = max_iter, solution_id = solution_id)\n",
    "run_solver(max_iter, solution_id)\n",
    "print solution_id, 'done'\n",
    "\n",
    "solution_id = randint(1,100000)\n",
    "change_solver(optimizer='Nesterov', momentum = 0.9, max_iter = max_iter, solution_id = solution_id)\n",
    "run_solver(max_iter, solution_id)\n",
    "print solution_id, 'done'\n",
    "\n",
    "solution_id = randint(1,100000)\n",
    "change_solver(optimizer='SGD', momentum = 0.9, max_iter = max_iter, solution_id = solution_id)\n",
    "run_solver(max_iter, solution_id)\n",
    "print solution_id, 'done'\n",
    "\n",
    "solution_id = randint(1,100000)\n",
    "change_solver(optimizer='RMSProp', max_iter = max_iter, solution_id = solution_id)\n",
    "run_solver(max_iter, solution_id)\n",
    "print solution_id, 'done'\n",
    "\n",
    "solution_id = randint(1,100000)\n",
    "feed_data(100)\n",
    "change_solver(optimizer='RMSProp', max_iter = max_iter, solution_id = solution_id)\n",
    "run_solver(max_iter, solution_id)\n",
    "print solution_id, 'done'\n",
    "\n",
    "solution_id = randint(1,100000)\n",
    "feed_data(300)\n",
    "change_solver(optimizer='RMSProp', max_iter = max_iter, solution_id = solution_id)\n",
    "train_loss, test_loss, test_acc, solution_id, test_interval = run_solver(max_iter, solution_id)\n",
    "print solution_id, 'done'\n",
    "\n",
    "feed_data('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0  0.2900\n",
       "1  0.0000\n",
       "2  0.0100\n",
       "3  0.0000\n",
       "4  0.0104\n",
       "5  0.0000\n",
       "6  0.0000\n",
       "7  0.0101\n",
       "8  0.0000\n",
       "9  0.4884"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
