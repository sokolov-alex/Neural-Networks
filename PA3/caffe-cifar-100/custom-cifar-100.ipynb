{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom cifar-100 conv net with Caffe in Python (Pycaffe)\n",
    "\n",
    "Here, I train a custom convnet on the cifar-100 dataset. I will try to build a new convolutional neural network architecture. It is a bit based on the NIN (Network In Network) architecture detailed in this paper: http://arxiv.org/pdf/1312.4400v3.pdf. \n",
    "\n",
    "I mainly use some convolution layers, cccp layers, pooling layers, dropout, fully connected layers, relu layers, as well ass sigmoid layers and softmax with loss on top of the neural network. \n",
    "\n",
    "My code, other than the neural network architecture, is inspired from the official caffe python \".ipynb\" examples available at: https://github.com/BVLC/caffe/tree/master/examples.\n",
    "\n",
    "Please refer to https://www.cs.toronto.edu/~kriz/cifar.html for more information on the nature of the task and of the dataset on which the convolutional neural network is trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamically download and convert the cifar-100 dataset to Caffe's HDF5 format using code of another git repo of mine.\n",
    "More info on the dataset can be found at http://www.cs.toronto.edu/~kriz/cifar.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘download-and-convert-cifar-100.py’: No such file or directory\n",
      "Getting the download script...\n",
      "--2016-02-09 21:39:40--  https://raw.githubusercontent.com/guillaume-chevalier/caffe-cifar-10-and-cifar-100-datasets-preprocessed-to-HDF5/master/download-and-convert-cifar-100.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.27.79.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.27.79.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3526 (3.4K) [text/plain]\n",
      "Saving to: ‘download-and-convert-cifar-100.py’\n",
      "\n",
      "100%[======================================>] 3,526       --.-K/s   in 0s      \n",
      "\n",
      "2016-02-09 21:39:40 (1.36 GB/s) - ‘download-and-convert-cifar-100.py’ saved [3526/3526]\n",
      "\n",
      "Downloaded script. Will execute to download and convert the cifar-100 dataset:\n",
      "\n",
      "Downloading...\n",
      "--2016-02-09 21:39:41--  http://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
      "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 169001437 (161M) [application/x-gzip]\n",
      "Saving to: ‘cifar-100-python.tar.gz’\n",
      "\n",
      "100%[======================================>] 169,001,437 4.19MB/s   in 71s    \n",
      "\n",
      "2016-02-09 21:40:52 (2.28 MB/s) - ‘cifar-100-python.tar.gz’ saved [169001437/169001437]\n",
      "\n",
      "Downloading done.\n",
      "\n",
      "Extracting...\n",
      "cifar-100-python/\n",
      "cifar-100-python/file.txt~\n",
      "cifar-100-python/train\n",
      "cifar-100-python/test\n",
      "cifar-100-python/meta\n",
      "Extracting successfully done to /home/alex/Desktop/python-caffe-custom-cifar-100-conv-net-master/cifar-100-python.\n",
      "Converting...\n",
      "INFO: each dataset's element are of shape 3*32*32:\n",
      "\"print(X.shape)\" --> \"(50000, 3, 32, 32)\"\n",
      "\n",
      "From the Caffe documentation: \n",
      "The conventional blob dimensions for batches of image data are number N x channel K x height H x width W.\n",
      "\n",
      "Data is fully loaded, now truly converting.\n",
      "Conversion successfully done to \"/home/alex/Desktop/python-caffe-custom-cifar-100-conv-net-master/cifar_100_caffe_hdf5\".\n",
      "\n",
      "CPU times: user 448 ms, sys: 88 ms, total: 536 ms\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!rm download-and-convert-cifar-100.py\n",
    "print(\"Getting the download script...\")\n",
    "!wget https://raw.githubusercontent.com/guillaume-chevalier/caffe-cifar-10-and-cifar-100-datasets-preprocessed-to-HDF5/master/download-and-convert-cifar-100.py\n",
    "print(\"Downloaded script. Will execute to download and convert the cifar-100 dataset:\")\n",
    "!python download-and-convert-cifar-100.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model with Caffe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import caffe\n",
    "from caffe import layers as L\n",
    "from caffe import params as P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cnn(hdf5, batch_size):\n",
    "    n = caffe.NetSpec()\n",
    "    n.data, n.label_coarse, n.label_fine = L.HDF5Data(batch_size=batch_size, source=hdf5, ntop=3)\n",
    "    \n",
    "    n.conv1 = L.Convolution(n.data, kernel_size=4, num_output=64, weight_filler=dict(type='xavier'))\n",
    "    n.cccp1a = L.Convolution(n.conv1, kernel_size=1, num_output=42, weight_filler=dict(type='xavier'))\n",
    "    n.relu1a = L.ReLU(n.cccp1a, in_place=True)\n",
    "    n.cccp1b = L.Convolution(n.relu1a, kernel_size=1, num_output=32, weight_filler=dict(type='xavier'))\n",
    "    n.pool1 = L.Pooling(n.cccp1b, kernel_size=3, stride=2, pool=P.Pooling.MAX)\n",
    "    n.drop1 = L.Dropout(n.pool1, in_place=True)\n",
    "    n.relu1b = L.ReLU(n.drop1, in_place=True)\n",
    "    \n",
    "    n.conv2 = L.Convolution(n.relu1b, kernel_size=4, num_output=42, weight_filler=dict(type='xavier'))\n",
    "    n.pool2 = L.Pooling(n.conv2, kernel_size=3, stride=2, pool=P.Pooling.MAX)\n",
    "    n.drop2 = L.Dropout(n.pool2, in_place=True)\n",
    "    n.relu2 = L.ReLU(n.drop2, in_place=True)\n",
    "    \n",
    "    n.conv3 = L.Convolution(n.relu2, kernel_size=2, num_output=64, weight_filler=dict(type='xavier'))\n",
    "    n.pool3 = L.Pooling(n.conv3, kernel_size=2, stride=2, pool=P.Pooling.AVE)\n",
    "    n.relu3 = L.ReLU(n.pool3, in_place=True)\n",
    "    \n",
    "    n.ip1 = L.InnerProduct(n.relu3, num_output=768, weight_filler=dict(type='xavier'))\n",
    "    n.sig1 = L.Sigmoid(n.ip1, in_place=True)\n",
    "    \n",
    "    n.ip_c = L.InnerProduct(n.sig1, num_output=20, weight_filler=dict(type='xavier'))\n",
    "    n.accuracy_c = L.Accuracy(n.ip_c, n.label_coarse)\n",
    "    n.loss_c = L.SoftmaxWithLoss(n.ip_c, n.label_coarse)\n",
    "    \n",
    "    n.ip_f = L.InnerProduct(n.sig1, num_output=100, weight_filler=dict(type='xavier'))\n",
    "    n.accuracy_f = L.Accuracy(n.ip_f, n.label_fine)\n",
    "    n.loss_f = L.SoftmaxWithLoss(n.ip_f, n.label_fine)\n",
    "    \n",
    "    return n.to_proto()\n",
    "    \n",
    "with open('cnn_train.prototxt', 'w') as f:\n",
    "    f.write(str(cnn('cifar_100_caffe_hdf5/train.txt', 100)))\n",
    "    \n",
    "with open('cnn_test.prototxt', 'w') as f:\n",
    "    f.write(str(cnn('cifar_100_caffe_hdf5/test.txt', 120)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and visualise the untrained network's internal structure and shape\n",
    "The network's structure (graph) visualisation tool of caffe is broken in the current release. We will simply print here the data shapes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_gpu()\n",
    "solver = caffe.get_solver('cnn_solver_rms.prototxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers' features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('data', (100, 3, 32, 32)),\n",
       " ('label_coarse', (100,)),\n",
       " ('label_fine', (100,)),\n",
       " ('label_coarse_data_1_split_0', (100,)),\n",
       " ('label_coarse_data_1_split_1', (100,)),\n",
       " ('label_fine_data_2_split_0', (100,)),\n",
       " ('label_fine_data_2_split_1', (100,)),\n",
       " ('conv1', (100, 64, 29, 29)),\n",
       " ('cccp1a', (100, 42, 29, 29)),\n",
       " ('cccp1b', (100, 32, 29, 29)),\n",
       " ('pool1', (100, 32, 14, 14)),\n",
       " ('conv2', (100, 42, 11, 11)),\n",
       " ('pool2', (100, 42, 5, 5)),\n",
       " ('conv3', (100, 64, 4, 4)),\n",
       " ('pool3', (100, 64, 2, 2)),\n",
       " ('ip1', (100, 768)),\n",
       " ('ip1_sig1_0_split_0', (100, 768)),\n",
       " ('ip1_sig1_0_split_1', (100, 768)),\n",
       " ('ip_c', (100, 20)),\n",
       " ('ip_c_ip_c_0_split_0', (100, 20)),\n",
       " ('ip_c_ip_c_0_split_1', (100, 20)),\n",
       " ('accuracy_c', ()),\n",
       " ('loss_c', ()),\n",
       " ('ip_f', (100, 100)),\n",
       " ('ip_f_ip_f_0_split_0', (100, 100)),\n",
       " ('ip_f_ip_f_0_split_1', (100, 100)),\n",
       " ('accuracy_f', ()),\n",
       " ('loss_f', ())]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Layers' features:\")\n",
    "[(k, v.data.shape) for k, v in solver.net.blobs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters and shape:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('conv1', (64, 3, 4, 4)),\n",
       " ('cccp1a', (42, 64, 1, 1)),\n",
       " ('cccp1b', (32, 42, 1, 1)),\n",
       " ('conv2', (42, 32, 4, 4)),\n",
       " ('conv3', (64, 42, 2, 2)),\n",
       " ('ip1', (768, 256)),\n",
       " ('ip_c', (20, 768)),\n",
       " ('ip_f', (100, 768))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Parameters and shape:\")\n",
    "[(k, v[0].data.shape) for k, v in solver.net.params.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver's params\n",
    "\n",
    "The solver's params for the created net are defined in a `.prototxt` file. \n",
    "\n",
    "Notice that because `max_iter: 100000`, the training will loop 2 times on the 50000 training data. Because we train data by minibatches of 100 as defined above when creating the net, there will be a total of `100000*100/50000 = 200` epochs on some of those pre-shuffled 100 images minibatches.\n",
    "\n",
    "We will test the net on `test_iter: 100` different test images at each `test_interval: 1000` images trained. \n",
    "____\n",
    "\n",
    "Here, **RMSProp** is used, it is SDG-based, it converges faster than a pure SGD and it is robust.\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_net: \"cnn_train.prototxt\"\r\n",
      "test_net: \"cnn_test.prototxt\"\r\n",
      "\r\n",
      "test_iter: 100\r\n",
      "test_interval: 1000\r\n",
      "\r\n",
      "base_lr: 0.0006\r\n",
      "momentum: 0.0\r\n",
      "weight_decay: 0.001\r\n",
      "\r\n",
      "lr_policy: \"inv\"\r\n",
      "gamma: 0.0001\r\n",
      "power: 0.75\r\n",
      "\r\n",
      "display: 100\r\n",
      "\r\n",
      "max_iter: 150000\r\n",
      "\r\n",
      "snapshot: 50000\r\n",
      "snapshot_prefix: \"cnn_snapshot\"\r\n",
      "solver_mode: GPU\r\n",
      "\r\n",
      "type: \"RMSProp\"\r\n",
      "rms_decay: 0.98\r\n"
     ]
    }
   ],
   "source": [
    "!cat cnn_solver_rms.prototxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative way to train directly in Python\n",
    "Since a recent update, there is no output in python by default, which is bad for debugging. \n",
    "Skip this cell and train with the second method shown below if needed. It is commented out in case you just chain some `shift+enter` ipython shortcuts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# solver.solve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train by calling caffe in command line\n",
    "Just set the parameters correctly. Be sure that the notebook is at the root of the ipython notebook server. \n",
    "You can run this in an external terminal if you open it in the notebook's directory. \n",
    "\n",
    "It is also possible to finetune an existing net with a different solver or different data. Here I do it, because I feel the net could better fit the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0209 21:41:29.272148  5681 caffe.cpp:185] Using GPUs 0\n",
      "I0209 21:41:29.286551  5681 caffe.cpp:190] GPU 0: GeForce GTX 860M\n",
      "I0209 21:41:29.440407  5681 solver.cpp:48] Initializing solver from parameters: \n",
      "train_net: \"cnn_train.prototxt\"\n",
      "test_net: \"cnn_test.prototxt\"\n",
      "test_iter: 100\n",
      "test_interval: 1000\n",
      "base_lr: 0.0006\n",
      "display: 100\n",
      "max_iter: 150000\n",
      "lr_policy: \"inv\"\n",
      "gamma: 0.0001\n",
      "power: 0.75\n",
      "momentum: 0\n",
      "weight_decay: 0.001\n",
      "snapshot: 50000\n",
      "snapshot_prefix: \"cnn_snapshot\"\n",
      "solver_mode: GPU\n",
      "device_id: 0\n",
      "rms_decay: 0.98\n",
      "type: \"RMSProp\"\n",
      "I0209 21:41:29.440644  5681 solver.cpp:81] Creating training net from train_net file: cnn_train.prototxt\n",
      "I0209 21:41:29.441289  5681 net.cpp:49] Initializing net from parameters: \n",
      "state {\n",
      "  phase: TRAIN\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"HDF5Data\"\n",
      "  top: \"data\"\n",
      "  top: \"label_coarse\"\n",
      "  top: \"label_fine\"\n",
      "  hdf5_data_param {\n",
      "    source: \"cifar_100_caffe_hdf5/train.txt\"\n",
      "    batch_size: 100\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 64\n",
      "    kernel_size: 4\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"cccp1a\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"cccp1a\"\n",
      "  convolution_param {\n",
      "    num_output: 42\n",
      "    kernel_size: 1\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1a\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"cccp1a\"\n",
      "  top: \"cccp1a\"\n",
      "}\n",
      "layer {\n",
      "  name: \"cccp1b\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"cccp1a\"\n",
      "  top: \"cccp1b\"\n",
      "  convolution_param {\n",
      "    num_output: 32\n",
      "    kernel_size: 1\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"cccp1b\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"drop1\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"pool1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1b\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"pool1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 42\n",
      "    kernel_size: 4\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"drop2\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"pool2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"pool2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 64\n",
      "    kernel_size: 2\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool3\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"pool3\"\n",
      "  pooling_param {\n",
      "    pool: AVE\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"pool3\"\n",
      "  top: \"pool3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"ip1\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool3\"\n",
      "  top: \"ip1\"\n",
      "  inner_product_param {\n",
      "    num_output: 768\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"sig1\"\n",
      "  type: \"Sigmoid\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"ip_c\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip_c\"\n",
      "  inner_product_param {\n",
      "    num_output: 20\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"accuracy_c\"\n",
      "  type: \"Accuracy\"\n",
      "  bottom: \"ip_c\"\n",
      "  bottom: \"label_coarse\"\n",
      "  top: \"accuracy_c\"\n",
      "}\n",
      "layer {\n",
      "  name: \"loss_c\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"ip_c\"\n",
      "  bottom: \"label_coarse\"\n",
      "  top: \"loss_c\"\n",
      "}\n",
      "layer {\n",
      "  name: \"ip_f\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip_f\"\n",
      "  inner_product_param {\n",
      "    num_output: 100\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"accuracy_f\"\n",
      "  type: \"Accuracy\"\n",
      "  bottom: \"ip_f\"\n",
      "  bottom: \"label_fine\"\n",
      "  top: \"accuracy_f\"\n",
      "}\n",
      "layer {\n",
      "  name: \"loss_f\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"ip_f\"\n",
      "  bottom: \"label_fine\"\n",
      "  top: \"loss_f\"\n",
      "}\n",
      "I0209 21:41:29.442219  5681 layer_factory.hpp:77] Creating layer data\n",
      "I0209 21:41:29.442282  5681 net.cpp:106] Creating Layer data\n",
      "I0209 21:41:29.442301  5681 net.cpp:411] data -> data\n",
      "I0209 21:41:29.442378  5681 net.cpp:411] data -> label_coarse\n",
      "I0209 21:41:29.442404  5681 net.cpp:411] data -> label_fine\n",
      "I0209 21:41:29.442437  5681 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: cifar_100_caffe_hdf5/train.txt\n",
      "I0209 21:41:29.442489  5681 hdf5_data_layer.cpp:93] Number of HDF5 files: 1\n",
      "I0209 21:41:29.442512  5681 hdf5_data_layer.cpp:28] Loading HDF5 file: /home/alex/Desktop/python-caffe-custom-cifar-100-conv-net-master/cifar_100_caffe_hdf5/train.h5\n",
      "I0209 21:41:29.454646  5681 hdf5.cpp:35] Datatype class: H5T_INTEGER\n",
      "I0209 21:41:31.335139  5681 hdf5_data_layer.cpp:67] Successully loaded 50000 rows\n",
      "I0209 21:41:31.335253  5681 net.cpp:150] Setting up data\n",
      "I0209 21:41:31.335285  5681 net.cpp:157] Top shape: 100 3 32 32 (307200)\n",
      "I0209 21:41:31.335296  5681 net.cpp:157] Top shape: 100 (100)\n",
      "I0209 21:41:31.335304  5681 net.cpp:157] Top shape: 100 (100)\n",
      "I0209 21:41:31.335310  5681 net.cpp:165] Memory required for data: 1229600\n",
      "I0209 21:41:31.335333  5681 layer_factory.hpp:77] Creating layer label_coarse_data_1_split\n",
      "I0209 21:41:31.335369  5681 net.cpp:106] Creating Layer label_coarse_data_1_split\n",
      "I0209 21:41:31.335397  5681 net.cpp:454] label_coarse_data_1_split <- label_coarse\n",
      "I0209 21:41:31.335444  5681 net.cpp:411] label_coarse_data_1_split -> label_coarse_data_1_split_0\n",
      "I0209 21:41:31.335470  5681 net.cpp:411] label_coarse_data_1_split -> label_coarse_data_1_split_1\n",
      "I0209 21:41:31.335525  5681 net.cpp:150] Setting up label_coarse_data_1_split\n",
      "I0209 21:41:31.335538  5681 net.cpp:157] Top shape: 100 (100)\n",
      "I0209 21:41:31.335547  5681 net.cpp:157] Top shape: 100 (100)\n",
      "I0209 21:41:31.335552  5681 net.cpp:165] Memory required for data: 1230400\n",
      "I0209 21:41:31.335559  5681 layer_factory.hpp:77] Creating layer label_fine_data_2_split\n",
      "I0209 21:41:31.335587  5681 net.cpp:106] Creating Layer label_fine_data_2_split\n",
      "I0209 21:41:31.335595  5681 net.cpp:454] label_fine_data_2_split <- label_fine\n",
      "I0209 21:41:31.335623  5681 net.cpp:411] label_fine_data_2_split -> label_fine_data_2_split_0\n",
      "I0209 21:41:31.335638  5681 net.cpp:411] label_fine_data_2_split -> label_fine_data_2_split_1\n",
      "I0209 21:41:31.335677  5681 net.cpp:150] Setting up label_fine_data_2_split\n",
      "I0209 21:41:31.335688  5681 net.cpp:157] Top shape: 100 (100)\n",
      "I0209 21:41:31.335695  5681 net.cpp:157] Top shape: 100 (100)\n",
      "I0209 21:41:31.335701  5681 net.cpp:165] Memory required for data: 1231200\n",
      "I0209 21:41:31.335707  5681 layer_factory.hpp:77] Creating layer conv1\n",
      "I0209 21:41:31.335744  5681 net.cpp:106] Creating Layer conv1\n",
      "I0209 21:41:31.335763  5681 net.cpp:454] conv1 <- data\n",
      "I0209 21:41:31.335782  5681 net.cpp:411] conv1 -> conv1\n",
      "I0209 21:41:31.466198  5681 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 24984\n",
      "I0209 21:41:31.466253  5681 net.cpp:150] Setting up conv1\n",
      "I0209 21:41:31.466271  5681 net.cpp:157] Top shape: 100 64 29 29 (5382400)\n",
      "I0209 21:41:31.466277  5681 net.cpp:165] Memory required for data: 22760800\n",
      "I0209 21:41:31.466342  5681 layer_factory.hpp:77] Creating layer cccp1a\n",
      "I0209 21:41:31.466389  5681 net.cpp:106] Creating Layer cccp1a\n",
      "I0209 21:41:31.466403  5681 net.cpp:454] cccp1a <- conv1\n",
      "I0209 21:41:31.466424  5681 net.cpp:411] cccp1a -> cccp1a\n",
      "I0209 21:41:31.467514  5681 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 21684\n",
      "I0209 21:41:31.467547  5681 net.cpp:150] Setting up cccp1a\n",
      "I0209 21:41:31.467560  5681 net.cpp:157] Top shape: 100 42 29 29 (3532200)\n",
      "I0209 21:41:31.467566  5681 net.cpp:165] Memory required for data: 36889600\n",
      "I0209 21:41:31.467597  5681 layer_factory.hpp:77] Creating layer relu1a\n",
      "I0209 21:41:31.467618  5681 net.cpp:106] Creating Layer relu1a\n",
      "I0209 21:41:31.467628  5681 net.cpp:454] relu1a <- cccp1a\n",
      "I0209 21:41:31.467645  5681 net.cpp:397] relu1a -> cccp1a (in-place)\n",
      "I0209 21:41:31.467980  5681 net.cpp:150] Setting up relu1a\n",
      "I0209 21:41:31.468005  5681 net.cpp:157] Top shape: 100 42 29 29 (3532200)\n",
      "I0209 21:41:31.468011  5681 net.cpp:165] Memory required for data: 51018400\n",
      "I0209 21:41:31.468019  5681 layer_factory.hpp:77] Creating layer cccp1b\n",
      "I0209 21:41:31.468049  5681 net.cpp:106] Creating Layer cccp1b\n",
      "I0209 21:41:31.468058  5681 net.cpp:454] cccp1b <- cccp1a\n",
      "I0209 21:41:31.468076  5681 net.cpp:411] cccp1b -> cccp1b\n",
      "I0209 21:41:31.469156  5681 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 21684\n",
      "I0209 21:41:31.469205  5681 net.cpp:150] Setting up cccp1b\n",
      "I0209 21:41:31.469228  5681 net.cpp:157] Top shape: 100 32 29 29 (2691200)\n",
      "I0209 21:41:31.469244  5681 net.cpp:165] Memory required for data: 61783200\n",
      "I0209 21:41:31.469275  5681 layer_factory.hpp:77] Creating layer pool1\n",
      "I0209 21:41:31.469298  5681 net.cpp:106] Creating Layer pool1\n",
      "I0209 21:41:31.469307  5681 net.cpp:454] pool1 <- cccp1b\n",
      "I0209 21:41:31.469324  5681 net.cpp:411] pool1 -> pool1\n",
      "I0209 21:41:31.469393  5681 net.cpp:150] Setting up pool1\n",
      "I0209 21:41:31.469415  5681 net.cpp:157] Top shape: 100 32 14 14 (627200)\n",
      "I0209 21:41:31.469421  5681 net.cpp:165] Memory required for data: 64292000\n",
      "I0209 21:41:31.469427  5681 layer_factory.hpp:77] Creating layer drop1\n",
      "I0209 21:41:31.469446  5681 net.cpp:106] Creating Layer drop1\n",
      "I0209 21:41:31.469455  5681 net.cpp:454] drop1 <- pool1\n",
      "I0209 21:41:31.469470  5681 net.cpp:397] drop1 -> pool1 (in-place)\n",
      "I0209 21:41:31.469504  5681 net.cpp:150] Setting up drop1\n",
      "I0209 21:41:31.469514  5681 net.cpp:157] Top shape: 100 32 14 14 (627200)\n",
      "I0209 21:41:31.469519  5681 net.cpp:165] Memory required for data: 66800800\n",
      "I0209 21:41:31.469527  5681 layer_factory.hpp:77] Creating layer relu1b\n",
      "I0209 21:41:31.469547  5681 net.cpp:106] Creating Layer relu1b\n",
      "I0209 21:41:31.469555  5681 net.cpp:454] relu1b <- pool1\n",
      "I0209 21:41:31.469569  5681 net.cpp:397] relu1b -> pool1 (in-place)\n",
      "I0209 21:41:31.469712  5681 net.cpp:150] Setting up relu1b\n",
      "I0209 21:41:31.469733  5681 net.cpp:157] Top shape: 100 32 14 14 (627200)\n",
      "I0209 21:41:31.469739  5681 net.cpp:165] Memory required for data: 69309600\n",
      "I0209 21:41:31.469748  5681 layer_factory.hpp:77] Creating layer conv2\n",
      "I0209 21:41:31.469775  5681 net.cpp:106] Creating Layer conv2\n",
      "I0209 21:41:31.469784  5681 net.cpp:454] conv2 <- pool1\n",
      "I0209 21:41:31.469801  5681 net.cpp:411] conv2 -> conv2\n",
      "I0209 21:41:31.471940  5681 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 9900\n",
      "I0209 21:41:31.472144  5681 net.cpp:150] Setting up conv2\n",
      "I0209 21:41:31.472159  5681 net.cpp:157] Top shape: 100 42 11 11 (508200)\n",
      "I0209 21:41:31.472165  5681 net.cpp:165] Memory required for data: 71342400\n",
      "I0209 21:41:31.472193  5681 layer_factory.hpp:77] Creating layer pool2\n",
      "I0209 21:41:31.472210  5681 net.cpp:106] Creating Layer pool2\n",
      "I0209 21:41:31.472219  5681 net.cpp:454] pool2 <- conv2\n",
      "I0209 21:41:31.472239  5681 net.cpp:411] pool2 -> pool2\n",
      "I0209 21:41:31.472297  5681 net.cpp:150] Setting up pool2\n",
      "I0209 21:41:31.472311  5681 net.cpp:157] Top shape: 100 42 5 5 (105000)\n",
      "I0209 21:41:31.472326  5681 net.cpp:165] Memory required for data: 71762400\n",
      "I0209 21:41:31.472333  5681 layer_factory.hpp:77] Creating layer drop2\n",
      "I0209 21:41:31.472347  5681 net.cpp:106] Creating Layer drop2\n",
      "I0209 21:41:31.472364  5681 net.cpp:454] drop2 <- pool2\n",
      "I0209 21:41:31.472378  5681 net.cpp:397] drop2 -> pool2 (in-place)\n",
      "I0209 21:41:31.472412  5681 net.cpp:150] Setting up drop2\n",
      "I0209 21:41:31.472422  5681 net.cpp:157] Top shape: 100 42 5 5 (105000)\n",
      "I0209 21:41:31.472427  5681 net.cpp:165] Memory required for data: 72182400\n",
      "I0209 21:41:31.472434  5681 layer_factory.hpp:77] Creating layer relu2\n",
      "I0209 21:41:31.472446  5681 net.cpp:106] Creating Layer relu2\n",
      "I0209 21:41:31.472453  5681 net.cpp:454] relu2 <- pool2\n",
      "I0209 21:41:31.472468  5681 net.cpp:397] relu2 -> pool2 (in-place)\n",
      "I0209 21:41:31.472635  5681 net.cpp:150] Setting up relu2\n",
      "I0209 21:41:31.472645  5681 net.cpp:157] Top shape: 100 42 5 5 (105000)\n",
      "I0209 21:41:31.472651  5681 net.cpp:165] Memory required for data: 72602400\n",
      "I0209 21:41:31.472658  5681 layer_factory.hpp:77] Creating layer conv3\n",
      "I0209 21:41:31.472689  5681 net.cpp:106] Creating Layer conv3\n",
      "I0209 21:41:31.472699  5681 net.cpp:454] conv3 <- pool2\n",
      "I0209 21:41:31.472728  5681 net.cpp:411] conv3 -> conv3\n",
      "I0209 21:41:31.474575  5681 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6996\n",
      "I0209 21:41:31.474611  5681 net.cpp:150] Setting up conv3\n",
      "I0209 21:41:31.474632  5681 net.cpp:157] Top shape: 100 64 4 4 (102400)\n",
      "I0209 21:41:31.474638  5681 net.cpp:165] Memory required for data: 73012000\n",
      "I0209 21:41:31.474673  5681 layer_factory.hpp:77] Creating layer pool3\n",
      "I0209 21:41:31.474696  5681 net.cpp:106] Creating Layer pool3\n",
      "I0209 21:41:31.474706  5681 net.cpp:454] pool3 <- conv3\n",
      "I0209 21:41:31.474722  5681 net.cpp:411] pool3 -> pool3\n",
      "I0209 21:41:31.475092  5681 net.cpp:150] Setting up pool3\n",
      "I0209 21:41:31.475118  5681 net.cpp:157] Top shape: 100 64 2 2 (25600)\n",
      "I0209 21:41:31.475124  5681 net.cpp:165] Memory required for data: 73114400\n",
      "I0209 21:41:31.475132  5681 layer_factory.hpp:77] Creating layer relu3\n",
      "I0209 21:41:31.475160  5681 net.cpp:106] Creating Layer relu3\n",
      "I0209 21:41:31.475169  5681 net.cpp:454] relu3 <- pool3\n",
      "I0209 21:41:31.475184  5681 net.cpp:397] relu3 -> pool3 (in-place)\n",
      "I0209 21:41:31.475342  5681 net.cpp:150] Setting up relu3\n",
      "I0209 21:41:31.475353  5681 net.cpp:157] Top shape: 100 64 2 2 (25600)\n",
      "I0209 21:41:31.475359  5681 net.cpp:165] Memory required for data: 73216800\n",
      "I0209 21:41:31.475366  5681 layer_factory.hpp:77] Creating layer ip1\n",
      "I0209 21:41:31.475386  5681 net.cpp:106] Creating Layer ip1\n",
      "I0209 21:41:31.475395  5681 net.cpp:454] ip1 <- pool3\n",
      "I0209 21:41:31.475412  5681 net.cpp:411] ip1 -> ip1\n",
      "I0209 21:41:31.485607  5681 net.cpp:150] Setting up ip1\n",
      "I0209 21:41:31.485635  5681 net.cpp:157] Top shape: 100 768 (76800)\n",
      "I0209 21:41:31.485642  5681 net.cpp:165] Memory required for data: 73524000\n",
      "I0209 21:41:31.485656  5681 layer_factory.hpp:77] Creating layer sig1\n",
      "I0209 21:41:31.485685  5681 net.cpp:106] Creating Layer sig1\n",
      "I0209 21:41:31.485694  5681 net.cpp:454] sig1 <- ip1\n",
      "I0209 21:41:31.485710  5681 net.cpp:397] sig1 -> ip1 (in-place)\n",
      "I0209 21:41:31.486060  5681 net.cpp:150] Setting up sig1\n",
      "I0209 21:41:31.486085  5681 net.cpp:157] Top shape: 100 768 (76800)\n",
      "I0209 21:41:31.486091  5681 net.cpp:165] Memory required for data: 73831200\n",
      "I0209 21:41:31.486099  5681 layer_factory.hpp:77] Creating layer ip1_sig1_0_split\n",
      "I0209 21:41:31.486114  5681 net.cpp:106] Creating Layer ip1_sig1_0_split\n",
      "I0209 21:41:31.486131  5681 net.cpp:454] ip1_sig1_0_split <- ip1\n",
      "I0209 21:41:31.486150  5681 net.cpp:411] ip1_sig1_0_split -> ip1_sig1_0_split_0\n",
      "I0209 21:41:31.486171  5681 net.cpp:411] ip1_sig1_0_split -> ip1_sig1_0_split_1\n",
      "I0209 21:41:31.486222  5681 net.cpp:150] Setting up ip1_sig1_0_split\n",
      "I0209 21:41:31.486234  5681 net.cpp:157] Top shape: 100 768 (76800)\n",
      "I0209 21:41:31.486241  5681 net.cpp:157] Top shape: 100 768 (76800)\n",
      "I0209 21:41:31.486246  5681 net.cpp:165] Memory required for data: 74445600\n",
      "I0209 21:41:31.486253  5681 layer_factory.hpp:77] Creating layer ip_c\n",
      "I0209 21:41:31.486279  5681 net.cpp:106] Creating Layer ip_c\n",
      "I0209 21:41:31.486287  5681 net.cpp:454] ip_c <- ip1_sig1_0_split_0\n",
      "I0209 21:41:31.486316  5681 net.cpp:411] ip_c -> ip_c\n",
      "I0209 21:41:31.487221  5681 net.cpp:150] Setting up ip_c\n",
      "I0209 21:41:31.487244  5681 net.cpp:157] Top shape: 100 20 (2000)\n",
      "I0209 21:41:31.487251  5681 net.cpp:165] Memory required for data: 74453600\n",
      "I0209 21:41:31.487273  5681 layer_factory.hpp:77] Creating layer ip_c_ip_c_0_split\n",
      "I0209 21:41:31.487289  5681 net.cpp:106] Creating Layer ip_c_ip_c_0_split\n",
      "I0209 21:41:31.487298  5681 net.cpp:454] ip_c_ip_c_0_split <- ip_c\n",
      "I0209 21:41:31.487313  5681 net.cpp:411] ip_c_ip_c_0_split -> ip_c_ip_c_0_split_0\n",
      "I0209 21:41:31.487331  5681 net.cpp:411] ip_c_ip_c_0_split -> ip_c_ip_c_0_split_1\n",
      "I0209 21:41:31.487373  5681 net.cpp:150] Setting up ip_c_ip_c_0_split\n",
      "I0209 21:41:31.487385  5681 net.cpp:157] Top shape: 100 20 (2000)\n",
      "I0209 21:41:31.487391  5681 net.cpp:157] Top shape: 100 20 (2000)\n",
      "I0209 21:41:31.487396  5681 net.cpp:165] Memory required for data: 74469600\n",
      "I0209 21:41:31.487403  5681 layer_factory.hpp:77] Creating layer accuracy_c\n",
      "I0209 21:41:31.487429  5681 net.cpp:106] Creating Layer accuracy_c\n",
      "I0209 21:41:31.487438  5681 net.cpp:454] accuracy_c <- ip_c_ip_c_0_split_0\n",
      "I0209 21:41:31.487462  5681 net.cpp:454] accuracy_c <- label_coarse_data_1_split_0\n",
      "I0209 21:41:31.487473  5681 net.cpp:411] accuracy_c -> accuracy_c\n",
      "I0209 21:41:31.487494  5681 net.cpp:150] Setting up accuracy_c\n",
      "I0209 21:41:31.487504  5681 net.cpp:157] Top shape: (1)\n",
      "I0209 21:41:31.487510  5681 net.cpp:165] Memory required for data: 74469604\n",
      "I0209 21:41:31.487529  5681 layer_factory.hpp:77] Creating layer loss_c\n",
      "I0209 21:41:31.487545  5681 net.cpp:106] Creating Layer loss_c\n",
      "I0209 21:41:31.487555  5681 net.cpp:454] loss_c <- ip_c_ip_c_0_split_1\n",
      "I0209 21:41:31.487566  5681 net.cpp:454] loss_c <- label_coarse_data_1_split_1\n",
      "I0209 21:41:31.487581  5681 net.cpp:411] loss_c -> loss_c\n",
      "I0209 21:41:31.487612  5681 layer_factory.hpp:77] Creating layer loss_c\n",
      "I0209 21:41:31.487884  5681 net.cpp:150] Setting up loss_c\n",
      "I0209 21:41:31.487898  5681 net.cpp:157] Top shape: (1)\n",
      "I0209 21:41:31.487903  5681 net.cpp:160]     with loss weight 1\n",
      "I0209 21:41:31.487920  5681 net.cpp:165] Memory required for data: 74469608\n",
      "I0209 21:41:31.487928  5681 layer_factory.hpp:77] Creating layer ip_f\n",
      "I0209 21:41:31.487952  5681 net.cpp:106] Creating Layer ip_f\n",
      "I0209 21:41:31.487962  5681 net.cpp:454] ip_f <- ip1_sig1_0_split_1\n",
      "I0209 21:41:31.487989  5681 net.cpp:411] ip_f -> ip_f\n",
      "I0209 21:41:31.492228  5681 net.cpp:150] Setting up ip_f\n",
      "I0209 21:41:31.492254  5681 net.cpp:157] Top shape: 100 100 (10000)\n",
      "I0209 21:41:31.492260  5681 net.cpp:165] Memory required for data: 74509608\n",
      "I0209 21:41:31.492285  5681 layer_factory.hpp:77] Creating layer ip_f_ip_f_0_split\n",
      "I0209 21:41:31.492300  5681 net.cpp:106] Creating Layer ip_f_ip_f_0_split\n",
      "I0209 21:41:31.492308  5681 net.cpp:454] ip_f_ip_f_0_split <- ip_f\n",
      "I0209 21:41:31.492323  5681 net.cpp:411] ip_f_ip_f_0_split -> ip_f_ip_f_0_split_0\n",
      "I0209 21:41:31.492341  5681 net.cpp:411] ip_f_ip_f_0_split -> ip_f_ip_f_0_split_1\n",
      "I0209 21:41:31.492384  5681 net.cpp:150] Setting up ip_f_ip_f_0_split\n",
      "I0209 21:41:31.492395  5681 net.cpp:157] Top shape: 100 100 (10000)\n",
      "I0209 21:41:31.492403  5681 net.cpp:157] Top shape: 100 100 (10000)\n",
      "I0209 21:41:31.492408  5681 net.cpp:165] Memory required for data: 74589608\n",
      "I0209 21:41:31.492424  5681 layer_factory.hpp:77] Creating layer accuracy_f\n",
      "I0209 21:41:31.492436  5681 net.cpp:106] Creating Layer accuracy_f\n",
      "I0209 21:41:31.492458  5681 net.cpp:454] accuracy_f <- ip_f_ip_f_0_split_0\n",
      "I0209 21:41:31.492481  5681 net.cpp:454] accuracy_f <- label_fine_data_2_split_0\n",
      "I0209 21:41:31.492493  5681 net.cpp:411] accuracy_f -> accuracy_f\n",
      "I0209 21:41:31.492516  5681 net.cpp:150] Setting up accuracy_f\n",
      "I0209 21:41:31.492525  5681 net.cpp:157] Top shape: (1)\n",
      "I0209 21:41:31.492542  5681 net.cpp:165] Memory required for data: 74589612\n",
      "I0209 21:41:31.492549  5681 layer_factory.hpp:77] Creating layer loss_f\n",
      "I0209 21:41:31.492563  5681 net.cpp:106] Creating Layer loss_f\n",
      "I0209 21:41:31.492570  5681 net.cpp:454] loss_f <- ip_f_ip_f_0_split_1\n",
      "I0209 21:41:31.492593  5681 net.cpp:454] loss_f <- label_fine_data_2_split_1\n",
      "I0209 21:41:31.492615  5681 net.cpp:411] loss_f -> loss_f\n",
      "I0209 21:41:31.492643  5681 layer_factory.hpp:77] Creating layer loss_f\n",
      "I0209 21:41:31.493197  5681 net.cpp:150] Setting up loss_f\n",
      "I0209 21:41:31.493224  5681 net.cpp:157] Top shape: (1)\n",
      "I0209 21:41:31.493230  5681 net.cpp:160]     with loss weight 1\n",
      "I0209 21:41:31.493239  5681 net.cpp:165] Memory required for data: 74589616\n",
      "I0209 21:41:31.493257  5681 net.cpp:226] loss_f needs backward computation.\n",
      "I0209 21:41:31.493276  5681 net.cpp:228] accuracy_f does not need backward computation.\n",
      "I0209 21:41:31.493284  5681 net.cpp:226] ip_f_ip_f_0_split needs backward computation.\n",
      "I0209 21:41:31.493290  5681 net.cpp:226] ip_f needs backward computation.\n",
      "I0209 21:41:31.493296  5681 net.cpp:226] loss_c needs backward computation.\n",
      "I0209 21:41:31.493304  5681 net.cpp:228] accuracy_c does not need backward computation.\n",
      "I0209 21:41:31.493312  5681 net.cpp:226] ip_c_ip_c_0_split needs backward computation.\n",
      "I0209 21:41:31.493319  5681 net.cpp:226] ip_c needs backward computation.\n",
      "I0209 21:41:31.493325  5681 net.cpp:226] ip1_sig1_0_split needs backward computation.\n",
      "I0209 21:41:31.493332  5681 net.cpp:226] sig1 needs backward computation.\n",
      "I0209 21:41:31.493338  5681 net.cpp:226] ip1 needs backward computation.\n",
      "I0209 21:41:31.493345  5681 net.cpp:226] relu3 needs backward computation.\n",
      "I0209 21:41:31.493350  5681 net.cpp:226] pool3 needs backward computation.\n",
      "I0209 21:41:31.493368  5681 net.cpp:226] conv3 needs backward computation.\n",
      "I0209 21:41:31.493376  5681 net.cpp:226] relu2 needs backward computation.\n",
      "I0209 21:41:31.493381  5681 net.cpp:226] drop2 needs backward computation.\n",
      "I0209 21:41:31.493387  5681 net.cpp:226] pool2 needs backward computation.\n",
      "I0209 21:41:31.493393  5681 net.cpp:226] conv2 needs backward computation.\n",
      "I0209 21:41:31.493409  5681 net.cpp:226] relu1b needs backward computation.\n",
      "I0209 21:41:31.493415  5681 net.cpp:226] drop1 needs backward computation.\n",
      "I0209 21:41:31.493422  5681 net.cpp:226] pool1 needs backward computation.\n",
      "I0209 21:41:31.493428  5681 net.cpp:226] cccp1b needs backward computation.\n",
      "I0209 21:41:31.493435  5681 net.cpp:226] relu1a needs backward computation.\n",
      "I0209 21:41:31.493451  5681 net.cpp:226] cccp1a needs backward computation.\n",
      "I0209 21:41:31.493458  5681 net.cpp:226] conv1 needs backward computation.\n",
      "I0209 21:41:31.493465  5681 net.cpp:228] label_fine_data_2_split does not need backward computation.\n",
      "I0209 21:41:31.493474  5681 net.cpp:228] label_coarse_data_1_split does not need backward computation.\n",
      "I0209 21:41:31.493481  5681 net.cpp:228] data does not need backward computation.\n",
      "I0209 21:41:31.493489  5681 net.cpp:270] This network produces output accuracy_c\n",
      "I0209 21:41:31.493499  5681 net.cpp:270] This network produces output accuracy_f\n",
      "I0209 21:41:31.493506  5681 net.cpp:270] This network produces output loss_c\n",
      "I0209 21:41:31.493513  5681 net.cpp:270] This network produces output loss_f\n",
      "I0209 21:41:31.493553  5681 net.cpp:283] Network initialization done.\n",
      "I0209 21:41:31.494050  5681 solver.cpp:181] Creating test net (#0) specified by test_net file: cnn_test.prototxt\n",
      "I0209 21:41:31.494230  5681 net.cpp:49] Initializing net from parameters: \n",
      "state {\n",
      "  phase: TEST\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"HDF5Data\"\n",
      "  top: \"data\"\n",
      "  top: \"label_coarse\"\n",
      "  top: \"label_fine\"\n",
      "  hdf5_data_param {\n",
      "    source: \"cifar_100_caffe_hdf5/test.txt\"\n",
      "    batch_size: 120\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 64\n",
      "    kernel_size: 4\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"cccp1a\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"cccp1a\"\n",
      "  convolution_param {\n",
      "    num_output: 42\n",
      "    kernel_size: 1\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1a\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"cccp1a\"\n",
      "  top: \"cccp1a\"\n",
      "}\n",
      "layer {\n",
      "  name: \"cccp1b\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"cccp1a\"\n",
      "  top: \"cccp1b\"\n",
      "  convolution_param {\n",
      "    num_output: 32\n",
      "    kernel_size: 1\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"cccp1b\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"drop1\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"pool1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1b\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"pool1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 42\n",
      "    kernel_size: 4\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"drop2\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"pool2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"pool2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 64\n",
      "    kernel_size: 2\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool3\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"pool3\"\n",
      "  pooling_param {\n",
      "    pool: AVE\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"pool3\"\n",
      "  top: \"pool3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"ip1\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool3\"\n",
      "  top: \"ip1\"\n",
      "  inner_product_param {\n",
      "    num_output: 768\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"sig1\"\n",
      "  type: \"Sigmoid\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"ip_c\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip_c\"\n",
      "  inner_product_param {\n",
      "    num_output: 20\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"accuracy_c\"\n",
      "  type: \"Accuracy\"\n",
      "  bottom: \"ip_c\"\n",
      "  bottom: \"label_coarse\"\n",
      "  top: \"accuracy_c\"\n",
      "}\n",
      "layer {\n",
      "  name: \"loss_c\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"ip_c\"\n",
      "  bottom: \"label_coarse\"\n",
      "  top: \"loss_c\"\n",
      "}\n",
      "layer {\n",
      "  name: \"ip_f\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip_f\"\n",
      "  inner_product_param {\n",
      "    num_output: 100\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"accuracy_f\"\n",
      "  type: \"Accuracy\"\n",
      "  bottom: \"ip_f\"\n",
      "  bottom: \"label_fine\"\n",
      "  top: \"accuracy_f\"\n",
      "}\n",
      "layer {\n",
      "  name: \"loss_f\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"ip_f\"\n",
      "  bottom: \"label_fine\"\n",
      "  top: \"loss_f\"\n",
      "}\n",
      "I0209 21:41:31.494979  5681 layer_factory.hpp:77] Creating layer data\n",
      "I0209 21:41:31.495004  5681 net.cpp:106] Creating Layer data\n",
      "I0209 21:41:31.495015  5681 net.cpp:411] data -> data\n",
      "I0209 21:41:31.495038  5681 net.cpp:411] data -> label_coarse\n",
      "I0209 21:41:31.495056  5681 net.cpp:411] data -> label_fine\n",
      "I0209 21:41:31.495072  5681 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: cifar_100_caffe_hdf5/test.txt\n",
      "I0209 21:41:31.495093  5681 hdf5_data_layer.cpp:93] Number of HDF5 files: 1\n",
      "I0209 21:41:31.495103  5681 hdf5_data_layer.cpp:28] Loading HDF5 file: /home/alex/Desktop/python-caffe-custom-cifar-100-conv-net-master/cifar_100_caffe_hdf5/test.h5\n",
      "I0209 21:41:31.804735  5681 hdf5_data_layer.cpp:67] Successully loaded 10000 rows\n",
      "I0209 21:41:31.804842  5681 net.cpp:150] Setting up data\n",
      "I0209 21:41:31.804872  5681 net.cpp:157] Top shape: 120 3 32 32 (368640)\n",
      "I0209 21:41:31.804880  5681 net.cpp:157] Top shape: 120 (120)\n",
      "I0209 21:41:31.804888  5681 net.cpp:157] Top shape: 120 (120)\n",
      "I0209 21:41:31.804893  5681 net.cpp:165] Memory required for data: 1475520\n",
      "I0209 21:41:31.804913  5681 layer_factory.hpp:77] Creating layer label_coarse_data_1_split\n",
      "I0209 21:41:31.804945  5681 net.cpp:106] Creating Layer label_coarse_data_1_split\n",
      "I0209 21:41:31.804960  5681 net.cpp:454] label_coarse_data_1_split <- label_coarse\n",
      "I0209 21:41:31.804983  5681 net.cpp:411] label_coarse_data_1_split -> label_coarse_data_1_split_0\n",
      "I0209 21:41:31.805006  5681 net.cpp:411] label_coarse_data_1_split -> label_coarse_data_1_split_1\n",
      "I0209 21:41:31.805058  5681 net.cpp:150] Setting up label_coarse_data_1_split\n",
      "I0209 21:41:31.805070  5681 net.cpp:157] Top shape: 120 (120)\n",
      "I0209 21:41:31.805078  5681 net.cpp:157] Top shape: 120 (120)\n",
      "I0209 21:41:31.805083  5681 net.cpp:165] Memory required for data: 1476480\n",
      "I0209 21:41:31.805090  5681 layer_factory.hpp:77] Creating layer label_fine_data_2_split\n",
      "I0209 21:41:31.805105  5681 net.cpp:106] Creating Layer label_fine_data_2_split\n",
      "I0209 21:41:31.805114  5681 net.cpp:454] label_fine_data_2_split <- label_fine\n",
      "I0209 21:41:31.805130  5681 net.cpp:411] label_fine_data_2_split -> label_fine_data_2_split_0\n",
      "I0209 21:41:31.805146  5681 net.cpp:411] label_fine_data_2_split -> label_fine_data_2_split_1\n",
      "I0209 21:41:31.805188  5681 net.cpp:150] Setting up label_fine_data_2_split\n",
      "I0209 21:41:31.805200  5681 net.cpp:157] Top shape: 120 (120)\n",
      "I0209 21:41:31.805207  5681 net.cpp:157] Top shape: 120 (120)\n",
      "I0209 21:41:31.805212  5681 net.cpp:165] Memory required for data: 1477440\n",
      "I0209 21:41:31.805219  5681 layer_factory.hpp:77] Creating layer conv1\n",
      "I0209 21:41:31.805245  5681 net.cpp:106] Creating Layer conv1\n",
      "I0209 21:41:31.805254  5681 net.cpp:454] conv1 <- data\n",
      "I0209 21:41:31.805272  5681 net.cpp:411] conv1 -> conv1\n",
      "I0209 21:41:31.806494  5681 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 15408\n",
      "I0209 21:41:31.806536  5681 net.cpp:150] Setting up conv1\n",
      "I0209 21:41:31.806557  5681 net.cpp:157] Top shape: 120 64 29 29 (6458880)\n",
      "I0209 21:41:31.806563  5681 net.cpp:165] Memory required for data: 27312960\n",
      "I0209 21:41:31.806591  5681 layer_factory.hpp:77] Creating layer cccp1a\n",
      "I0209 21:41:31.806615  5681 net.cpp:106] Creating Layer cccp1a\n",
      "I0209 21:41:31.806625  5681 net.cpp:454] cccp1a <- conv1\n",
      "I0209 21:41:31.806643  5681 net.cpp:411] cccp1a -> cccp1a\n",
      "I0209 21:41:31.807777  5681 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 21684\n",
      "I0209 21:41:31.807809  5681 net.cpp:150] Setting up cccp1a\n",
      "I0209 21:41:31.807821  5681 net.cpp:157] Top shape: 120 42 29 29 (4238640)\n",
      "I0209 21:41:31.807837  5681 net.cpp:165] Memory required for data: 44267520\n",
      "I0209 21:41:31.807858  5681 layer_factory.hpp:77] Creating layer relu1a\n",
      "I0209 21:41:31.807875  5681 net.cpp:106] Creating Layer relu1a\n",
      "I0209 21:41:31.807884  5681 net.cpp:454] relu1a <- cccp1a\n",
      "I0209 21:41:31.807899  5681 net.cpp:397] relu1a -> cccp1a (in-place)\n",
      "I0209 21:41:31.808248  5681 net.cpp:150] Setting up relu1a\n",
      "I0209 21:41:31.808272  5681 net.cpp:157] Top shape: 120 42 29 29 (4238640)\n",
      "I0209 21:41:31.808279  5681 net.cpp:165] Memory required for data: 61222080\n",
      "I0209 21:41:31.808286  5681 layer_factory.hpp:77] Creating layer cccp1b\n",
      "I0209 21:41:31.808316  5681 net.cpp:106] Creating Layer cccp1b\n",
      "I0209 21:41:31.808326  5681 net.cpp:454] cccp1b <- cccp1a\n",
      "I0209 21:41:31.808344  5681 net.cpp:411] cccp1b -> cccp1b\n",
      "I0209 21:41:31.809408  5681 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 21684\n",
      "I0209 21:41:31.809432  5681 net.cpp:150] Setting up cccp1b\n",
      "I0209 21:41:31.809453  5681 net.cpp:157] Top shape: 120 32 29 29 (3229440)\n",
      "I0209 21:41:31.809458  5681 net.cpp:165] Memory required for data: 74139840\n",
      "I0209 21:41:31.809481  5681 layer_factory.hpp:77] Creating layer pool1\n",
      "I0209 21:41:31.809501  5681 net.cpp:106] Creating Layer pool1\n",
      "I0209 21:41:31.809520  5681 net.cpp:454] pool1 <- cccp1b\n",
      "I0209 21:41:31.809537  5681 net.cpp:411] pool1 -> pool1\n",
      "I0209 21:41:31.809603  5681 net.cpp:150] Setting up pool1\n",
      "I0209 21:41:31.809617  5681 net.cpp:157] Top shape: 120 32 14 14 (752640)\n",
      "I0209 21:41:31.809623  5681 net.cpp:165] Memory required for data: 77150400\n",
      "I0209 21:41:31.809630  5681 layer_factory.hpp:77] Creating layer drop1\n",
      "I0209 21:41:31.809656  5681 net.cpp:106] Creating Layer drop1\n",
      "I0209 21:41:31.809665  5681 net.cpp:454] drop1 <- pool1\n",
      "I0209 21:41:31.809681  5681 net.cpp:397] drop1 -> pool1 (in-place)\n",
      "I0209 21:41:31.809716  5681 net.cpp:150] Setting up drop1\n",
      "I0209 21:41:31.809726  5681 net.cpp:157] Top shape: 120 32 14 14 (752640)\n",
      "I0209 21:41:31.809732  5681 net.cpp:165] Memory required for data: 80160960\n",
      "I0209 21:41:31.809739  5681 layer_factory.hpp:77] Creating layer relu1b\n",
      "I0209 21:41:31.809751  5681 net.cpp:106] Creating Layer relu1b\n",
      "I0209 21:41:31.809759  5681 net.cpp:454] relu1b <- pool1\n",
      "I0209 21:41:31.809773  5681 net.cpp:397] relu1b -> pool1 (in-place)\n",
      "I0209 21:41:31.809947  5681 net.cpp:150] Setting up relu1b\n",
      "I0209 21:41:31.809960  5681 net.cpp:157] Top shape: 120 32 14 14 (752640)\n",
      "I0209 21:41:31.809975  5681 net.cpp:165] Memory required for data: 83171520\n",
      "I0209 21:41:31.809994  5681 layer_factory.hpp:77] Creating layer conv2\n",
      "I0209 21:41:31.810024  5681 net.cpp:106] Creating Layer conv2\n",
      "I0209 21:41:31.810042  5681 net.cpp:454] conv2 <- pool1\n",
      "I0209 21:41:31.810061  5681 net.cpp:411] conv2 -> conv2\n",
      "I0209 21:41:31.812074  5681 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080\n",
      "I0209 21:41:31.812111  5681 net.cpp:150] Setting up conv2\n",
      "I0209 21:41:31.812132  5681 net.cpp:157] Top shape: 120 42 11 11 (609840)\n",
      "I0209 21:41:31.812139  5681 net.cpp:165] Memory required for data: 85610880\n",
      "I0209 21:41:31.812152  5681 layer_factory.hpp:77] Creating layer pool2\n",
      "I0209 21:41:31.812168  5681 net.cpp:106] Creating Layer pool2\n",
      "I0209 21:41:31.812178  5681 net.cpp:454] pool2 <- conv2\n",
      "I0209 21:41:31.812196  5681 net.cpp:411] pool2 -> pool2\n",
      "I0209 21:41:31.812247  5681 net.cpp:150] Setting up pool2\n",
      "I0209 21:41:31.812259  5681 net.cpp:157] Top shape: 120 42 5 5 (126000)\n",
      "I0209 21:41:31.812274  5681 net.cpp:165] Memory required for data: 86114880\n",
      "I0209 21:41:31.812283  5681 layer_factory.hpp:77] Creating layer drop2\n",
      "I0209 21:41:31.812294  5681 net.cpp:106] Creating Layer drop2\n",
      "I0209 21:41:31.812302  5681 net.cpp:454] drop2 <- pool2\n",
      "I0209 21:41:31.812327  5681 net.cpp:397] drop2 -> pool2 (in-place)\n",
      "I0209 21:41:31.812361  5681 net.cpp:150] Setting up drop2\n",
      "I0209 21:41:31.812371  5681 net.cpp:157] Top shape: 120 42 5 5 (126000)\n",
      "I0209 21:41:31.812387  5681 net.cpp:165] Memory required for data: 86618880\n",
      "I0209 21:41:31.812396  5681 layer_factory.hpp:77] Creating layer relu2\n",
      "I0209 21:41:31.812408  5681 net.cpp:106] Creating Layer relu2\n",
      "I0209 21:41:31.812417  5681 net.cpp:454] relu2 <- pool2\n",
      "I0209 21:41:31.812432  5681 net.cpp:397] relu2 -> pool2 (in-place)\n",
      "I0209 21:41:31.812772  5681 net.cpp:150] Setting up relu2\n",
      "I0209 21:41:31.812796  5681 net.cpp:157] Top shape: 120 42 5 5 (126000)\n",
      "I0209 21:41:31.812803  5681 net.cpp:165] Memory required for data: 87122880\n",
      "I0209 21:41:31.812810  5681 layer_factory.hpp:77] Creating layer conv3\n",
      "I0209 21:41:31.812855  5681 net.cpp:106] Creating Layer conv3\n",
      "I0209 21:41:31.812866  5681 net.cpp:454] conv3 <- pool2\n",
      "I0209 21:41:31.812894  5681 net.cpp:411] conv3 -> conv3\n",
      "I0209 21:41:31.814240  5681 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6996\n",
      "I0209 21:41:31.814276  5681 net.cpp:150] Setting up conv3\n",
      "I0209 21:41:31.814296  5681 net.cpp:157] Top shape: 120 64 4 4 (122880)\n",
      "I0209 21:41:31.814302  5681 net.cpp:165] Memory required for data: 87614400\n",
      "I0209 21:41:31.814335  5681 layer_factory.hpp:77] Creating layer pool3\n",
      "I0209 21:41:31.814353  5681 net.cpp:106] Creating Layer pool3\n",
      "I0209 21:41:31.814363  5681 net.cpp:454] pool3 <- conv3\n",
      "I0209 21:41:31.814379  5681 net.cpp:411] pool3 -> pool3\n",
      "I0209 21:41:31.814733  5681 net.cpp:150] Setting up pool3\n",
      "I0209 21:41:31.814759  5681 net.cpp:157] Top shape: 120 64 2 2 (30720)\n",
      "I0209 21:41:31.814775  5681 net.cpp:165] Memory required for data: 87737280\n",
      "I0209 21:41:31.814784  5681 layer_factory.hpp:77] Creating layer relu3\n",
      "I0209 21:41:31.814812  5681 net.cpp:106] Creating Layer relu3\n",
      "I0209 21:41:31.814832  5681 net.cpp:454] relu3 <- pool3\n",
      "I0209 21:41:31.814848  5681 net.cpp:397] relu3 -> pool3 (in-place)\n",
      "I0209 21:41:31.815202  5681 net.cpp:150] Setting up relu3\n",
      "I0209 21:41:31.815227  5681 net.cpp:157] Top shape: 120 64 2 2 (30720)\n",
      "I0209 21:41:31.815233  5681 net.cpp:165] Memory required for data: 87860160\n",
      "I0209 21:41:31.815242  5681 layer_factory.hpp:77] Creating layer ip1\n",
      "I0209 21:41:31.815278  5681 net.cpp:106] Creating Layer ip1\n",
      "I0209 21:41:31.815287  5681 net.cpp:454] ip1 <- pool3\n",
      "I0209 21:41:31.815306  5681 net.cpp:411] ip1 -> ip1\n",
      "I0209 21:41:31.825582  5681 net.cpp:150] Setting up ip1\n",
      "I0209 21:41:31.825611  5681 net.cpp:157] Top shape: 120 768 (92160)\n",
      "I0209 21:41:31.825618  5681 net.cpp:165] Memory required for data: 88228800\n",
      "I0209 21:41:31.825634  5681 layer_factory.hpp:77] Creating layer sig1\n",
      "I0209 21:41:31.825661  5681 net.cpp:106] Creating Layer sig1\n",
      "I0209 21:41:31.825670  5681 net.cpp:454] sig1 <- ip1\n",
      "I0209 21:41:31.825686  5681 net.cpp:397] sig1 -> ip1 (in-place)\n",
      "I0209 21:41:31.825857  5681 net.cpp:150] Setting up sig1\n",
      "I0209 21:41:31.825870  5681 net.cpp:157] Top shape: 120 768 (92160)\n",
      "I0209 21:41:31.825875  5681 net.cpp:165] Memory required for data: 88597440\n",
      "I0209 21:41:31.825881  5681 layer_factory.hpp:77] Creating layer ip1_sig1_0_split\n",
      "I0209 21:41:31.825894  5681 net.cpp:106] Creating Layer ip1_sig1_0_split\n",
      "I0209 21:41:31.825903  5681 net.cpp:454] ip1_sig1_0_split <- ip1\n",
      "I0209 21:41:31.825918  5681 net.cpp:411] ip1_sig1_0_split -> ip1_sig1_0_split_0\n",
      "I0209 21:41:31.825950  5681 net.cpp:411] ip1_sig1_0_split -> ip1_sig1_0_split_1\n",
      "I0209 21:41:31.826011  5681 net.cpp:150] Setting up ip1_sig1_0_split\n",
      "I0209 21:41:31.826025  5681 net.cpp:157] Top shape: 120 768 (92160)\n",
      "I0209 21:41:31.826031  5681 net.cpp:157] Top shape: 120 768 (92160)\n",
      "I0209 21:41:31.826036  5681 net.cpp:165] Memory required for data: 89334720\n",
      "I0209 21:41:31.826043  5681 layer_factory.hpp:77] Creating layer ip_c\n",
      "I0209 21:41:31.826058  5681 net.cpp:106] Creating Layer ip_c\n",
      "I0209 21:41:31.826067  5681 net.cpp:454] ip_c <- ip1_sig1_0_split_0\n",
      "I0209 21:41:31.826084  5681 net.cpp:411] ip_c -> ip_c\n",
      "I0209 21:41:31.826973  5681 net.cpp:150] Setting up ip_c\n",
      "I0209 21:41:31.826998  5681 net.cpp:157] Top shape: 120 20 (2400)\n",
      "I0209 21:41:31.827004  5681 net.cpp:165] Memory required for data: 89344320\n",
      "I0209 21:41:31.827018  5681 layer_factory.hpp:77] Creating layer ip_c_ip_c_0_split\n",
      "I0209 21:41:31.827031  5681 net.cpp:106] Creating Layer ip_c_ip_c_0_split\n",
      "I0209 21:41:31.827062  5681 net.cpp:454] ip_c_ip_c_0_split <- ip_c\n",
      "I0209 21:41:31.827078  5681 net.cpp:411] ip_c_ip_c_0_split -> ip_c_ip_c_0_split_0\n",
      "I0209 21:41:31.827095  5681 net.cpp:411] ip_c_ip_c_0_split -> ip_c_ip_c_0_split_1\n",
      "I0209 21:41:31.827139  5681 net.cpp:150] Setting up ip_c_ip_c_0_split\n",
      "I0209 21:41:31.827150  5681 net.cpp:157] Top shape: 120 20 (2400)\n",
      "I0209 21:41:31.827157  5681 net.cpp:157] Top shape: 120 20 (2400)\n",
      "I0209 21:41:31.827162  5681 net.cpp:165] Memory required for data: 89363520\n",
      "I0209 21:41:31.827169  5681 layer_factory.hpp:77] Creating layer accuracy_c\n",
      "I0209 21:41:31.827193  5681 net.cpp:106] Creating Layer accuracy_c\n",
      "I0209 21:41:31.827201  5681 net.cpp:454] accuracy_c <- ip_c_ip_c_0_split_0\n",
      "I0209 21:41:31.827215  5681 net.cpp:454] accuracy_c <- label_coarse_data_1_split_0\n",
      "I0209 21:41:31.827237  5681 net.cpp:411] accuracy_c -> accuracy_c\n",
      "I0209 21:41:31.827257  5681 net.cpp:150] Setting up accuracy_c\n",
      "I0209 21:41:31.827267  5681 net.cpp:157] Top shape: (1)\n",
      "I0209 21:41:31.827272  5681 net.cpp:165] Memory required for data: 89363524\n",
      "I0209 21:41:31.827280  5681 layer_factory.hpp:77] Creating layer loss_c\n",
      "I0209 21:41:31.827292  5681 net.cpp:106] Creating Layer loss_c\n",
      "I0209 21:41:31.827301  5681 net.cpp:454] loss_c <- ip_c_ip_c_0_split_1\n",
      "I0209 21:41:31.827312  5681 net.cpp:454] loss_c <- label_coarse_data_1_split_1\n",
      "I0209 21:41:31.827324  5681 net.cpp:411] loss_c -> loss_c\n",
      "I0209 21:41:31.827342  5681 layer_factory.hpp:77] Creating layer loss_c\n",
      "I0209 21:41:31.827787  5681 net.cpp:150] Setting up loss_c\n",
      "I0209 21:41:31.827813  5681 net.cpp:157] Top shape: (1)\n",
      "I0209 21:41:31.827819  5681 net.cpp:160]     with loss weight 1\n",
      "I0209 21:41:31.827831  5681 net.cpp:165] Memory required for data: 89363528\n",
      "I0209 21:41:31.827839  5681 layer_factory.hpp:77] Creating layer ip_f\n",
      "I0209 21:41:31.827864  5681 net.cpp:106] Creating Layer ip_f\n",
      "I0209 21:41:31.827874  5681 net.cpp:454] ip_f <- ip1_sig1_0_split_1\n",
      "I0209 21:41:31.827893  5681 net.cpp:411] ip_f -> ip_f\n",
      "I0209 21:41:31.831774  5681 net.cpp:150] Setting up ip_f\n",
      "I0209 21:41:31.831799  5681 net.cpp:157] Top shape: 120 100 (12000)\n",
      "I0209 21:41:31.831805  5681 net.cpp:165] Memory required for data: 89411528\n",
      "I0209 21:41:31.831820  5681 layer_factory.hpp:77] Creating layer ip_f_ip_f_0_split\n",
      "I0209 21:41:31.831843  5681 net.cpp:106] Creating Layer ip_f_ip_f_0_split\n",
      "I0209 21:41:31.831852  5681 net.cpp:454] ip_f_ip_f_0_split <- ip_f\n",
      "I0209 21:41:31.831867  5681 net.cpp:411] ip_f_ip_f_0_split -> ip_f_ip_f_0_split_0\n",
      "I0209 21:41:31.831886  5681 net.cpp:411] ip_f_ip_f_0_split -> ip_f_ip_f_0_split_1\n",
      "I0209 21:41:31.831928  5681 net.cpp:150] Setting up ip_f_ip_f_0_split\n",
      "I0209 21:41:31.831939  5681 net.cpp:157] Top shape: 120 100 (12000)\n",
      "I0209 21:41:31.831946  5681 net.cpp:157] Top shape: 120 100 (12000)\n",
      "I0209 21:41:31.831951  5681 net.cpp:165] Memory required for data: 89507528\n",
      "I0209 21:41:31.831959  5681 layer_factory.hpp:77] Creating layer accuracy_f\n",
      "I0209 21:41:31.831980  5681 net.cpp:106] Creating Layer accuracy_f\n",
      "I0209 21:41:31.831989  5681 net.cpp:454] accuracy_f <- ip_f_ip_f_0_split_0\n",
      "I0209 21:41:31.832001  5681 net.cpp:454] accuracy_f <- label_fine_data_2_split_0\n",
      "I0209 21:41:31.832015  5681 net.cpp:411] accuracy_f -> accuracy_f\n",
      "I0209 21:41:31.832043  5681 net.cpp:150] Setting up accuracy_f\n",
      "I0209 21:41:31.832053  5681 net.cpp:157] Top shape: (1)\n",
      "I0209 21:41:31.832059  5681 net.cpp:165] Memory required for data: 89507532\n",
      "I0209 21:41:31.832065  5681 layer_factory.hpp:77] Creating layer loss_f\n",
      "I0209 21:41:31.832077  5681 net.cpp:106] Creating Layer loss_f\n",
      "I0209 21:41:31.832085  5681 net.cpp:454] loss_f <- ip_f_ip_f_0_split_1\n",
      "I0209 21:41:31.832098  5681 net.cpp:454] loss_f <- label_fine_data_2_split_1\n",
      "I0209 21:41:31.832109  5681 net.cpp:411] loss_f -> loss_f\n",
      "I0209 21:41:31.832126  5681 layer_factory.hpp:77] Creating layer loss_f\n",
      "I0209 21:41:31.832433  5681 net.cpp:150] Setting up loss_f\n",
      "I0209 21:41:31.832458  5681 net.cpp:157] Top shape: (1)\n",
      "I0209 21:41:31.832463  5681 net.cpp:160]     with loss weight 1\n",
      "I0209 21:41:31.832471  5681 net.cpp:165] Memory required for data: 89507536\n",
      "I0209 21:41:31.832499  5681 net.cpp:226] loss_f needs backward computation.\n",
      "I0209 21:41:31.832509  5681 net.cpp:228] accuracy_f does not need backward computation.\n",
      "I0209 21:41:31.832516  5681 net.cpp:226] ip_f_ip_f_0_split needs backward computation.\n",
      "I0209 21:41:31.832522  5681 net.cpp:226] ip_f needs backward computation.\n",
      "I0209 21:41:31.832528  5681 net.cpp:226] loss_c needs backward computation.\n",
      "I0209 21:41:31.832536  5681 net.cpp:228] accuracy_c does not need backward computation.\n",
      "I0209 21:41:31.832545  5681 net.cpp:226] ip_c_ip_c_0_split needs backward computation.\n",
      "I0209 21:41:31.832551  5681 net.cpp:226] ip_c needs backward computation.\n",
      "I0209 21:41:31.832556  5681 net.cpp:226] ip1_sig1_0_split needs backward computation.\n",
      "I0209 21:41:31.832563  5681 net.cpp:226] sig1 needs backward computation.\n",
      "I0209 21:41:31.832568  5681 net.cpp:226] ip1 needs backward computation.\n",
      "I0209 21:41:31.832576  5681 net.cpp:226] relu3 needs backward computation.\n",
      "I0209 21:41:31.832581  5681 net.cpp:226] pool3 needs backward computation.\n",
      "I0209 21:41:31.832587  5681 net.cpp:226] conv3 needs backward computation.\n",
      "I0209 21:41:31.832593  5681 net.cpp:226] relu2 needs backward computation.\n",
      "I0209 21:41:31.832599  5681 net.cpp:226] drop2 needs backward computation.\n",
      "I0209 21:41:31.832605  5681 net.cpp:226] pool2 needs backward computation.\n",
      "I0209 21:41:31.832612  5681 net.cpp:226] conv2 needs backward computation.\n",
      "I0209 21:41:31.832618  5681 net.cpp:226] relu1b needs backward computation.\n",
      "I0209 21:41:31.832623  5681 net.cpp:226] drop1 needs backward computation.\n",
      "I0209 21:41:31.832639  5681 net.cpp:226] pool1 needs backward computation.\n",
      "I0209 21:41:31.832645  5681 net.cpp:226] cccp1b needs backward computation.\n",
      "I0209 21:41:31.832653  5681 net.cpp:226] relu1a needs backward computation.\n",
      "I0209 21:41:31.832659  5681 net.cpp:226] cccp1a needs backward computation.\n",
      "I0209 21:41:31.832665  5681 net.cpp:226] conv1 needs backward computation.\n",
      "I0209 21:41:31.832684  5681 net.cpp:228] label_fine_data_2_split does not need backward computation.\n",
      "I0209 21:41:31.832690  5681 net.cpp:228] label_coarse_data_1_split does not need backward computation.\n",
      "I0209 21:41:31.832700  5681 net.cpp:228] data does not need backward computation.\n",
      "I0209 21:41:31.832705  5681 net.cpp:270] This network produces output accuracy_c\n",
      "I0209 21:41:31.832715  5681 net.cpp:270] This network produces output accuracy_f\n",
      "I0209 21:41:31.832721  5681 net.cpp:270] This network produces output loss_c\n",
      "I0209 21:41:31.832728  5681 net.cpp:270] This network produces output loss_f\n",
      "I0209 21:41:31.832770  5681 net.cpp:283] Network initialization done.\n",
      "I0209 21:41:31.832911  5681 solver.cpp:60] Solver scaffolding done.\n",
      "I0209 21:41:31.833463  5681 caffe.cpp:219] Starting Optimization\n",
      "I0209 21:41:31.833483  5681 solver.cpp:280] Solving \n",
      "I0209 21:41:31.833489  5681 solver.cpp:281] Learning Rate Policy: inv\n",
      "I0209 21:41:31.834378  5681 solver.cpp:338] Iteration 0, Testing net (#0)\n",
      "I0209 21:41:31.834406  5681 net.cpp:751] Copying source layer data\n",
      "I0209 21:41:31.834413  5681 net.cpp:751] Copying source layer label_coarse_data_1_split\n",
      "I0209 21:41:31.834419  5681 net.cpp:751] Copying source layer label_fine_data_2_split\n",
      "I0209 21:41:31.834432  5681 net.cpp:751] Copying source layer conv1\n",
      "I0209 21:41:31.834478  5681 net.cpp:751] Copying source layer cccp1a\n",
      "I0209 21:41:31.834508  5681 net.cpp:751] Copying source layer relu1a\n",
      "I0209 21:41:31.834516  5681 net.cpp:751] Copying source layer cccp1b\n",
      "I0209 21:41:31.834543  5681 net.cpp:751] Copying source layer pool1\n",
      "I0209 21:41:31.834549  5681 net.cpp:751] Copying source layer drop1\n",
      "I0209 21:41:31.834554  5681 net.cpp:751] Copying source layer relu1b\n",
      "I0209 21:41:31.834560  5681 net.cpp:751] Copying source layer conv2\n",
      "I0209 21:41:31.834607  5681 net.cpp:751] Copying source layer pool2\n",
      "I0209 21:41:31.834614  5681 net.cpp:751] Copying source layer drop2\n",
      "I0209 21:41:31.834619  5681 net.cpp:751] Copying source layer relu2\n",
      "I0209 21:41:31.834625  5681 net.cpp:751] Copying source layer conv3\n",
      "I0209 21:41:31.834648  5681 net.cpp:751] Copying source layer pool3\n",
      "I0209 21:41:31.834664  5681 net.cpp:751] Copying source layer relu3\n",
      "I0209 21:41:31.834671  5681 net.cpp:751] Copying source layer ip1\n",
      "I0209 21:41:31.834986  5681 net.cpp:751] Copying source layer sig1\n",
      "I0209 21:41:31.835007  5681 net.cpp:751] Copying source layer ip1_sig1_0_split\n",
      "I0209 21:41:31.835013  5681 net.cpp:751] Copying source layer ip_c\n",
      "I0209 21:41:31.835049  5681 net.cpp:751] Copying source layer ip_c_ip_c_0_split\n",
      "I0209 21:41:31.835057  5681 net.cpp:751] Copying source layer accuracy_c\n",
      "I0209 21:41:31.835062  5681 net.cpp:751] Copying source layer loss_c\n",
      "I0209 21:41:31.835067  5681 net.cpp:751] Copying source layer ip_f\n",
      "I0209 21:41:31.835090  5681 net.cpp:751] Copying source layer ip_f_ip_f_0_split\n",
      "I0209 21:41:31.835098  5681 net.cpp:751] Copying source layer accuracy_f\n",
      "I0209 21:41:31.835103  5681 net.cpp:751] Copying source layer loss_f\n",
      "I0209 21:41:34.136008  5681 solver.cpp:406]     Test net output #0: accuracy_c = 0.05075\n",
      "I0209 21:41:34.136052  5681 solver.cpp:406]     Test net output #1: accuracy_f = 0.009\n",
      "I0209 21:41:34.136065  5681 solver.cpp:406]     Test net output #2: loss_c = 3.20615 (* 1 = 3.20615 loss)\n",
      "I0209 21:41:34.136072  5681 solver.cpp:406]     Test net output #3: loss_f = 4.93057 (* 1 = 4.93057 loss)\n",
      "I0209 21:41:34.166957  5681 solver.cpp:229] Iteration 0, loss = 8.19246\n",
      "I0209 21:41:34.167004  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.08\n",
      "I0209 21:41:34.167013  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.02\n",
      "I0209 21:41:34.167024  5681 solver.cpp:245]     Train net output #2: loss_c = 3.25774 (* 1 = 3.25774 loss)\n",
      "I0209 21:41:34.167033  5681 solver.cpp:245]     Train net output #3: loss_f = 4.93472 (* 1 = 4.93472 loss)\n",
      "I0209 21:41:34.167047  5681 sgd_solver.cpp:106] Iteration 0, lr = 0.0006\n",
      "I0209 21:41:42.522385  5681 solver.cpp:229] Iteration 100, loss = 7.55238\n",
      "I0209 21:41:42.522431  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.11\n",
      "I0209 21:41:42.522442  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.01\n",
      "I0209 21:41:42.522454  5681 solver.cpp:245]     Train net output #2: loss_c = 2.96571 (* 1 = 2.96571 loss)\n",
      "I0209 21:41:42.522462  5681 solver.cpp:245]     Train net output #3: loss_f = 4.58667 (* 1 = 4.58667 loss)\n",
      "I0209 21:41:42.522471  5681 sgd_solver.cpp:106] Iteration 100, lr = 0.000595539\n",
      "I0209 21:41:50.845633  5681 solver.cpp:229] Iteration 200, loss = 7.25102\n",
      "I0209 21:41:50.845679  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.17\n",
      "I0209 21:41:50.845690  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.03\n",
      "I0209 21:41:50.845700  5681 solver.cpp:245]     Train net output #2: loss_c = 2.83043 (* 1 = 2.83043 loss)\n",
      "I0209 21:41:50.845710  5681 solver.cpp:245]     Train net output #3: loss_f = 4.4206 (* 1 = 4.4206 loss)\n",
      "I0209 21:41:50.845717  5681 sgd_solver.cpp:106] Iteration 200, lr = 0.000591155\n",
      "I0209 21:41:58.463763  5681 solver.cpp:229] Iteration 300, loss = 7.47054\n",
      "I0209 21:41:58.463809  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.1\n",
      "I0209 21:41:58.463819  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0\n",
      "I0209 21:41:58.463829  5681 solver.cpp:245]     Train net output #2: loss_c = 2.9211 (* 1 = 2.9211 loss)\n",
      "I0209 21:41:58.463838  5681 solver.cpp:245]     Train net output #3: loss_f = 4.54944 (* 1 = 4.54944 loss)\n",
      "I0209 21:41:58.463846  5681 sgd_solver.cpp:106] Iteration 300, lr = 0.000586845\n",
      "I0209 21:42:06.052978  5681 solver.cpp:229] Iteration 400, loss = 6.98909\n",
      "I0209 21:42:06.053052  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.11\n",
      "I0209 21:42:06.053064  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.03\n",
      "I0209 21:42:06.053076  5681 solver.cpp:245]     Train net output #2: loss_c = 2.76963 (* 1 = 2.76963 loss)\n",
      "I0209 21:42:06.053083  5681 solver.cpp:245]     Train net output #3: loss_f = 4.21946 (* 1 = 4.21946 loss)\n",
      "I0209 21:42:06.053093  5681 sgd_solver.cpp:106] Iteration 400, lr = 0.000582608\n",
      "I0209 21:42:13.782188  5681 solver.cpp:229] Iteration 500, loss = 6.85364\n",
      "I0209 21:42:13.782234  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.2\n",
      "I0209 21:42:13.782243  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.04\n",
      "I0209 21:42:13.782253  5681 solver.cpp:245]     Train net output #2: loss_c = 2.69588 (* 1 = 2.69588 loss)\n",
      "I0209 21:42:13.782263  5681 solver.cpp:245]     Train net output #3: loss_f = 4.15776 (* 1 = 4.15776 loss)\n",
      "I0209 21:42:13.782269  5681 sgd_solver.cpp:106] Iteration 500, lr = 0.000578441\n",
      "I0209 21:42:21.627717  5681 solver.cpp:229] Iteration 600, loss = 6.60805\n",
      "I0209 21:42:21.627763  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.2\n",
      "I0209 21:42:21.627774  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.08\n",
      "I0209 21:42:21.627784  5681 solver.cpp:245]     Train net output #2: loss_c = 2.59059 (* 1 = 2.59059 loss)\n",
      "I0209 21:42:21.627792  5681 solver.cpp:245]     Train net output #3: loss_f = 4.01745 (* 1 = 4.01745 loss)\n",
      "I0209 21:42:21.627801  5681 sgd_solver.cpp:106] Iteration 600, lr = 0.000574344\n",
      "I0209 21:42:29.363342  5681 solver.cpp:229] Iteration 700, loss = 6.56285\n",
      "I0209 21:42:29.363378  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.28\n",
      "I0209 21:42:29.363387  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.08\n",
      "I0209 21:42:29.363399  5681 solver.cpp:245]     Train net output #2: loss_c = 2.5062 (* 1 = 2.5062 loss)\n",
      "I0209 21:42:29.363406  5681 solver.cpp:245]     Train net output #3: loss_f = 4.05665 (* 1 = 4.05665 loss)\n",
      "I0209 21:42:29.363415  5681 sgd_solver.cpp:106] Iteration 700, lr = 0.000570313\n",
      "I0209 21:42:36.938963  5681 solver.cpp:229] Iteration 800, loss = 6.73547\n",
      "I0209 21:42:36.939123  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.18\n",
      "I0209 21:42:36.939136  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.08\n",
      "I0209 21:42:36.939146  5681 solver.cpp:245]     Train net output #2: loss_c = 2.61391 (* 1 = 2.61391 loss)\n",
      "I0209 21:42:36.939154  5681 solver.cpp:245]     Train net output #3: loss_f = 4.12156 (* 1 = 4.12156 loss)\n",
      "I0209 21:42:36.939162  5681 sgd_solver.cpp:106] Iteration 800, lr = 0.000566348\n",
      "I0209 21:42:44.510023  5681 solver.cpp:229] Iteration 900, loss = 6.58125\n",
      "I0209 21:42:44.510069  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.17\n",
      "I0209 21:42:44.510079  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.05\n",
      "I0209 21:42:44.510089  5681 solver.cpp:245]     Train net output #2: loss_c = 2.59231 (* 1 = 2.59231 loss)\n",
      "I0209 21:42:44.510097  5681 solver.cpp:245]     Train net output #3: loss_f = 3.98894 (* 1 = 3.98894 loss)\n",
      "I0209 21:42:44.510115  5681 sgd_solver.cpp:106] Iteration 900, lr = 0.000562447\n",
      "I0209 21:42:52.253432  5681 solver.cpp:338] Iteration 1000, Testing net (#0)\n",
      "I0209 21:42:52.253463  5681 net.cpp:751] Copying source layer data\n",
      "I0209 21:42:52.253470  5681 net.cpp:751] Copying source layer label_coarse_data_1_split\n",
      "I0209 21:42:52.253476  5681 net.cpp:751] Copying source layer label_fine_data_2_split\n",
      "I0209 21:42:52.253481  5681 net.cpp:751] Copying source layer conv1\n",
      "I0209 21:42:52.253489  5681 net.cpp:751] Copying source layer cccp1a\n",
      "I0209 21:42:52.253495  5681 net.cpp:751] Copying source layer relu1a\n",
      "I0209 21:42:52.253501  5681 net.cpp:751] Copying source layer cccp1b\n",
      "I0209 21:42:52.253507  5681 net.cpp:751] Copying source layer pool1\n",
      "I0209 21:42:52.253512  5681 net.cpp:751] Copying source layer drop1\n",
      "I0209 21:42:52.253518  5681 net.cpp:751] Copying source layer relu1b\n",
      "I0209 21:42:52.253523  5681 net.cpp:751] Copying source layer conv2\n",
      "I0209 21:42:52.253530  5681 net.cpp:751] Copying source layer pool2\n",
      "I0209 21:42:52.253535  5681 net.cpp:751] Copying source layer drop2\n",
      "I0209 21:42:52.253540  5681 net.cpp:751] Copying source layer relu2\n",
      "I0209 21:42:52.253545  5681 net.cpp:751] Copying source layer conv3\n",
      "I0209 21:42:52.253552  5681 net.cpp:751] Copying source layer pool3\n",
      "I0209 21:42:52.253557  5681 net.cpp:751] Copying source layer relu3\n",
      "I0209 21:42:52.253562  5681 net.cpp:751] Copying source layer ip1\n",
      "I0209 21:42:52.253569  5681 net.cpp:751] Copying source layer sig1\n",
      "I0209 21:42:52.253574  5681 net.cpp:751] Copying source layer ip1_sig1_0_split\n",
      "I0209 21:42:52.253581  5681 net.cpp:751] Copying source layer ip_c\n",
      "I0209 21:42:52.253587  5681 net.cpp:751] Copying source layer ip_c_ip_c_0_split\n",
      "I0209 21:42:52.253592  5681 net.cpp:751] Copying source layer accuracy_c\n",
      "I0209 21:42:52.253597  5681 net.cpp:751] Copying source layer loss_c\n",
      "I0209 21:42:52.253603  5681 net.cpp:751] Copying source layer ip_f\n",
      "I0209 21:42:52.253609  5681 net.cpp:751] Copying source layer ip_f_ip_f_0_split\n",
      "I0209 21:42:52.253615  5681 net.cpp:751] Copying source layer accuracy_f\n",
      "I0209 21:42:52.253620  5681 net.cpp:751] Copying source layer loss_f\n",
      "I0209 21:42:54.520732  5681 solver.cpp:406]     Test net output #0: accuracy_c = 0.225833\n",
      "I0209 21:42:54.520777  5681 solver.cpp:406]     Test net output #1: accuracy_f = 0.0885\n",
      "I0209 21:42:54.520789  5681 solver.cpp:406]     Test net output #2: loss_c = 2.50882 (* 1 = 2.50882 loss)\n",
      "I0209 21:42:54.520798  5681 solver.cpp:406]     Test net output #3: loss_f = 3.93482 (* 1 = 3.93482 loss)\n",
      "I0209 21:42:54.540592  5681 solver.cpp:229] Iteration 1000, loss = 6.30933\n",
      "I0209 21:42:54.540632  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.22\n",
      "I0209 21:42:54.540642  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.1\n",
      "I0209 21:42:54.540652  5681 solver.cpp:245]     Train net output #2: loss_c = 2.46177 (* 1 = 2.46177 loss)\n",
      "I0209 21:42:54.540659  5681 solver.cpp:245]     Train net output #3: loss_f = 3.84756 (* 1 = 3.84756 loss)\n",
      "I0209 21:42:54.540670  5681 sgd_solver.cpp:106] Iteration 1000, lr = 0.000558608\n",
      "I0209 21:43:02.443203  5681 solver.cpp:229] Iteration 1100, loss = 6.20141\n",
      "I0209 21:43:02.443250  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.29\n",
      "I0209 21:43:02.443284  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.1\n",
      "I0209 21:43:02.443295  5681 solver.cpp:245]     Train net output #2: loss_c = 2.43792 (* 1 = 2.43792 loss)\n",
      "I0209 21:43:02.443305  5681 solver.cpp:245]     Train net output #3: loss_f = 3.76349 (* 1 = 3.76349 loss)\n",
      "I0209 21:43:02.443312  5681 sgd_solver.cpp:106] Iteration 1100, lr = 0.000554829\n",
      "I0209 21:43:10.085963  5681 solver.cpp:229] Iteration 1200, loss = 6.28611\n",
      "I0209 21:43:10.086117  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.3\n",
      "I0209 21:43:10.086140  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.12\n",
      "I0209 21:43:10.086151  5681 solver.cpp:245]     Train net output #2: loss_c = 2.4162 (* 1 = 2.4162 loss)\n",
      "I0209 21:43:10.086160  5681 solver.cpp:245]     Train net output #3: loss_f = 3.86991 (* 1 = 3.86991 loss)\n",
      "I0209 21:43:10.086169  5681 sgd_solver.cpp:106] Iteration 1200, lr = 0.000551109\n",
      "I0209 21:43:17.698674  5681 solver.cpp:229] Iteration 1300, loss = 6.44738\n",
      "I0209 21:43:17.698721  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.2\n",
      "I0209 21:43:17.698730  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.15\n",
      "I0209 21:43:17.698740  5681 solver.cpp:245]     Train net output #2: loss_c = 2.55496 (* 1 = 2.55496 loss)\n",
      "I0209 21:43:17.698750  5681 solver.cpp:245]     Train net output #3: loss_f = 3.89241 (* 1 = 3.89241 loss)\n",
      "I0209 21:43:17.698756  5681 sgd_solver.cpp:106] Iteration 1300, lr = 0.000547447\n",
      "I0209 21:43:25.264545  5681 solver.cpp:229] Iteration 1400, loss = 6.00372\n",
      "I0209 21:43:25.264590  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.21\n",
      "I0209 21:43:25.264598  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.1\n",
      "I0209 21:43:25.264608  5681 solver.cpp:245]     Train net output #2: loss_c = 2.4021 (* 1 = 2.4021 loss)\n",
      "I0209 21:43:25.264616  5681 solver.cpp:245]     Train net output #3: loss_f = 3.60161 (* 1 = 3.60161 loss)\n",
      "I0209 21:43:25.264624  5681 sgd_solver.cpp:106] Iteration 1400, lr = 0.000543842\n",
      "I0209 21:43:32.972745  5681 solver.cpp:229] Iteration 1500, loss = 6.17308\n",
      "I0209 21:43:32.972792  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.28\n",
      "I0209 21:43:32.972801  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.12\n",
      "I0209 21:43:32.972810  5681 solver.cpp:245]     Train net output #2: loss_c = 2.43494 (* 1 = 2.43494 loss)\n",
      "I0209 21:43:32.972822  5681 solver.cpp:245]     Train net output #3: loss_f = 3.73814 (* 1 = 3.73814 loss)\n",
      "I0209 21:43:32.972832  5681 sgd_solver.cpp:106] Iteration 1500, lr = 0.000540291\n",
      "I0209 21:43:40.756397  5681 solver.cpp:229] Iteration 1600, loss = 6.03019\n",
      "I0209 21:43:40.756544  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.28\n",
      "I0209 21:43:40.756567  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.13\n",
      "I0209 21:43:40.756577  5681 solver.cpp:245]     Train net output #2: loss_c = 2.37758 (* 1 = 2.37758 loss)\n",
      "I0209 21:43:40.756587  5681 solver.cpp:245]     Train net output #3: loss_f = 3.65261 (* 1 = 3.65261 loss)\n",
      "I0209 21:43:40.756594  5681 sgd_solver.cpp:106] Iteration 1600, lr = 0.000536794\n",
      "I0209 21:43:48.478963  5681 solver.cpp:229] Iteration 1700, loss = 6.09366\n",
      "I0209 21:43:48.479012  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.23\n",
      "I0209 21:43:48.479022  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.16\n",
      "I0209 21:43:48.479032  5681 solver.cpp:245]     Train net output #2: loss_c = 2.36745 (* 1 = 2.36745 loss)\n",
      "I0209 21:43:48.479039  5681 solver.cpp:245]     Train net output #3: loss_f = 3.72621 (* 1 = 3.72621 loss)\n",
      "I0209 21:43:48.479046  5681 sgd_solver.cpp:106] Iteration 1700, lr = 0.00053335\n",
      "I0209 21:43:56.023553  5681 solver.cpp:229] Iteration 1800, loss = 6.27849\n",
      "I0209 21:43:56.023602  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.19\n",
      "I0209 21:43:56.023612  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.12\n",
      "I0209 21:43:56.023622  5681 solver.cpp:245]     Train net output #2: loss_c = 2.48012 (* 1 = 2.48012 loss)\n",
      "I0209 21:43:56.023629  5681 solver.cpp:245]     Train net output #3: loss_f = 3.79837 (* 1 = 3.79837 loss)\n",
      "I0209 21:43:56.023646  5681 sgd_solver.cpp:106] Iteration 1800, lr = 0.000529956\n",
      "I0209 21:44:03.886442  5681 solver.cpp:229] Iteration 1900, loss = 5.62426\n",
      "I0209 21:44:03.886487  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.24\n",
      "I0209 21:44:03.886498  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.17\n",
      "I0209 21:44:03.886508  5681 solver.cpp:245]     Train net output #2: loss_c = 2.2446 (* 1 = 2.2446 loss)\n",
      "I0209 21:44:03.886518  5681 solver.cpp:245]     Train net output #3: loss_f = 3.37965 (* 1 = 3.37965 loss)\n",
      "I0209 21:44:03.886529  5681 sgd_solver.cpp:106] Iteration 1900, lr = 0.000526612\n",
      "I0209 21:44:11.462873  5681 solver.cpp:338] Iteration 2000, Testing net (#0)\n",
      "I0209 21:44:11.462960  5681 net.cpp:751] Copying source layer data\n",
      "I0209 21:44:11.462976  5681 net.cpp:751] Copying source layer label_coarse_data_1_split\n",
      "I0209 21:44:11.462982  5681 net.cpp:751] Copying source layer label_fine_data_2_split\n",
      "I0209 21:44:11.462987  5681 net.cpp:751] Copying source layer conv1\n",
      "I0209 21:44:11.462996  5681 net.cpp:751] Copying source layer cccp1a\n",
      "I0209 21:44:11.463002  5681 net.cpp:751] Copying source layer relu1a\n",
      "I0209 21:44:11.463007  5681 net.cpp:751] Copying source layer cccp1b\n",
      "I0209 21:44:11.463013  5681 net.cpp:751] Copying source layer pool1\n",
      "I0209 21:44:11.463018  5681 net.cpp:751] Copying source layer drop1\n",
      "I0209 21:44:11.463024  5681 net.cpp:751] Copying source layer relu1b\n",
      "I0209 21:44:11.463029  5681 net.cpp:751] Copying source layer conv2\n",
      "I0209 21:44:11.463035  5681 net.cpp:751] Copying source layer pool2\n",
      "I0209 21:44:11.463042  5681 net.cpp:751] Copying source layer drop2\n",
      "I0209 21:44:11.463047  5681 net.cpp:751] Copying source layer relu2\n",
      "I0209 21:44:11.463052  5681 net.cpp:751] Copying source layer conv3\n",
      "I0209 21:44:11.463057  5681 net.cpp:751] Copying source layer pool3\n",
      "I0209 21:44:11.463063  5681 net.cpp:751] Copying source layer relu3\n",
      "I0209 21:44:11.463068  5681 net.cpp:751] Copying source layer ip1\n",
      "I0209 21:44:11.463074  5681 net.cpp:751] Copying source layer sig1\n",
      "I0209 21:44:11.463080  5681 net.cpp:751] Copying source layer ip1_sig1_0_split\n",
      "I0209 21:44:11.463085  5681 net.cpp:751] Copying source layer ip_c\n",
      "I0209 21:44:11.463091  5681 net.cpp:751] Copying source layer ip_c_ip_c_0_split\n",
      "I0209 21:44:11.463098  5681 net.cpp:751] Copying source layer accuracy_c\n",
      "I0209 21:44:11.463102  5681 net.cpp:751] Copying source layer loss_c\n",
      "I0209 21:44:11.463109  5681 net.cpp:751] Copying source layer ip_f\n",
      "I0209 21:44:11.463114  5681 net.cpp:751] Copying source layer ip_f_ip_f_0_split\n",
      "I0209 21:44:11.463119  5681 net.cpp:751] Copying source layer accuracy_f\n",
      "I0209 21:44:11.463125  5681 net.cpp:751] Copying source layer loss_f\n",
      "I0209 21:44:13.734472  5681 solver.cpp:406]     Test net output #0: accuracy_c = 0.293667\n",
      "I0209 21:44:13.734518  5681 solver.cpp:406]     Test net output #1: accuracy_f = 0.15225\n",
      "I0209 21:44:13.734529  5681 solver.cpp:406]     Test net output #2: loss_c = 2.27772 (* 1 = 2.27772 loss)\n",
      "I0209 21:44:13.734536  5681 solver.cpp:406]     Test net output #3: loss_f = 3.53129 (* 1 = 3.53129 loss)\n",
      "I0209 21:44:13.754299  5681 solver.cpp:229] Iteration 2000, loss = 5.80675\n",
      "I0209 21:44:13.754340  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.26\n",
      "I0209 21:44:13.754350  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.15\n",
      "I0209 21:44:13.754359  5681 solver.cpp:245]     Train net output #2: loss_c = 2.29562 (* 1 = 2.29562 loss)\n",
      "I0209 21:44:13.754369  5681 solver.cpp:245]     Train net output #3: loss_f = 3.51113 (* 1 = 3.51113 loss)\n",
      "I0209 21:44:13.754379  5681 sgd_solver.cpp:106] Iteration 2000, lr = 0.000523318\n",
      "I0209 21:44:21.510965  5681 solver.cpp:229] Iteration 2100, loss = 5.82874\n",
      "I0209 21:44:21.511011  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.3\n",
      "I0209 21:44:21.511021  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.15\n",
      "I0209 21:44:21.511031  5681 solver.cpp:245]     Train net output #2: loss_c = 2.31241 (* 1 = 2.31241 loss)\n",
      "I0209 21:44:21.511039  5681 solver.cpp:245]     Train net output #3: loss_f = 3.51633 (* 1 = 3.51633 loss)\n",
      "I0209 21:44:21.511047  5681 sgd_solver.cpp:106] Iteration 2100, lr = 0.00052007\n",
      "I0209 21:44:29.080999  5681 solver.cpp:229] Iteration 2200, loss = 5.85254\n",
      "I0209 21:44:29.081044  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.3\n",
      "I0209 21:44:29.081053  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.16\n",
      "I0209 21:44:29.081063  5681 solver.cpp:245]     Train net output #2: loss_c = 2.27307 (* 1 = 2.27307 loss)\n",
      "I0209 21:44:29.081071  5681 solver.cpp:245]     Train net output #3: loss_f = 3.57946 (* 1 = 3.57946 loss)\n",
      "I0209 21:44:29.081080  5681 sgd_solver.cpp:106] Iteration 2200, lr = 0.00051687\n",
      "I0209 21:44:36.675135  5681 solver.cpp:229] Iteration 2300, loss = 6.03414\n",
      "I0209 21:44:36.675182  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.17\n",
      "I0209 21:44:36.675215  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.16\n",
      "I0209 21:44:36.675235  5681 solver.cpp:245]     Train net output #2: loss_c = 2.45698 (* 1 = 2.45698 loss)\n",
      "I0209 21:44:36.675242  5681 solver.cpp:245]     Train net output #3: loss_f = 3.57715 (* 1 = 3.57715 loss)\n",
      "I0209 21:44:36.675251  5681 sgd_solver.cpp:106] Iteration 2300, lr = 0.000513715\n",
      "I0209 21:44:44.272289  5681 solver.cpp:229] Iteration 2400, loss = 5.39298\n",
      "I0209 21:44:44.272414  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.27\n",
      "I0209 21:44:44.272436  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.15\n",
      "I0209 21:44:44.272446  5681 solver.cpp:245]     Train net output #2: loss_c = 2.13631 (* 1 = 2.13631 loss)\n",
      "I0209 21:44:44.272454  5681 solver.cpp:245]     Train net output #3: loss_f = 3.25667 (* 1 = 3.25667 loss)\n",
      "I0209 21:44:44.272462  5681 sgd_solver.cpp:106] Iteration 2400, lr = 0.000510605\n",
      "I0209 21:44:51.873513  5681 solver.cpp:229] Iteration 2500, loss = 5.69592\n",
      "I0209 21:44:51.873559  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.3\n",
      "I0209 21:44:51.873569  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.18\n",
      "I0209 21:44:51.873579  5681 solver.cpp:245]     Train net output #2: loss_c = 2.26189 (* 1 = 2.26189 loss)\n",
      "I0209 21:44:51.873587  5681 solver.cpp:245]     Train net output #3: loss_f = 3.43403 (* 1 = 3.43403 loss)\n",
      "I0209 21:44:51.873595  5681 sgd_solver.cpp:106] Iteration 2500, lr = 0.000507538\n",
      "I0209 21:44:59.463217  5681 solver.cpp:229] Iteration 2600, loss = 5.75546\n",
      "I0209 21:44:59.463263  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.3\n",
      "I0209 21:44:59.463273  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.15\n",
      "I0209 21:44:59.463282  5681 solver.cpp:245]     Train net output #2: loss_c = 2.3408 (* 1 = 2.3408 loss)\n",
      "I0209 21:44:59.463291  5681 solver.cpp:245]     Train net output #3: loss_f = 3.41466 (* 1 = 3.41466 loss)\n",
      "I0209 21:44:59.463299  5681 sgd_solver.cpp:106] Iteration 2600, lr = 0.000504514\n",
      "I0209 21:45:07.196365  5681 solver.cpp:229] Iteration 2700, loss = 5.81249\n",
      "I0209 21:45:07.196410  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.33\n",
      "I0209 21:45:07.196420  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.19\n",
      "I0209 21:45:07.196431  5681 solver.cpp:245]     Train net output #2: loss_c = 2.24243 (* 1 = 2.24243 loss)\n",
      "I0209 21:45:07.196440  5681 solver.cpp:245]     Train net output #3: loss_f = 3.57007 (* 1 = 3.57007 loss)\n",
      "I0209 21:45:07.196458  5681 sgd_solver.cpp:106] Iteration 2700, lr = 0.000501532\n",
      "I0209 21:45:14.949944  5681 solver.cpp:229] Iteration 2800, loss = 5.56073\n",
      "I0209 21:45:14.950117  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.29\n",
      "I0209 21:45:14.950132  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.17\n",
      "I0209 21:45:14.950144  5681 solver.cpp:245]     Train net output #2: loss_c = 2.23315 (* 1 = 2.23315 loss)\n",
      "I0209 21:45:14.950151  5681 solver.cpp:245]     Train net output #3: loss_f = 3.32758 (* 1 = 3.32758 loss)\n",
      "I0209 21:45:14.950160  5681 sgd_solver.cpp:106] Iteration 2800, lr = 0.00049859\n",
      "I0209 21:45:22.718969  5681 solver.cpp:229] Iteration 2900, loss = 5.06352\n",
      "I0209 21:45:22.719017  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.36\n",
      "I0209 21:45:22.719027  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.22\n",
      "I0209 21:45:22.719038  5681 solver.cpp:245]     Train net output #2: loss_c = 2.01461 (* 1 = 2.01461 loss)\n",
      "I0209 21:45:22.719048  5681 solver.cpp:245]     Train net output #3: loss_f = 3.0489 (* 1 = 3.0489 loss)\n",
      "I0209 21:45:22.719058  5681 sgd_solver.cpp:106] Iteration 2900, lr = 0.000495689\n",
      "I0209 21:45:30.316623  5681 solver.cpp:338] Iteration 3000, Testing net (#0)\n",
      "I0209 21:45:30.316664  5681 net.cpp:751] Copying source layer data\n",
      "I0209 21:45:30.316673  5681 net.cpp:751] Copying source layer label_coarse_data_1_split\n",
      "I0209 21:45:30.316679  5681 net.cpp:751] Copying source layer label_fine_data_2_split\n",
      "I0209 21:45:30.316684  5681 net.cpp:751] Copying source layer conv1\n",
      "I0209 21:45:30.316692  5681 net.cpp:751] Copying source layer cccp1a\n",
      "I0209 21:45:30.316699  5681 net.cpp:751] Copying source layer relu1a\n",
      "I0209 21:45:30.316715  5681 net.cpp:751] Copying source layer cccp1b\n",
      "I0209 21:45:30.316720  5681 net.cpp:751] Copying source layer pool1\n",
      "I0209 21:45:30.316725  5681 net.cpp:751] Copying source layer drop1\n",
      "I0209 21:45:30.316730  5681 net.cpp:751] Copying source layer relu1b\n",
      "I0209 21:45:30.316736  5681 net.cpp:751] Copying source layer conv2\n",
      "I0209 21:45:30.316742  5681 net.cpp:751] Copying source layer pool2\n",
      "I0209 21:45:30.316747  5681 net.cpp:751] Copying source layer drop2\n",
      "I0209 21:45:30.316752  5681 net.cpp:751] Copying source layer relu2\n",
      "I0209 21:45:30.316758  5681 net.cpp:751] Copying source layer conv3\n",
      "I0209 21:45:30.316764  5681 net.cpp:751] Copying source layer pool3\n",
      "I0209 21:45:30.316771  5681 net.cpp:751] Copying source layer relu3\n",
      "I0209 21:45:30.316776  5681 net.cpp:751] Copying source layer ip1\n",
      "I0209 21:45:30.316781  5681 net.cpp:751] Copying source layer sig1\n",
      "I0209 21:45:30.316787  5681 net.cpp:751] Copying source layer ip1_sig1_0_split\n",
      "I0209 21:45:30.316792  5681 net.cpp:751] Copying source layer ip_c\n",
      "I0209 21:45:30.316798  5681 net.cpp:751] Copying source layer ip_c_ip_c_0_split\n",
      "I0209 21:45:30.316804  5681 net.cpp:751] Copying source layer accuracy_c\n",
      "I0209 21:45:30.316809  5681 net.cpp:751] Copying source layer loss_c\n",
      "I0209 21:45:30.316815  5681 net.cpp:751] Copying source layer ip_f\n",
      "I0209 21:45:30.316824  5681 net.cpp:751] Copying source layer ip_f_ip_f_0_split\n",
      "I0209 21:45:30.316831  5681 net.cpp:751] Copying source layer accuracy_f\n",
      "I0209 21:45:30.316836  5681 net.cpp:751] Copying source layer loss_f\n",
      "I0209 21:45:32.697116  5681 solver.cpp:406]     Test net output #0: accuracy_c = 0.332917\n",
      "I0209 21:45:32.697159  5681 solver.cpp:406]     Test net output #1: accuracy_f = 0.201917\n",
      "I0209 21:45:32.697170  5681 solver.cpp:406]     Test net output #2: loss_c = 2.17271 (* 1 = 2.17271 loss)\n",
      "I0209 21:45:32.697178  5681 solver.cpp:406]     Test net output #3: loss_f = 3.30959 (* 1 = 3.30959 loss)\n",
      "I0209 21:45:32.716946  5681 solver.cpp:229] Iteration 3000, loss = 5.48485\n",
      "I0209 21:45:32.716975  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.27\n",
      "I0209 21:45:32.716984  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.17\n",
      "I0209 21:45:32.716994  5681 solver.cpp:245]     Train net output #2: loss_c = 2.19438 (* 1 = 2.19438 loss)\n",
      "I0209 21:45:32.717001  5681 solver.cpp:245]     Train net output #3: loss_f = 3.29047 (* 1 = 3.29047 loss)\n",
      "I0209 21:45:32.717020  5681 sgd_solver.cpp:106] Iteration 3000, lr = 0.000492826\n",
      "I0209 21:45:40.371243  5681 solver.cpp:229] Iteration 3100, loss = 5.52562\n",
      "I0209 21:45:40.371280  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.29\n",
      "I0209 21:45:40.371315  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.21\n",
      "I0209 21:45:40.371327  5681 solver.cpp:245]     Train net output #2: loss_c = 2.23968 (* 1 = 2.23968 loss)\n",
      "I0209 21:45:40.371336  5681 solver.cpp:245]     Train net output #3: loss_f = 3.28594 (* 1 = 3.28594 loss)\n",
      "I0209 21:45:40.371345  5681 sgd_solver.cpp:106] Iteration 3100, lr = 0.000490002\n",
      "I0209 21:45:48.098814  5681 solver.cpp:229] Iteration 3200, loss = 5.55434\n",
      "I0209 21:45:48.099009  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.32\n",
      "I0209 21:45:48.099025  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.17\n",
      "I0209 21:45:48.099035  5681 solver.cpp:245]     Train net output #2: loss_c = 2.15389 (* 1 = 2.15389 loss)\n",
      "I0209 21:45:48.099045  5681 solver.cpp:245]     Train net output #3: loss_f = 3.40044 (* 1 = 3.40044 loss)\n",
      "I0209 21:45:48.099056  5681 sgd_solver.cpp:106] Iteration 3200, lr = 0.000487215\n",
      "I0209 21:45:55.807250  5681 solver.cpp:229] Iteration 3300, loss = 5.72642\n",
      "I0209 21:45:55.807286  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.33\n",
      "I0209 21:45:55.807296  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.17\n",
      "I0209 21:45:55.807307  5681 solver.cpp:245]     Train net output #2: loss_c = 2.33518 (* 1 = 2.33518 loss)\n",
      "I0209 21:45:55.807315  5681 solver.cpp:245]     Train net output #3: loss_f = 3.39124 (* 1 = 3.39124 loss)\n",
      "I0209 21:45:55.807324  5681 sgd_solver.cpp:106] Iteration 3300, lr = 0.000484465\n",
      "I0209 21:46:03.512784  5681 solver.cpp:229] Iteration 3400, loss = 4.8186\n",
      "I0209 21:46:03.512835  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.37\n",
      "I0209 21:46:03.512847  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.28\n",
      "I0209 21:46:03.512858  5681 solver.cpp:245]     Train net output #2: loss_c = 1.92921 (* 1 = 1.92921 loss)\n",
      "I0209 21:46:03.512867  5681 solver.cpp:245]     Train net output #3: loss_f = 2.88939 (* 1 = 2.88939 loss)\n",
      "I0209 21:46:03.512881  5681 sgd_solver.cpp:106] Iteration 3400, lr = 0.000481751\n",
      "I0209 21:46:11.115629  5681 solver.cpp:229] Iteration 3500, loss = 5.39483\n",
      "I0209 21:46:11.115680  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.29\n",
      "I0209 21:46:11.115689  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.21\n",
      "I0209 21:46:11.115700  5681 solver.cpp:245]     Train net output #2: loss_c = 2.14171 (* 1 = 2.14171 loss)\n",
      "I0209 21:46:11.115710  5681 solver.cpp:245]     Train net output #3: loss_f = 3.25313 (* 1 = 3.25313 loss)\n",
      "I0209 21:46:11.115720  5681 sgd_solver.cpp:106] Iteration 3500, lr = 0.000479072\n",
      "I0209 21:46:18.705967  5681 solver.cpp:229] Iteration 3600, loss = 5.47403\n",
      "I0209 21:46:18.706095  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.34\n",
      "I0209 21:46:18.706107  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.2\n",
      "I0209 21:46:18.706118  5681 solver.cpp:245]     Train net output #2: loss_c = 2.23137 (* 1 = 2.23137 loss)\n",
      "I0209 21:46:18.706126  5681 solver.cpp:245]     Train net output #3: loss_f = 3.24266 (* 1 = 3.24266 loss)\n",
      "I0209 21:46:18.706135  5681 sgd_solver.cpp:106] Iteration 3600, lr = 0.000476428\n",
      "I0209 21:46:26.443756  5681 solver.cpp:229] Iteration 3700, loss = 5.24547\n",
      "I0209 21:46:26.443805  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.38\n",
      "I0209 21:46:26.443815  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.21\n",
      "I0209 21:46:26.443825  5681 solver.cpp:245]     Train net output #2: loss_c = 2.0452 (* 1 = 2.0452 loss)\n",
      "I0209 21:46:26.443833  5681 solver.cpp:245]     Train net output #3: loss_f = 3.20026 (* 1 = 3.20026 loss)\n",
      "I0209 21:46:26.443845  5681 sgd_solver.cpp:106] Iteration 3700, lr = 0.000473817\n",
      "I0209 21:46:34.050492  5681 solver.cpp:229] Iteration 3800, loss = 5.24541\n",
      "I0209 21:46:34.050536  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.3\n",
      "I0209 21:46:34.050546  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.22\n",
      "I0209 21:46:34.050556  5681 solver.cpp:245]     Train net output #2: loss_c = 2.10885 (* 1 = 2.10885 loss)\n",
      "I0209 21:46:34.050565  5681 solver.cpp:245]     Train net output #3: loss_f = 3.13656 (* 1 = 3.13656 loss)\n",
      "I0209 21:46:34.050583  5681 sgd_solver.cpp:106] Iteration 3800, lr = 0.00047124\n",
      "I0209 21:46:41.994992  5681 solver.cpp:229] Iteration 3900, loss = 4.54988\n",
      "I0209 21:46:41.995056  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.38\n",
      "I0209 21:46:41.995076  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.25\n",
      "I0209 21:46:41.995095  5681 solver.cpp:245]     Train net output #2: loss_c = 1.82459 (* 1 = 1.82459 loss)\n",
      "I0209 21:46:41.995111  5681 solver.cpp:245]     Train net output #3: loss_f = 2.72529 (* 1 = 2.72529 loss)\n",
      "I0209 21:46:41.995131  5681 sgd_solver.cpp:106] Iteration 3900, lr = 0.000468695\n",
      "I0209 21:46:50.119760  5681 solver.cpp:338] Iteration 4000, Testing net (#0)\n",
      "I0209 21:46:50.119890  5681 net.cpp:751] Copying source layer data\n",
      "I0209 21:46:50.119900  5681 net.cpp:751] Copying source layer label_coarse_data_1_split\n",
      "I0209 21:46:50.119906  5681 net.cpp:751] Copying source layer label_fine_data_2_split\n",
      "I0209 21:46:50.119911  5681 net.cpp:751] Copying source layer conv1\n",
      "I0209 21:46:50.119920  5681 net.cpp:751] Copying source layer cccp1a\n",
      "I0209 21:46:50.119927  5681 net.cpp:751] Copying source layer relu1a\n",
      "I0209 21:46:50.119932  5681 net.cpp:751] Copying source layer cccp1b\n",
      "I0209 21:46:50.119938  5681 net.cpp:751] Copying source layer pool1\n",
      "I0209 21:46:50.119945  5681 net.cpp:751] Copying source layer drop1\n",
      "I0209 21:46:50.119949  5681 net.cpp:751] Copying source layer relu1b\n",
      "I0209 21:46:50.119954  5681 net.cpp:751] Copying source layer conv2\n",
      "I0209 21:46:50.119961  5681 net.cpp:751] Copying source layer pool2\n",
      "I0209 21:46:50.119967  5681 net.cpp:751] Copying source layer drop2\n",
      "I0209 21:46:50.119972  5681 net.cpp:751] Copying source layer relu2\n",
      "I0209 21:46:50.119977  5681 net.cpp:751] Copying source layer conv3\n",
      "I0209 21:46:50.119984  5681 net.cpp:751] Copying source layer pool3\n",
      "I0209 21:46:50.119990  5681 net.cpp:751] Copying source layer relu3\n",
      "I0209 21:46:50.119995  5681 net.cpp:751] Copying source layer ip1\n",
      "I0209 21:46:50.120002  5681 net.cpp:751] Copying source layer sig1\n",
      "I0209 21:46:50.120007  5681 net.cpp:751] Copying source layer ip1_sig1_0_split\n",
      "I0209 21:46:50.120013  5681 net.cpp:751] Copying source layer ip_c\n",
      "I0209 21:46:50.120019  5681 net.cpp:751] Copying source layer ip_c_ip_c_0_split\n",
      "I0209 21:46:50.120025  5681 net.cpp:751] Copying source layer accuracy_c\n",
      "I0209 21:46:50.120030  5681 net.cpp:751] Copying source layer loss_c\n",
      "I0209 21:46:50.120036  5681 net.cpp:751] Copying source layer ip_f\n",
      "I0209 21:46:50.120043  5681 net.cpp:751] Copying source layer ip_f_ip_f_0_split\n",
      "I0209 21:46:50.120048  5681 net.cpp:751] Copying source layer accuracy_f\n",
      "I0209 21:46:50.120054  5681 net.cpp:751] Copying source layer loss_f\n",
      "I0209 21:46:52.403548  5681 solver.cpp:406]     Test net output #0: accuracy_c = 0.376333\n",
      "I0209 21:46:52.403584  5681 solver.cpp:406]     Test net output #1: accuracy_f = 0.236917\n",
      "I0209 21:46:52.403594  5681 solver.cpp:406]     Test net output #2: loss_c = 2.04395 (* 1 = 2.04395 loss)\n",
      "I0209 21:46:52.403604  5681 solver.cpp:406]     Test net output #3: loss_f = 3.10825 (* 1 = 3.10825 loss)\n",
      "I0209 21:46:52.423377  5681 solver.cpp:229] Iteration 4000, loss = 5.37537\n",
      "I0209 21:46:52.423408  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.31\n",
      "I0209 21:46:52.423418  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.2\n",
      "I0209 21:46:52.423426  5681 solver.cpp:245]     Train net output #2: loss_c = 2.14051 (* 1 = 2.14051 loss)\n",
      "I0209 21:46:52.423435  5681 solver.cpp:245]     Train net output #3: loss_f = 3.23487 (* 1 = 3.23487 loss)\n",
      "I0209 21:46:52.423444  5681 sgd_solver.cpp:106] Iteration 4000, lr = 0.000466182\n",
      "I0209 21:47:00.067085  5681 solver.cpp:229] Iteration 4100, loss = 5.18646\n",
      "I0209 21:47:00.067124  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.38\n",
      "I0209 21:47:00.067134  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.25\n",
      "I0209 21:47:00.067145  5681 solver.cpp:245]     Train net output #2: loss_c = 2.15417 (* 1 = 2.15417 loss)\n",
      "I0209 21:47:00.067153  5681 solver.cpp:245]     Train net output #3: loss_f = 3.03229 (* 1 = 3.03229 loss)\n",
      "I0209 21:47:00.067163  5681 sgd_solver.cpp:106] Iteration 4100, lr = 0.0004637\n",
      "I0209 21:47:08.018631  5681 solver.cpp:229] Iteration 4200, loss = 5.38722\n",
      "I0209 21:47:08.018673  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.37\n",
      "I0209 21:47:08.018684  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.22\n",
      "I0209 21:47:08.018695  5681 solver.cpp:245]     Train net output #2: loss_c = 2.14781 (* 1 = 2.14781 loss)\n",
      "I0209 21:47:08.018704  5681 solver.cpp:245]     Train net output #3: loss_f = 3.23941 (* 1 = 3.23941 loss)\n",
      "I0209 21:47:08.018715  5681 sgd_solver.cpp:106] Iteration 4200, lr = 0.000461249\n",
      "I0209 21:47:16.022610  5681 solver.cpp:229] Iteration 4300, loss = 5.34038\n",
      "I0209 21:47:16.022655  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.27\n",
      "I0209 21:47:16.022692  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.24\n",
      "I0209 21:47:16.022707  5681 solver.cpp:245]     Train net output #2: loss_c = 2.15763 (* 1 = 2.15763 loss)\n",
      "I0209 21:47:16.022718  5681 solver.cpp:245]     Train net output #3: loss_f = 3.18275 (* 1 = 3.18275 loss)\n",
      "I0209 21:47:16.022729  5681 sgd_solver.cpp:106] Iteration 4300, lr = 0.000458827\n",
      "I0209 21:47:23.650909  5681 solver.cpp:229] Iteration 4400, loss = 4.62421\n",
      "I0209 21:47:23.651041  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.37\n",
      "I0209 21:47:23.651051  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.29\n",
      "I0209 21:47:23.651062  5681 solver.cpp:245]     Train net output #2: loss_c = 1.85487 (* 1 = 1.85487 loss)\n",
      "I0209 21:47:23.651070  5681 solver.cpp:245]     Train net output #3: loss_f = 2.76934 (* 1 = 2.76934 loss)\n",
      "I0209 21:47:23.651079  5681 sgd_solver.cpp:106] Iteration 4400, lr = 0.000456435\n",
      "I0209 21:47:31.257133  5681 solver.cpp:229] Iteration 4500, loss = 5.05902\n",
      "I0209 21:47:31.257177  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.37\n",
      "I0209 21:47:31.257186  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.19\n",
      "I0209 21:47:31.257196  5681 solver.cpp:245]     Train net output #2: loss_c = 1.97882 (* 1 = 1.97882 loss)\n",
      "I0209 21:47:31.257205  5681 solver.cpp:245]     Train net output #3: loss_f = 3.0802 (* 1 = 3.0802 loss)\n",
      "I0209 21:47:31.257215  5681 sgd_solver.cpp:106] Iteration 4500, lr = 0.000454073\n",
      "I0209 21:47:38.867524  5681 solver.cpp:229] Iteration 4600, loss = 5.11713\n",
      "I0209 21:47:38.867563  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.38\n",
      "I0209 21:47:38.867573  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.25\n",
      "I0209 21:47:38.867585  5681 solver.cpp:245]     Train net output #2: loss_c = 2.0689 (* 1 = 2.0689 loss)\n",
      "I0209 21:47:38.867594  5681 solver.cpp:245]     Train net output #3: loss_f = 3.04823 (* 1 = 3.04823 loss)\n",
      "I0209 21:47:38.867602  5681 sgd_solver.cpp:106] Iteration 4600, lr = 0.000451738\n",
      "I0209 21:47:46.642618  5681 solver.cpp:229] Iteration 4700, loss = 5.34364\n",
      "I0209 21:47:46.642657  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.32\n",
      "I0209 21:47:46.642668  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.22\n",
      "I0209 21:47:46.642678  5681 solver.cpp:245]     Train net output #2: loss_c = 2.10926 (* 1 = 2.10926 loss)\n",
      "I0209 21:47:46.642688  5681 solver.cpp:245]     Train net output #3: loss_f = 3.23438 (* 1 = 3.23438 loss)\n",
      "I0209 21:47:46.642698  5681 sgd_solver.cpp:106] Iteration 4700, lr = 0.000449431\n",
      "I0209 21:47:54.584473  5681 solver.cpp:229] Iteration 4800, loss = 5.09449\n",
      "I0209 21:47:54.584625  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.37\n",
      "I0209 21:47:54.584640  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.22\n",
      "I0209 21:47:54.584651  5681 solver.cpp:245]     Train net output #2: loss_c = 2.04143 (* 1 = 2.04143 loss)\n",
      "I0209 21:47:54.584661  5681 solver.cpp:245]     Train net output #3: loss_f = 3.05306 (* 1 = 3.05306 loss)\n",
      "I0209 21:47:54.584669  5681 sgd_solver.cpp:106] Iteration 4800, lr = 0.000447152\n",
      "I0209 21:48:02.195621  5681 solver.cpp:229] Iteration 4900, loss = 4.30982\n",
      "I0209 21:48:02.195659  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.45\n",
      "I0209 21:48:02.195670  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.34\n",
      "I0209 21:48:02.195680  5681 solver.cpp:245]     Train net output #2: loss_c = 1.71998 (* 1 = 1.71998 loss)\n",
      "I0209 21:48:02.195689  5681 solver.cpp:245]     Train net output #3: loss_f = 2.58984 (* 1 = 2.58984 loss)\n",
      "I0209 21:48:02.195699  5681 sgd_solver.cpp:106] Iteration 4900, lr = 0.000444899\n",
      "I0209 21:48:09.737417  5681 solver.cpp:338] Iteration 5000, Testing net (#0)\n",
      "I0209 21:48:09.737452  5681 net.cpp:751] Copying source layer data\n",
      "I0209 21:48:09.737459  5681 net.cpp:751] Copying source layer label_coarse_data_1_split\n",
      "I0209 21:48:09.737465  5681 net.cpp:751] Copying source layer label_fine_data_2_split\n",
      "I0209 21:48:09.737471  5681 net.cpp:751] Copying source layer conv1\n",
      "I0209 21:48:09.737481  5681 net.cpp:751] Copying source layer cccp1a\n",
      "I0209 21:48:09.737488  5681 net.cpp:751] Copying source layer relu1a\n",
      "I0209 21:48:09.737494  5681 net.cpp:751] Copying source layer cccp1b\n",
      "I0209 21:48:09.737500  5681 net.cpp:751] Copying source layer pool1\n",
      "I0209 21:48:09.737506  5681 net.cpp:751] Copying source layer drop1\n",
      "I0209 21:48:09.737512  5681 net.cpp:751] Copying source layer relu1b\n",
      "I0209 21:48:09.737519  5681 net.cpp:751] Copying source layer conv2\n",
      "I0209 21:48:09.737525  5681 net.cpp:751] Copying source layer pool2\n",
      "I0209 21:48:09.737531  5681 net.cpp:751] Copying source layer drop2\n",
      "I0209 21:48:09.737536  5681 net.cpp:751] Copying source layer relu2\n",
      "I0209 21:48:09.737542  5681 net.cpp:751] Copying source layer conv3\n",
      "I0209 21:48:09.737550  5681 net.cpp:751] Copying source layer pool3\n",
      "I0209 21:48:09.737555  5681 net.cpp:751] Copying source layer relu3\n",
      "I0209 21:48:09.737561  5681 net.cpp:751] Copying source layer ip1\n",
      "I0209 21:48:09.737567  5681 net.cpp:751] Copying source layer sig1\n",
      "I0209 21:48:09.737573  5681 net.cpp:751] Copying source layer ip1_sig1_0_split\n",
      "I0209 21:48:09.737579  5681 net.cpp:751] Copying source layer ip_c\n",
      "I0209 21:48:09.737586  5681 net.cpp:751] Copying source layer ip_c_ip_c_0_split\n",
      "I0209 21:48:09.737592  5681 net.cpp:751] Copying source layer accuracy_c\n",
      "I0209 21:48:09.737598  5681 net.cpp:751] Copying source layer loss_c\n",
      "I0209 21:48:09.737604  5681 net.cpp:751] Copying source layer ip_f\n",
      "I0209 21:48:09.737612  5681 net.cpp:751] Copying source layer ip_f_ip_f_0_split\n",
      "I0209 21:48:09.737617  5681 net.cpp:751] Copying source layer accuracy_f\n",
      "I0209 21:48:09.737623  5681 net.cpp:751] Copying source layer loss_f\n",
      "I0209 21:48:12.070067  5681 solver.cpp:406]     Test net output #0: accuracy_c = 0.396167\n",
      "I0209 21:48:12.070104  5681 solver.cpp:406]     Test net output #1: accuracy_f = 0.257583\n",
      "I0209 21:48:12.070116  5681 solver.cpp:406]     Test net output #2: loss_c = 1.96402 (* 1 = 1.96402 loss)\n",
      "I0209 21:48:12.070127  5681 solver.cpp:406]     Test net output #3: loss_f = 2.992 (* 1 = 2.992 loss)\n",
      "I0209 21:48:12.090055  5681 solver.cpp:229] Iteration 5000, loss = 4.87208\n",
      "I0209 21:48:12.090077  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.41\n",
      "I0209 21:48:12.090086  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.23\n",
      "I0209 21:48:12.090096  5681 solver.cpp:245]     Train net output #2: loss_c = 1.88961 (* 1 = 1.88961 loss)\n",
      "I0209 21:48:12.090106  5681 solver.cpp:245]     Train net output #3: loss_f = 2.98247 (* 1 = 2.98247 loss)\n",
      "I0209 21:48:12.090116  5681 sgd_solver.cpp:106] Iteration 5000, lr = 0.000442673\n",
      "I0209 21:48:20.098345  5681 solver.cpp:229] Iteration 5100, loss = 5.09078\n",
      "I0209 21:48:20.098384  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.33\n",
      "I0209 21:48:20.098418  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.28\n",
      "I0209 21:48:20.098431  5681 solver.cpp:245]     Train net output #2: loss_c = 2.08876 (* 1 = 2.08876 loss)\n",
      "I0209 21:48:20.098440  5681 solver.cpp:245]     Train net output #3: loss_f = 3.00201 (* 1 = 3.00201 loss)\n",
      "I0209 21:48:20.098451  5681 sgd_solver.cpp:106] Iteration 5100, lr = 0.000440472\n",
      "I0209 21:48:28.390444  5681 solver.cpp:229] Iteration 5200, loss = 5.04634\n",
      "I0209 21:48:28.390564  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.39\n",
      "I0209 21:48:28.390579  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.26\n",
      "I0209 21:48:28.390591  5681 solver.cpp:245]     Train net output #2: loss_c = 1.96418 (* 1 = 1.96418 loss)\n",
      "I0209 21:48:28.390600  5681 solver.cpp:245]     Train net output #3: loss_f = 3.08216 (* 1 = 3.08216 loss)\n",
      "I0209 21:48:28.390611  5681 sgd_solver.cpp:106] Iteration 5200, lr = 0.000438297\n",
      "I0209 21:48:36.550297  5681 solver.cpp:229] Iteration 5300, loss = 4.8562\n",
      "I0209 21:48:36.550338  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.39\n",
      "I0209 21:48:36.550348  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.28\n",
      "I0209 21:48:36.550359  5681 solver.cpp:245]     Train net output #2: loss_c = 1.99477 (* 1 = 1.99477 loss)\n",
      "I0209 21:48:36.550369  5681 solver.cpp:245]     Train net output #3: loss_f = 2.86144 (* 1 = 2.86144 loss)\n",
      "I0209 21:48:36.550379  5681 sgd_solver.cpp:106] Iteration 5300, lr = 0.000436147\n",
      "I0209 21:48:44.514549  5681 solver.cpp:229] Iteration 5400, loss = 4.34337\n",
      "I0209 21:48:44.514601  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.43\n",
      "I0209 21:48:44.514618  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.3\n",
      "I0209 21:48:44.514637  5681 solver.cpp:245]     Train net output #2: loss_c = 1.76555 (* 1 = 1.76555 loss)\n",
      "I0209 21:48:44.514653  5681 solver.cpp:245]     Train net output #3: loss_f = 2.57782 (* 1 = 2.57782 loss)\n",
      "I0209 21:48:44.514670  5681 sgd_solver.cpp:106] Iteration 5400, lr = 0.000434021\n",
      "I0209 21:48:52.297404  5681 solver.cpp:229] Iteration 5500, loss = 4.53178\n",
      "I0209 21:48:52.297454  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.43\n",
      "I0209 21:48:52.297466  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.28\n",
      "I0209 21:48:52.297477  5681 solver.cpp:245]     Train net output #2: loss_c = 1.76855 (* 1 = 1.76855 loss)\n",
      "I0209 21:48:52.297488  5681 solver.cpp:245]     Train net output #3: loss_f = 2.76322 (* 1 = 2.76322 loss)\n",
      "I0209 21:48:52.297499  5681 sgd_solver.cpp:106] Iteration 5500, lr = 0.000431919\n",
      "I0209 21:49:00.016737  5681 solver.cpp:229] Iteration 5600, loss = 4.92653\n",
      "I0209 21:49:00.016850  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.36\n",
      "I0209 21:49:00.016880  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.29\n",
      "I0209 21:49:00.016891  5681 solver.cpp:245]     Train net output #2: loss_c = 2.01383 (* 1 = 2.01383 loss)\n",
      "I0209 21:49:00.016901  5681 solver.cpp:245]     Train net output #3: loss_f = 2.9127 (* 1 = 2.9127 loss)\n",
      "I0209 21:49:00.016921  5681 sgd_solver.cpp:106] Iteration 5600, lr = 0.000429841\n",
      "I0209 21:49:07.697268  5681 solver.cpp:229] Iteration 5700, loss = 4.77258\n",
      "I0209 21:49:07.697314  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.44\n",
      "I0209 21:49:07.697324  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.27\n",
      "I0209 21:49:07.697335  5681 solver.cpp:245]     Train net output #2: loss_c = 1.8637 (* 1 = 1.8637 loss)\n",
      "I0209 21:49:07.697343  5681 solver.cpp:245]     Train net output #3: loss_f = 2.90888 (* 1 = 2.90888 loss)\n",
      "I0209 21:49:07.697352  5681 sgd_solver.cpp:106] Iteration 5700, lr = 0.000427786\n",
      "I0209 21:49:15.371932  5681 solver.cpp:229] Iteration 5800, loss = 4.96045\n",
      "I0209 21:49:15.371978  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.3\n",
      "I0209 21:49:15.371989  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.25\n",
      "I0209 21:49:15.371997  5681 solver.cpp:245]     Train net output #2: loss_c = 2.0229 (* 1 = 2.0229 loss)\n",
      "I0209 21:49:15.372005  5681 solver.cpp:245]     Train net output #3: loss_f = 2.93755 (* 1 = 2.93755 loss)\n",
      "I0209 21:49:15.372014  5681 sgd_solver.cpp:106] Iteration 5800, lr = 0.000425754\n",
      "I0209 21:49:22.933190  5681 solver.cpp:229] Iteration 5900, loss = 4.25626\n",
      "I0209 21:49:22.933236  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.43\n",
      "I0209 21:49:22.933246  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.29\n",
      "I0209 21:49:22.933256  5681 solver.cpp:245]     Train net output #2: loss_c = 1.71411 (* 1 = 1.71411 loss)\n",
      "I0209 21:49:22.933264  5681 solver.cpp:245]     Train net output #3: loss_f = 2.54215 (* 1 = 2.54215 loss)\n",
      "I0209 21:49:22.933272  5681 sgd_solver.cpp:106] Iteration 5900, lr = 0.000423744\n",
      "I0209 21:49:30.456920  5681 solver.cpp:338] Iteration 6000, Testing net (#0)\n",
      "I0209 21:49:30.457093  5681 net.cpp:751] Copying source layer data\n",
      "I0209 21:49:30.457103  5681 net.cpp:751] Copying source layer label_coarse_data_1_split\n",
      "I0209 21:49:30.457108  5681 net.cpp:751] Copying source layer label_fine_data_2_split\n",
      "I0209 21:49:30.457113  5681 net.cpp:751] Copying source layer conv1\n",
      "I0209 21:49:30.457121  5681 net.cpp:751] Copying source layer cccp1a\n",
      "I0209 21:49:30.457129  5681 net.cpp:751] Copying source layer relu1a\n",
      "I0209 21:49:30.457134  5681 net.cpp:751] Copying source layer cccp1b\n",
      "I0209 21:49:30.457139  5681 net.cpp:751] Copying source layer pool1\n",
      "I0209 21:49:30.457145  5681 net.cpp:751] Copying source layer drop1\n",
      "I0209 21:49:30.457150  5681 net.cpp:751] Copying source layer relu1b\n",
      "I0209 21:49:30.457155  5681 net.cpp:751] Copying source layer conv2\n",
      "I0209 21:49:30.457161  5681 net.cpp:751] Copying source layer pool2\n",
      "I0209 21:49:30.457167  5681 net.cpp:751] Copying source layer drop2\n",
      "I0209 21:49:30.457172  5681 net.cpp:751] Copying source layer relu2\n",
      "I0209 21:49:30.457177  5681 net.cpp:751] Copying source layer conv3\n",
      "I0209 21:49:30.457185  5681 net.cpp:751] Copying source layer pool3\n",
      "I0209 21:49:30.457190  5681 net.cpp:751] Copying source layer relu3\n",
      "I0209 21:49:30.457195  5681 net.cpp:751] Copying source layer ip1\n",
      "I0209 21:49:30.457201  5681 net.cpp:751] Copying source layer sig1\n",
      "I0209 21:49:30.457206  5681 net.cpp:751] Copying source layer ip1_sig1_0_split\n",
      "I0209 21:49:30.457212  5681 net.cpp:751] Copying source layer ip_c\n",
      "I0209 21:49:30.457218  5681 net.cpp:751] Copying source layer ip_c_ip_c_0_split\n",
      "I0209 21:49:30.457224  5681 net.cpp:751] Copying source layer accuracy_c\n",
      "I0209 21:49:30.457229  5681 net.cpp:751] Copying source layer loss_c\n",
      "I0209 21:49:30.457236  5681 net.cpp:751] Copying source layer ip_f\n",
      "I0209 21:49:30.457242  5681 net.cpp:751] Copying source layer ip_f_ip_f_0_split\n",
      "I0209 21:49:30.457247  5681 net.cpp:751] Copying source layer accuracy_f\n",
      "I0209 21:49:30.457252  5681 net.cpp:751] Copying source layer loss_f\n",
      "I0209 21:49:32.728485  5681 solver.cpp:406]     Test net output #0: accuracy_c = 0.415\n",
      "I0209 21:49:32.728530  5681 solver.cpp:406]     Test net output #1: accuracy_f = 0.278667\n",
      "I0209 21:49:32.728541  5681 solver.cpp:406]     Test net output #2: loss_c = 1.89376 (* 1 = 1.89376 loss)\n",
      "I0209 21:49:32.728549  5681 solver.cpp:406]     Test net output #3: loss_f = 2.89154 (* 1 = 2.89154 loss)\n",
      "I0209 21:49:32.748311  5681 solver.cpp:229] Iteration 6000, loss = 4.55969\n",
      "I0209 21:49:32.748342  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.39\n",
      "I0209 21:49:32.748350  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.28\n",
      "I0209 21:49:32.748359  5681 solver.cpp:245]     Train net output #2: loss_c = 1.77887 (* 1 = 1.77887 loss)\n",
      "I0209 21:49:32.748368  5681 solver.cpp:245]     Train net output #3: loss_f = 2.78082 (* 1 = 2.78082 loss)\n",
      "I0209 21:49:32.748386  5681 sgd_solver.cpp:106] Iteration 6000, lr = 0.000421756\n",
      "I0209 21:49:40.345242  5681 solver.cpp:229] Iteration 6100, loss = 4.82089\n",
      "I0209 21:49:40.345288  5681 solver.cpp:245]     Train net output #0: accuracy_c = 0.31\n",
      "I0209 21:49:40.345299  5681 solver.cpp:245]     Train net output #1: accuracy_f = 0.32\n",
      "I0209 21:49:40.345309  5681 solver.cpp:245]     Train net output #2: loss_c = 1.96937 (* 1 = 1.96937 loss)\n",
      "I0209 21:49:40.345316  5681 solver.cpp:245]     Train net output #3: loss_f = 2.85153 (* 1 = 2.85153 loss)\n",
      "I0209 21:49:40.345325  5681 sgd_solver.cpp:106] Iteration 6100, lr = 0.00041979\n",
      "^C\n",
      "I0209 21:49:43.327046  5681 solver.cpp:456] Snapshotting to binary proto file cnn_snapshot_iter_6140.caffemodel\n",
      "I0209 21:49:43.327081  5681 net.cpp:918] Serializing 28 layers\n",
      "I0209 21:49:43.399093  5681 sgd_solver.cpp:273] Snapshotting solver state to binary proto file cnn_snapshot_iter_6140.solverstate\n",
      "I0209 21:49:43.406704  5681 solver.cpp:302] Optimization stopped early.\n",
      "I0209 21:49:43.406719  5681 caffe.cpp:222] Optimization Done.\n",
      "CPU times: user 1.08 s, sys: 128 ms, total: 1.21 s\n",
      "Wall time: 8min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!$CAFFE_ROOT/build/tools/caffe train -solver cnn_solver_rms.prototxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caffe brewed. \n",
    "## Test the model completely on test data\n",
    "Let's test directly in command-line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0209 21:50:14.472558  6056 caffe.cpp:246] Use CPU.\n",
      "I0209 21:50:14.644433  6056 net.cpp:49] Initializing net from parameters: \n",
      "state {\n",
      "  phase: TEST\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"HDF5Data\"\n",
      "  top: \"data\"\n",
      "  top: \"label_coarse\"\n",
      "  top: \"label_fine\"\n",
      "  hdf5_data_param {\n",
      "    source: \"cifar_100_caffe_hdf5/test.txt\"\n",
      "    batch_size: 120\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  convolution_param {\n",
      "    num_output: 64\n",
      "    kernel_size: 4\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"cccp1a\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"cccp1a\"\n",
      "  convolution_param {\n",
      "    num_output: 42\n",
      "    kernel_size: 1\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1a\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"cccp1a\"\n",
      "  top: \"cccp1a\"\n",
      "}\n",
      "layer {\n",
      "  name: \"cccp1b\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"cccp1a\"\n",
      "  top: \"cccp1b\"\n",
      "  convolution_param {\n",
      "    num_output: 32\n",
      "    kernel_size: 1\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"cccp1b\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"drop1\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"pool1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1b\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"pool1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  convolution_param {\n",
      "    num_output: 42\n",
      "    kernel_size: 4\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"drop2\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"pool2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"pool2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"conv3\"\n",
      "  convolution_param {\n",
      "    num_output: 64\n",
      "    kernel_size: 2\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool3\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"pool3\"\n",
      "  pooling_param {\n",
      "    pool: AVE\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"pool3\"\n",
      "  top: \"pool3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"ip1\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool3\"\n",
      "  top: \"ip1\"\n",
      "  inner_product_param {\n",
      "    num_output: 768\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"sig1\"\n",
      "  type: \"Sigmoid\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"ip_c\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip_c\"\n",
      "  inner_product_param {\n",
      "    num_output: 20\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"accuracy_c\"\n",
      "  type: \"Accuracy\"\n",
      "  bottom: \"ip_c\"\n",
      "  bottom: \"label_coarse\"\n",
      "  top: \"accuracy_c\"\n",
      "}\n",
      "layer {\n",
      "  name: \"loss_c\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"ip_c\"\n",
      "  bottom: \"label_coarse\"\n",
      "  top: \"loss_c\"\n",
      "}\n",
      "layer {\n",
      "  name: \"ip_f\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip_f\"\n",
      "  inner_product_param {\n",
      "    num_output: 100\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"accuracy_f\"\n",
      "  type: \"Accuracy\"\n",
      "  bottom: \"ip_f\"\n",
      "  bottom: \"label_fine\"\n",
      "  top: \"accuracy_f\"\n",
      "}\n",
      "layer {\n",
      "  name: \"loss_f\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"ip_f\"\n",
      "  bottom: \"label_fine\"\n",
      "  top: \"loss_f\"\n",
      "}\n",
      "I0209 21:50:14.645447  6056 layer_factory.hpp:77] Creating layer data\n",
      "I0209 21:50:14.645501  6056 net.cpp:106] Creating Layer data\n",
      "I0209 21:50:14.645529  6056 net.cpp:411] data -> data\n",
      "I0209 21:50:14.645611  6056 net.cpp:411] data -> label_coarse\n",
      "I0209 21:50:14.645638  6056 net.cpp:411] data -> label_fine\n",
      "I0209 21:50:14.645671  6056 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: cifar_100_caffe_hdf5/test.txt\n",
      "I0209 21:50:14.645719  6056 hdf5_data_layer.cpp:93] Number of HDF5 files: 1\n",
      "I0209 21:50:14.645751  6056 hdf5_data_layer.cpp:28] Loading HDF5 file: /home/alex/Desktop/python-caffe-custom-cifar-100-conv-net-master/cifar_100_caffe_hdf5/test.h5\n",
      "I0209 21:50:14.646420  6056 hdf5.cpp:35] Datatype class: H5T_INTEGER\n",
      "I0209 21:50:14.929419  6056 hdf5_data_layer.cpp:67] Successully loaded 10000 rows\n",
      "I0209 21:50:14.929474  6056 net.cpp:150] Setting up data\n",
      "I0209 21:50:14.929507  6056 net.cpp:157] Top shape: 120 3 32 32 (368640)\n",
      "I0209 21:50:14.929538  6056 net.cpp:157] Top shape: 120 (120)\n",
      "I0209 21:50:14.929545  6056 net.cpp:157] Top shape: 120 (120)\n",
      "I0209 21:50:14.929550  6056 net.cpp:165] Memory required for data: 1475520\n",
      "I0209 21:50:14.929572  6056 layer_factory.hpp:77] Creating layer label_coarse_data_1_split\n",
      "I0209 21:50:14.929610  6056 net.cpp:106] Creating Layer label_coarse_data_1_split\n",
      "I0209 21:50:14.929627  6056 net.cpp:454] label_coarse_data_1_split <- label_coarse\n",
      "I0209 21:50:14.929662  6056 net.cpp:411] label_coarse_data_1_split -> label_coarse_data_1_split_0\n",
      "I0209 21:50:14.929687  6056 net.cpp:411] label_coarse_data_1_split -> label_coarse_data_1_split_1\n",
      "I0209 21:50:14.929718  6056 net.cpp:150] Setting up label_coarse_data_1_split\n",
      "I0209 21:50:14.929730  6056 net.cpp:157] Top shape: 120 (120)\n",
      "I0209 21:50:14.929738  6056 net.cpp:157] Top shape: 120 (120)\n",
      "I0209 21:50:14.929744  6056 net.cpp:165] Memory required for data: 1476480\n",
      "I0209 21:50:14.929750  6056 layer_factory.hpp:77] Creating layer label_fine_data_2_split\n",
      "I0209 21:50:14.929764  6056 net.cpp:106] Creating Layer label_fine_data_2_split\n",
      "I0209 21:50:14.929774  6056 net.cpp:454] label_fine_data_2_split <- label_fine\n",
      "I0209 21:50:14.929788  6056 net.cpp:411] label_fine_data_2_split -> label_fine_data_2_split_0\n",
      "I0209 21:50:14.929805  6056 net.cpp:411] label_fine_data_2_split -> label_fine_data_2_split_1\n",
      "I0209 21:50:14.929822  6056 net.cpp:150] Setting up label_fine_data_2_split\n",
      "I0209 21:50:14.929832  6056 net.cpp:157] Top shape: 120 (120)\n",
      "I0209 21:50:14.929838  6056 net.cpp:157] Top shape: 120 (120)\n",
      "I0209 21:50:14.929844  6056 net.cpp:165] Memory required for data: 1477440\n",
      "I0209 21:50:14.929850  6056 layer_factory.hpp:77] Creating layer conv1\n",
      "I0209 21:50:14.929886  6056 net.cpp:106] Creating Layer conv1\n",
      "I0209 21:50:14.929895  6056 net.cpp:454] conv1 <- data\n",
      "I0209 21:50:14.929913  6056 net.cpp:411] conv1 -> conv1\n",
      "I0209 21:50:15.077723  6056 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 15408\n",
      "I0209 21:50:15.077947  6056 net.cpp:150] Setting up conv1\n",
      "I0209 21:50:15.077977  6056 net.cpp:157] Top shape: 120 64 29 29 (6458880)\n",
      "I0209 21:50:15.077983  6056 net.cpp:165] Memory required for data: 27312960\n",
      "I0209 21:50:15.078057  6056 layer_factory.hpp:77] Creating layer cccp1a\n",
      "I0209 21:50:15.078102  6056 net.cpp:106] Creating Layer cccp1a\n",
      "I0209 21:50:15.078115  6056 net.cpp:454] cccp1a <- conv1\n",
      "I0209 21:50:15.078136  6056 net.cpp:411] cccp1a -> cccp1a\n",
      "I0209 21:50:15.079035  6056 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 21684\n",
      "I0209 21:50:15.079071  6056 net.cpp:150] Setting up cccp1a\n",
      "I0209 21:50:15.079082  6056 net.cpp:157] Top shape: 120 42 29 29 (4238640)\n",
      "I0209 21:50:15.079087  6056 net.cpp:165] Memory required for data: 44267520\n",
      "I0209 21:50:15.079118  6056 layer_factory.hpp:77] Creating layer relu1a\n",
      "I0209 21:50:15.079139  6056 net.cpp:106] Creating Layer relu1a\n",
      "I0209 21:50:15.079149  6056 net.cpp:454] relu1a <- cccp1a\n",
      "I0209 21:50:15.079167  6056 net.cpp:397] relu1a -> cccp1a (in-place)\n",
      "I0209 21:50:15.079499  6056 net.cpp:150] Setting up relu1a\n",
      "I0209 21:50:15.079524  6056 net.cpp:157] Top shape: 120 42 29 29 (4238640)\n",
      "I0209 21:50:15.079531  6056 net.cpp:165] Memory required for data: 61222080\n",
      "I0209 21:50:15.079540  6056 layer_factory.hpp:77] Creating layer cccp1b\n",
      "I0209 21:50:15.079568  6056 net.cpp:106] Creating Layer cccp1b\n",
      "I0209 21:50:15.079577  6056 net.cpp:454] cccp1b <- cccp1a\n",
      "I0209 21:50:15.079596  6056 net.cpp:411] cccp1b -> cccp1b\n",
      "I0209 21:50:15.080423  6056 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 21684\n",
      "I0209 21:50:15.080457  6056 net.cpp:150] Setting up cccp1b\n",
      "I0209 21:50:15.080478  6056 net.cpp:157] Top shape: 120 32 29 29 (3229440)\n",
      "I0209 21:50:15.080484  6056 net.cpp:165] Memory required for data: 74139840\n",
      "I0209 21:50:15.080505  6056 layer_factory.hpp:77] Creating layer pool1\n",
      "I0209 21:50:15.080528  6056 net.cpp:106] Creating Layer pool1\n",
      "I0209 21:50:15.080538  6056 net.cpp:454] pool1 <- cccp1b\n",
      "I0209 21:50:15.080554  6056 net.cpp:411] pool1 -> pool1\n",
      "I0209 21:50:15.080588  6056 net.cpp:150] Setting up pool1\n",
      "I0209 21:50:15.080600  6056 net.cpp:157] Top shape: 120 32 14 14 (752640)\n",
      "I0209 21:50:15.080632  6056 net.cpp:165] Memory required for data: 77150400\n",
      "I0209 21:50:15.080641  6056 layer_factory.hpp:77] Creating layer drop1\n",
      "I0209 21:50:15.080668  6056 net.cpp:106] Creating Layer drop1\n",
      "I0209 21:50:15.080677  6056 net.cpp:454] drop1 <- pool1\n",
      "I0209 21:50:15.080693  6056 net.cpp:397] drop1 -> pool1 (in-place)\n",
      "I0209 21:50:15.080715  6056 net.cpp:150] Setting up drop1\n",
      "I0209 21:50:15.080724  6056 net.cpp:157] Top shape: 120 32 14 14 (752640)\n",
      "I0209 21:50:15.080729  6056 net.cpp:165] Memory required for data: 80160960\n",
      "I0209 21:50:15.080736  6056 layer_factory.hpp:77] Creating layer relu1b\n",
      "I0209 21:50:15.080747  6056 net.cpp:106] Creating Layer relu1b\n",
      "I0209 21:50:15.080754  6056 net.cpp:454] relu1b <- pool1\n",
      "I0209 21:50:15.080768  6056 net.cpp:397] relu1b -> pool1 (in-place)\n",
      "I0209 21:50:15.080925  6056 net.cpp:150] Setting up relu1b\n",
      "I0209 21:50:15.080937  6056 net.cpp:157] Top shape: 120 32 14 14 (752640)\n",
      "I0209 21:50:15.080943  6056 net.cpp:165] Memory required for data: 83171520\n",
      "I0209 21:50:15.080950  6056 layer_factory.hpp:77] Creating layer conv2\n",
      "I0209 21:50:15.080977  6056 net.cpp:106] Creating Layer conv2\n",
      "I0209 21:50:15.080987  6056 net.cpp:454] conv2 <- pool1\n",
      "I0209 21:50:15.081014  6056 net.cpp:411] conv2 -> conv2\n",
      "I0209 21:50:15.082806  6056 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080\n",
      "I0209 21:50:15.082842  6056 net.cpp:150] Setting up conv2\n",
      "I0209 21:50:15.082862  6056 net.cpp:157] Top shape: 120 42 11 11 (609840)\n",
      "I0209 21:50:15.082869  6056 net.cpp:165] Memory required for data: 85610880\n",
      "I0209 21:50:15.082881  6056 layer_factory.hpp:77] Creating layer pool2\n",
      "I0209 21:50:15.082897  6056 net.cpp:106] Creating Layer pool2\n",
      "I0209 21:50:15.082907  6056 net.cpp:454] pool2 <- conv2\n",
      "I0209 21:50:15.082924  6056 net.cpp:411] pool2 -> pool2\n",
      "I0209 21:50:15.082950  6056 net.cpp:150] Setting up pool2\n",
      "I0209 21:50:15.082962  6056 net.cpp:157] Top shape: 120 42 5 5 (126000)\n",
      "I0209 21:50:15.082967  6056 net.cpp:165] Memory required for data: 86114880\n",
      "I0209 21:50:15.082973  6056 layer_factory.hpp:77] Creating layer drop2\n",
      "I0209 21:50:15.082985  6056 net.cpp:106] Creating Layer drop2\n",
      "I0209 21:50:15.083003  6056 net.cpp:454] drop2 <- pool2\n",
      "I0209 21:50:15.083017  6056 net.cpp:397] drop2 -> pool2 (in-place)\n",
      "I0209 21:50:15.083046  6056 net.cpp:150] Setting up drop2\n",
      "I0209 21:50:15.083055  6056 net.cpp:157] Top shape: 120 42 5 5 (126000)\n",
      "I0209 21:50:15.083060  6056 net.cpp:165] Memory required for data: 86618880\n",
      "I0209 21:50:15.083066  6056 layer_factory.hpp:77] Creating layer relu2\n",
      "I0209 21:50:15.083077  6056 net.cpp:106] Creating Layer relu2\n",
      "I0209 21:50:15.083086  6056 net.cpp:454] relu2 <- pool2\n",
      "I0209 21:50:15.083098  6056 net.cpp:397] relu2 -> pool2 (in-place)\n",
      "I0209 21:50:15.083243  6056 net.cpp:150] Setting up relu2\n",
      "I0209 21:50:15.083255  6056 net.cpp:157] Top shape: 120 42 5 5 (126000)\n",
      "I0209 21:50:15.083261  6056 net.cpp:165] Memory required for data: 87122880\n",
      "I0209 21:50:15.083267  6056 layer_factory.hpp:77] Creating layer conv3\n",
      "I0209 21:50:15.083286  6056 net.cpp:106] Creating Layer conv3\n",
      "I0209 21:50:15.083294  6056 net.cpp:454] conv3 <- pool2\n",
      "I0209 21:50:15.083312  6056 net.cpp:411] conv3 -> conv3\n",
      "I0209 21:50:15.084568  6056 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 6996\n",
      "I0209 21:50:15.084609  6056 net.cpp:150] Setting up conv3\n",
      "I0209 21:50:15.084628  6056 net.cpp:157] Top shape: 120 64 4 4 (122880)\n",
      "I0209 21:50:15.084635  6056 net.cpp:165] Memory required for data: 87614400\n",
      "I0209 21:50:15.084656  6056 layer_factory.hpp:77] Creating layer pool3\n",
      "I0209 21:50:15.084676  6056 net.cpp:106] Creating Layer pool3\n",
      "I0209 21:50:15.084686  6056 net.cpp:454] pool3 <- conv3\n",
      "I0209 21:50:15.084702  6056 net.cpp:411] pool3 -> pool3\n",
      "I0209 21:50:15.085046  6056 net.cpp:150] Setting up pool3\n",
      "I0209 21:50:15.085072  6056 net.cpp:157] Top shape: 120 64 2 2 (30720)\n",
      "I0209 21:50:15.085078  6056 net.cpp:165] Memory required for data: 87737280\n",
      "I0209 21:50:15.085085  6056 layer_factory.hpp:77] Creating layer relu3\n",
      "I0209 21:50:15.085113  6056 net.cpp:106] Creating Layer relu3\n",
      "I0209 21:50:15.085130  6056 net.cpp:454] relu3 <- pool3\n",
      "I0209 21:50:15.085147  6056 net.cpp:397] relu3 -> pool3 (in-place)\n",
      "I0209 21:50:15.085294  6056 net.cpp:150] Setting up relu3\n",
      "I0209 21:50:15.085304  6056 net.cpp:157] Top shape: 120 64 2 2 (30720)\n",
      "I0209 21:50:15.085310  6056 net.cpp:165] Memory required for data: 87860160\n",
      "I0209 21:50:15.085317  6056 layer_factory.hpp:77] Creating layer ip1\n",
      "I0209 21:50:15.085336  6056 net.cpp:106] Creating Layer ip1\n",
      "I0209 21:50:15.085345  6056 net.cpp:454] ip1 <- pool3\n",
      "I0209 21:50:15.085362  6056 net.cpp:411] ip1 -> ip1\n",
      "I0209 21:50:15.095144  6056 net.cpp:150] Setting up ip1\n",
      "I0209 21:50:15.095171  6056 net.cpp:157] Top shape: 120 768 (92160)\n",
      "I0209 21:50:15.095177  6056 net.cpp:165] Memory required for data: 88228800\n",
      "I0209 21:50:15.095191  6056 layer_factory.hpp:77] Creating layer sig1\n",
      "I0209 21:50:15.095219  6056 net.cpp:106] Creating Layer sig1\n",
      "I0209 21:50:15.095228  6056 net.cpp:454] sig1 <- ip1\n",
      "I0209 21:50:15.095243  6056 net.cpp:397] sig1 -> ip1 (in-place)\n",
      "I0209 21:50:15.095580  6056 net.cpp:150] Setting up sig1\n",
      "I0209 21:50:15.095605  6056 net.cpp:157] Top shape: 120 768 (92160)\n",
      "I0209 21:50:15.095612  6056 net.cpp:165] Memory required for data: 88597440\n",
      "I0209 21:50:15.095619  6056 layer_factory.hpp:77] Creating layer ip1_sig1_0_split\n",
      "I0209 21:50:15.095633  6056 net.cpp:106] Creating Layer ip1_sig1_0_split\n",
      "I0209 21:50:15.095651  6056 net.cpp:454] ip1_sig1_0_split <- ip1\n",
      "I0209 21:50:15.095669  6056 net.cpp:411] ip1_sig1_0_split -> ip1_sig1_0_split_0\n",
      "I0209 21:50:15.095690  6056 net.cpp:411] ip1_sig1_0_split -> ip1_sig1_0_split_1\n",
      "I0209 21:50:15.095710  6056 net.cpp:150] Setting up ip1_sig1_0_split\n",
      "I0209 21:50:15.095721  6056 net.cpp:157] Top shape: 120 768 (92160)\n",
      "I0209 21:50:15.095728  6056 net.cpp:157] Top shape: 120 768 (92160)\n",
      "I0209 21:50:15.095733  6056 net.cpp:165] Memory required for data: 89334720\n",
      "I0209 21:50:15.095739  6056 layer_factory.hpp:77] Creating layer ip_c\n",
      "I0209 21:50:15.095753  6056 net.cpp:106] Creating Layer ip_c\n",
      "I0209 21:50:15.095762  6056 net.cpp:454] ip_c <- ip1_sig1_0_split_0\n",
      "I0209 21:50:15.095788  6056 net.cpp:411] ip_c -> ip_c\n",
      "I0209 21:50:15.096606  6056 net.cpp:150] Setting up ip_c\n",
      "I0209 21:50:15.096631  6056 net.cpp:157] Top shape: 120 20 (2400)\n",
      "I0209 21:50:15.096637  6056 net.cpp:165] Memory required for data: 89344320\n",
      "I0209 21:50:15.096649  6056 layer_factory.hpp:77] Creating layer ip_c_ip_c_0_split\n",
      "I0209 21:50:15.096671  6056 net.cpp:106] Creating Layer ip_c_ip_c_0_split\n",
      "I0209 21:50:15.096680  6056 net.cpp:454] ip_c_ip_c_0_split <- ip_c\n",
      "I0209 21:50:15.096695  6056 net.cpp:411] ip_c_ip_c_0_split -> ip_c_ip_c_0_split_0\n",
      "I0209 21:50:15.096712  6056 net.cpp:411] ip_c_ip_c_0_split -> ip_c_ip_c_0_split_1\n",
      "I0209 21:50:15.096730  6056 net.cpp:150] Setting up ip_c_ip_c_0_split\n",
      "I0209 21:50:15.096740  6056 net.cpp:157] Top shape: 120 20 (2400)\n",
      "I0209 21:50:15.096746  6056 net.cpp:157] Top shape: 120 20 (2400)\n",
      "I0209 21:50:15.096751  6056 net.cpp:165] Memory required for data: 89363520\n",
      "I0209 21:50:15.096758  6056 layer_factory.hpp:77] Creating layer accuracy_c\n",
      "I0209 21:50:15.096773  6056 net.cpp:106] Creating Layer accuracy_c\n",
      "I0209 21:50:15.096781  6056 net.cpp:454] accuracy_c <- ip_c_ip_c_0_split_0\n",
      "I0209 21:50:15.096793  6056 net.cpp:454] accuracy_c <- label_coarse_data_1_split_0\n",
      "I0209 21:50:15.096817  6056 net.cpp:411] accuracy_c -> accuracy_c\n",
      "I0209 21:50:15.096844  6056 net.cpp:150] Setting up accuracy_c\n",
      "I0209 21:50:15.096864  6056 net.cpp:157] Top shape: (1)\n",
      "I0209 21:50:15.096869  6056 net.cpp:165] Memory required for data: 89363524\n",
      "I0209 21:50:15.096876  6056 layer_factory.hpp:77] Creating layer loss_c\n",
      "I0209 21:50:15.096892  6056 net.cpp:106] Creating Layer loss_c\n",
      "I0209 21:50:15.096900  6056 net.cpp:454] loss_c <- ip_c_ip_c_0_split_1\n",
      "I0209 21:50:15.096912  6056 net.cpp:454] loss_c <- label_coarse_data_1_split_1\n",
      "I0209 21:50:15.096925  6056 net.cpp:411] loss_c -> loss_c\n",
      "I0209 21:50:15.096945  6056 layer_factory.hpp:77] Creating layer loss_c\n",
      "I0209 21:50:15.097144  6056 net.cpp:150] Setting up loss_c\n",
      "I0209 21:50:15.097157  6056 net.cpp:157] Top shape: (1)\n",
      "I0209 21:50:15.097172  6056 net.cpp:160]     with loss weight 1\n",
      "I0209 21:50:15.097204  6056 net.cpp:165] Memory required for data: 89363528\n",
      "I0209 21:50:15.097223  6056 layer_factory.hpp:77] Creating layer ip_f\n",
      "I0209 21:50:15.097239  6056 net.cpp:106] Creating Layer ip_f\n",
      "I0209 21:50:15.097249  6056 net.cpp:454] ip_f <- ip1_sig1_0_split_1\n",
      "I0209 21:50:15.097265  6056 net.cpp:411] ip_f -> ip_f\n",
      "I0209 21:50:15.101097  6056 net.cpp:150] Setting up ip_f\n",
      "I0209 21:50:15.101121  6056 net.cpp:157] Top shape: 120 100 (12000)\n",
      "I0209 21:50:15.101128  6056 net.cpp:165] Memory required for data: 89411528\n",
      "I0209 21:50:15.101150  6056 layer_factory.hpp:77] Creating layer ip_f_ip_f_0_split\n",
      "I0209 21:50:15.101164  6056 net.cpp:106] Creating Layer ip_f_ip_f_0_split\n",
      "I0209 21:50:15.101173  6056 net.cpp:454] ip_f_ip_f_0_split <- ip_f\n",
      "I0209 21:50:15.101188  6056 net.cpp:411] ip_f_ip_f_0_split -> ip_f_ip_f_0_split_0\n",
      "I0209 21:50:15.101205  6056 net.cpp:411] ip_f_ip_f_0_split -> ip_f_ip_f_0_split_1\n",
      "I0209 21:50:15.101223  6056 net.cpp:150] Setting up ip_f_ip_f_0_split\n",
      "I0209 21:50:15.101233  6056 net.cpp:157] Top shape: 120 100 (12000)\n",
      "I0209 21:50:15.101240  6056 net.cpp:157] Top shape: 120 100 (12000)\n",
      "I0209 21:50:15.101245  6056 net.cpp:165] Memory required for data: 89507528\n",
      "I0209 21:50:15.101251  6056 layer_factory.hpp:77] Creating layer accuracy_f\n",
      "I0209 21:50:15.101264  6056 net.cpp:106] Creating Layer accuracy_f\n",
      "I0209 21:50:15.101274  6056 net.cpp:454] accuracy_f <- ip_f_ip_f_0_split_0\n",
      "I0209 21:50:15.101294  6056 net.cpp:454] accuracy_f <- label_fine_data_2_split_0\n",
      "I0209 21:50:15.101307  6056 net.cpp:411] accuracy_f -> accuracy_f\n",
      "I0209 21:50:15.101336  6056 net.cpp:150] Setting up accuracy_f\n",
      "I0209 21:50:15.101346  6056 net.cpp:157] Top shape: (1)\n",
      "I0209 21:50:15.101351  6056 net.cpp:165] Memory required for data: 89507532\n",
      "I0209 21:50:15.101358  6056 layer_factory.hpp:77] Creating layer loss_f\n",
      "I0209 21:50:15.101369  6056 net.cpp:106] Creating Layer loss_f\n",
      "I0209 21:50:15.101377  6056 net.cpp:454] loss_f <- ip_f_ip_f_0_split_1\n",
      "I0209 21:50:15.101389  6056 net.cpp:454] loss_f <- label_fine_data_2_split_1\n",
      "I0209 21:50:15.101400  6056 net.cpp:411] loss_f -> loss_f\n",
      "I0209 21:50:15.101416  6056 layer_factory.hpp:77] Creating layer loss_f\n",
      "I0209 21:50:15.101827  6056 net.cpp:150] Setting up loss_f\n",
      "I0209 21:50:15.101852  6056 net.cpp:157] Top shape: (1)\n",
      "I0209 21:50:15.101858  6056 net.cpp:160]     with loss weight 1\n",
      "I0209 21:50:15.101866  6056 net.cpp:165] Memory required for data: 89507536\n",
      "I0209 21:50:15.101884  6056 net.cpp:226] loss_f needs backward computation.\n",
      "I0209 21:50:15.101893  6056 net.cpp:228] accuracy_f does not need backward computation.\n",
      "I0209 21:50:15.101902  6056 net.cpp:226] ip_f_ip_f_0_split needs backward computation.\n",
      "I0209 21:50:15.101907  6056 net.cpp:226] ip_f needs backward computation.\n",
      "I0209 21:50:15.101913  6056 net.cpp:226] loss_c needs backward computation.\n",
      "I0209 21:50:15.101920  6056 net.cpp:228] accuracy_c does not need backward computation.\n",
      "I0209 21:50:15.101927  6056 net.cpp:226] ip_c_ip_c_0_split needs backward computation.\n",
      "I0209 21:50:15.101935  6056 net.cpp:226] ip_c needs backward computation.\n",
      "I0209 21:50:15.101941  6056 net.cpp:226] ip1_sig1_0_split needs backward computation.\n",
      "I0209 21:50:15.101948  6056 net.cpp:226] sig1 needs backward computation.\n",
      "I0209 21:50:15.101954  6056 net.cpp:226] ip1 needs backward computation.\n",
      "I0209 21:50:15.101960  6056 net.cpp:226] relu3 needs backward computation.\n",
      "I0209 21:50:15.101966  6056 net.cpp:226] pool3 needs backward computation.\n",
      "I0209 21:50:15.101972  6056 net.cpp:226] conv3 needs backward computation.\n",
      "I0209 21:50:15.101979  6056 net.cpp:226] relu2 needs backward computation.\n",
      "I0209 21:50:15.101984  6056 net.cpp:226] drop2 needs backward computation.\n",
      "I0209 21:50:15.101989  6056 net.cpp:226] pool2 needs backward computation.\n",
      "I0209 21:50:15.101995  6056 net.cpp:226] conv2 needs backward computation.\n",
      "I0209 21:50:15.102001  6056 net.cpp:226] relu1b needs backward computation.\n",
      "I0209 21:50:15.102007  6056 net.cpp:226] drop1 needs backward computation.\n",
      "I0209 21:50:15.102022  6056 net.cpp:226] pool1 needs backward computation.\n",
      "I0209 21:50:15.102038  6056 net.cpp:226] cccp1b needs backward computation.\n",
      "I0209 21:50:15.102046  6056 net.cpp:226] relu1a needs backward computation.\n",
      "I0209 21:50:15.102061  6056 net.cpp:226] cccp1a needs backward computation.\n",
      "I0209 21:50:15.102067  6056 net.cpp:226] conv1 needs backward computation.\n",
      "I0209 21:50:15.102074  6056 net.cpp:228] label_fine_data_2_split does not need backward computation.\n",
      "I0209 21:50:15.102082  6056 net.cpp:228] label_coarse_data_1_split does not need backward computation.\n",
      "I0209 21:50:15.102090  6056 net.cpp:228] data does not need backward computation.\n",
      "I0209 21:50:15.102097  6056 net.cpp:270] This network produces output accuracy_c\n",
      "I0209 21:50:15.102108  6056 net.cpp:270] This network produces output accuracy_f\n",
      "I0209 21:50:15.102114  6056 net.cpp:270] This network produces output loss_c\n",
      "I0209 21:50:15.102121  6056 net.cpp:270] This network produces output loss_f\n",
      "I0209 21:50:15.102160  6056 net.cpp:283] Network initialization done.\n",
      "I0209 21:50:15.110242  6056 net.cpp:819] Copying source layer data\n",
      "I0209 21:50:15.110280  6056 net.cpp:819] Copying source layer label_coarse_data_1_split\n",
      "I0209 21:50:15.110287  6056 net.cpp:819] Copying source layer label_fine_data_2_split\n",
      "I0209 21:50:15.110292  6056 net.cpp:819] Copying source layer conv1\n",
      "I0209 21:50:15.110355  6056 net.cpp:819] Copying source layer cccp1a\n",
      "I0209 21:50:15.110394  6056 net.cpp:819] Copying source layer relu1a\n",
      "I0209 21:50:15.110400  6056 net.cpp:819] Copying source layer cccp1b\n",
      "I0209 21:50:15.110421  6056 net.cpp:819] Copying source layer pool1\n",
      "I0209 21:50:15.110427  6056 net.cpp:819] Copying source layer drop1\n",
      "I0209 21:50:15.110433  6056 net.cpp:819] Copying source layer relu1b\n",
      "I0209 21:50:15.110440  6056 net.cpp:819] Copying source layer conv2\n",
      "I0209 21:50:15.110705  6056 net.cpp:819] Copying source layer pool2\n",
      "I0209 21:50:15.110724  6056 net.cpp:819] Copying source layer drop2\n",
      "I0209 21:50:15.110730  6056 net.cpp:819] Copying source layer relu2\n",
      "I0209 21:50:15.110735  6056 net.cpp:819] Copying source layer conv3\n",
      "I0209 21:50:15.110853  6056 net.cpp:819] Copying source layer pool3\n",
      "I0209 21:50:15.110860  6056 net.cpp:819] Copying source layer relu3\n",
      "I0209 21:50:15.110865  6056 net.cpp:819] Copying source layer ip1\n",
      "I0209 21:50:15.112757  6056 net.cpp:819] Copying source layer sig1\n",
      "I0209 21:50:15.112766  6056 net.cpp:819] Copying source layer ip1_sig1_0_split\n",
      "I0209 21:50:15.112782  6056 net.cpp:819] Copying source layer ip_c\n",
      "I0209 21:50:15.112951  6056 net.cpp:819] Copying source layer ip_c_ip_c_0_split\n",
      "I0209 21:50:15.112958  6056 net.cpp:819] Copying source layer accuracy_c\n",
      "I0209 21:50:15.112974  6056 net.cpp:819] Copying source layer loss_c\n",
      "I0209 21:50:15.112979  6056 net.cpp:819] Copying source layer ip_f\n",
      "I0209 21:50:15.113746  6056 net.cpp:819] Copying source layer ip_f_ip_f_0_split\n",
      "I0209 21:50:15.113765  6056 net.cpp:819] Copying source layer accuracy_f\n",
      "I0209 21:50:15.113770  6056 net.cpp:819] Copying source layer loss_f\n",
      "I0209 21:50:15.113845  6056 caffe.cpp:252] Running for 1000 iterations.\n",
      "I0209 21:50:15.569108  6056 caffe.cpp:276] Batch 0, accuracy_c = 0.608333\n",
      "I0209 21:50:15.569159  6056 caffe.cpp:276] Batch 0, accuracy_f = 0.508333\n",
      "I0209 21:50:15.569175  6056 caffe.cpp:276] Batch 0, loss_c = 1.21104\n",
      "I0209 21:50:15.569187  6056 caffe.cpp:276] Batch 0, loss_f = 1.8871\n",
      "I0209 21:50:16.047929  6056 caffe.cpp:276] Batch 1, accuracy_c = 0.591667\n",
      "I0209 21:50:16.047981  6056 caffe.cpp:276] Batch 1, accuracy_f = 0.458333\n",
      "I0209 21:50:16.047996  6056 caffe.cpp:276] Batch 1, loss_c = 1.39065\n",
      "I0209 21:50:16.048008  6056 caffe.cpp:276] Batch 1, loss_f = 1.95418\n",
      "I0209 21:50:16.698557  6056 caffe.cpp:276] Batch 2, accuracy_c = 0.658333\n",
      "I0209 21:50:16.698606  6056 caffe.cpp:276] Batch 2, accuracy_f = 0.558333\n",
      "I0209 21:50:16.698619  6056 caffe.cpp:276] Batch 2, loss_c = 1.14977\n",
      "I0209 21:50:16.698632  6056 caffe.cpp:276] Batch 2, loss_f = 1.77614\n",
      "I0209 21:50:17.192714  6056 caffe.cpp:276] Batch 3, accuracy_c = 0.583333\n",
      "I0209 21:50:17.192762  6056 caffe.cpp:276] Batch 3, accuracy_f = 0.408333\n",
      "I0209 21:50:17.192776  6056 caffe.cpp:276] Batch 3, loss_c = 1.48332\n",
      "I0209 21:50:17.192813  6056 caffe.cpp:276] Batch 3, loss_f = 2.17044\n",
      "I0209 21:50:17.674860  6056 caffe.cpp:276] Batch 4, accuracy_c = 0.566667\n",
      "I0209 21:50:17.674909  6056 caffe.cpp:276] Batch 4, accuracy_f = 0.533333\n",
      "I0209 21:50:17.674923  6056 caffe.cpp:276] Batch 4, loss_c = 1.22574\n",
      "I0209 21:50:17.674934  6056 caffe.cpp:276] Batch 4, loss_f = 1.76926\n",
      "I0209 21:50:18.159957  6056 caffe.cpp:276] Batch 5, accuracy_c = 0.6\n",
      "I0209 21:50:18.160002  6056 caffe.cpp:276] Batch 5, accuracy_f = 0.441667\n",
      "I0209 21:50:18.160015  6056 caffe.cpp:276] Batch 5, loss_c = 1.18693\n",
      "I0209 21:50:18.160027  6056 caffe.cpp:276] Batch 5, loss_f = 1.99791\n",
      "I0209 21:50:18.825752  6056 caffe.cpp:276] Batch 6, accuracy_c = 0.5\n",
      "I0209 21:50:18.825803  6056 caffe.cpp:276] Batch 6, accuracy_f = 0.5\n",
      "I0209 21:50:18.825815  6056 caffe.cpp:276] Batch 6, loss_c = 1.55451\n",
      "I0209 21:50:18.825827  6056 caffe.cpp:276] Batch 6, loss_f = 2.12692\n",
      "I0209 21:50:20.351187  6056 caffe.cpp:276] Batch 7, accuracy_c = 0.566667\n",
      "I0209 21:50:20.351315  6056 caffe.cpp:276] Batch 7, accuracy_f = 0.383333\n",
      "I0209 21:50:20.351361  6056 caffe.cpp:276] Batch 7, loss_c = 1.37073\n",
      "I0209 21:50:20.351402  6056 caffe.cpp:276] Batch 7, loss_f = 2.36235\n",
      "I0209 21:50:22.131731  6056 caffe.cpp:276] Batch 8, accuracy_c = 0.608333\n",
      "I0209 21:50:22.131860  6056 caffe.cpp:276] Batch 8, accuracy_f = 0.558333\n",
      "I0209 21:50:22.131908  6056 caffe.cpp:276] Batch 8, loss_c = 1.23832\n",
      "I0209 21:50:22.131952  6056 caffe.cpp:276] Batch 8, loss_f = 1.79503\n",
      "I0209 21:50:22.664997  6056 caffe.cpp:276] Batch 9, accuracy_c = 0.616667\n",
      "I0209 21:50:22.665048  6056 caffe.cpp:276] Batch 9, accuracy_f = 0.491667\n",
      "I0209 21:50:22.665061  6056 caffe.cpp:276] Batch 9, loss_c = 1.34404\n",
      "I0209 21:50:22.665072  6056 caffe.cpp:276] Batch 9, loss_f = 1.99834\n",
      "I0209 21:50:23.124958  6056 caffe.cpp:276] Batch 10, accuracy_c = 0.591667\n",
      "I0209 21:50:23.125002  6056 caffe.cpp:276] Batch 10, accuracy_f = 0.466667\n",
      "I0209 21:50:23.125015  6056 caffe.cpp:276] Batch 10, loss_c = 1.40024\n",
      "I0209 21:50:23.125026  6056 caffe.cpp:276] Batch 10, loss_f = 2.06452\n",
      "I0209 21:50:23.588857  6056 caffe.cpp:276] Batch 11, accuracy_c = 0.566667\n",
      "I0209 21:50:23.588901  6056 caffe.cpp:276] Batch 11, accuracy_f = 0.4\n",
      "I0209 21:50:23.588915  6056 caffe.cpp:276] Batch 11, loss_c = 1.44381\n",
      "I0209 21:50:23.588927  6056 caffe.cpp:276] Batch 11, loss_f = 2.27387\n",
      "I0209 21:50:24.165208  6056 caffe.cpp:276] Batch 12, accuracy_c = 0.533333\n",
      "I0209 21:50:24.165256  6056 caffe.cpp:276] Batch 12, accuracy_f = 0.375\n",
      "I0209 21:50:24.165271  6056 caffe.cpp:276] Batch 12, loss_c = 1.37932\n",
      "I0209 21:50:24.165282  6056 caffe.cpp:276] Batch 12, loss_f = 2.14171\n",
      "I0209 21:50:24.644415  6056 caffe.cpp:276] Batch 13, accuracy_c = 0.558333\n",
      "I0209 21:50:24.644493  6056 caffe.cpp:276] Batch 13, accuracy_f = 0.45\n",
      "I0209 21:50:24.644510  6056 caffe.cpp:276] Batch 13, loss_c = 1.47189\n",
      "I0209 21:50:24.644521  6056 caffe.cpp:276] Batch 13, loss_f = 2.08253\n",
      "I0209 21:50:25.215167  6056 caffe.cpp:276] Batch 14, accuracy_c = 0.541667\n",
      "I0209 21:50:25.215255  6056 caffe.cpp:276] Batch 14, accuracy_f = 0.391667\n",
      "I0209 21:50:25.215272  6056 caffe.cpp:276] Batch 14, loss_c = 1.48338\n",
      "I0209 21:50:25.215284  6056 caffe.cpp:276] Batch 14, loss_f = 2.25224\n",
      "I0209 21:50:26.736800  6056 caffe.cpp:276] Batch 15, accuracy_c = 0.6\n",
      "I0209 21:50:26.736935  6056 caffe.cpp:276] Batch 15, accuracy_f = 0.508333\n",
      "I0209 21:50:26.736982  6056 caffe.cpp:276] Batch 15, loss_c = 1.21224\n",
      "I0209 21:50:26.737022  6056 caffe.cpp:276] Batch 15, loss_f = 1.96312\n",
      "I0209 21:50:28.586267  6056 caffe.cpp:276] Batch 16, accuracy_c = 0.575\n",
      "I0209 21:50:28.586314  6056 caffe.cpp:276] Batch 16, accuracy_f = 0.441667\n",
      "I0209 21:50:28.586328  6056 caffe.cpp:276] Batch 16, loss_c = 1.30889\n",
      "I0209 21:50:28.586340  6056 caffe.cpp:276] Batch 16, loss_f = 1.99622\n",
      "I0209 21:50:29.063952  6056 caffe.cpp:276] Batch 17, accuracy_c = 0.566667\n",
      "I0209 21:50:29.064002  6056 caffe.cpp:276] Batch 17, accuracy_f = 0.458333\n",
      "I0209 21:50:29.064016  6056 caffe.cpp:276] Batch 17, loss_c = 1.36907\n",
      "I0209 21:50:29.064028  6056 caffe.cpp:276] Batch 17, loss_f = 2.05922\n",
      "I0209 21:50:29.535826  6056 caffe.cpp:276] Batch 18, accuracy_c = 0.641667\n",
      "I0209 21:50:29.535872  6056 caffe.cpp:276] Batch 18, accuracy_f = 0.483333\n",
      "I0209 21:50:29.535887  6056 caffe.cpp:276] Batch 18, loss_c = 1.14562\n",
      "I0209 21:50:29.535897  6056 caffe.cpp:276] Batch 18, loss_f = 1.96976\n",
      "I0209 21:50:30.046707  6056 caffe.cpp:276] Batch 19, accuracy_c = 0.508333\n",
      "I0209 21:50:30.046752  6056 caffe.cpp:276] Batch 19, accuracy_f = 0.466667\n",
      "I0209 21:50:30.046766  6056 caffe.cpp:276] Batch 19, loss_c = 1.40372\n",
      "I0209 21:50:30.046778  6056 caffe.cpp:276] Batch 19, loss_f = 2.11139\n",
      "I0209 21:50:30.586127  6056 caffe.cpp:276] Batch 20, accuracy_c = 0.591667\n",
      "I0209 21:50:30.586185  6056 caffe.cpp:276] Batch 20, accuracy_f = 0.475\n",
      "I0209 21:50:30.586199  6056 caffe.cpp:276] Batch 20, loss_c = 1.36502\n",
      "I0209 21:50:30.586210  6056 caffe.cpp:276] Batch 20, loss_f = 2.07922\n",
      "I0209 21:50:31.054118  6056 caffe.cpp:276] Batch 21, accuracy_c = 0.525\n",
      "I0209 21:50:31.054165  6056 caffe.cpp:276] Batch 21, accuracy_f = 0.416667\n",
      "I0209 21:50:31.054177  6056 caffe.cpp:276] Batch 21, loss_c = 1.56102\n",
      "I0209 21:50:31.054188  6056 caffe.cpp:276] Batch 21, loss_f = 2.22743\n",
      "I0209 21:50:31.552587  6056 caffe.cpp:276] Batch 22, accuracy_c = 0.683333\n",
      "I0209 21:50:31.552633  6056 caffe.cpp:276] Batch 22, accuracy_f = 0.583333\n",
      "I0209 21:50:31.552645  6056 caffe.cpp:276] Batch 22, loss_c = 1.10294\n",
      "I0209 21:50:31.552656  6056 caffe.cpp:276] Batch 22, loss_f = 1.63534\n",
      "I0209 21:50:32.990628  6056 caffe.cpp:276] Batch 23, accuracy_c = 0.516667\n",
      "I0209 21:50:32.990756  6056 caffe.cpp:276] Batch 23, accuracy_f = 0.416667\n",
      "I0209 21:50:32.990800  6056 caffe.cpp:276] Batch 23, loss_c = 1.50777\n",
      "I0209 21:50:32.990844  6056 caffe.cpp:276] Batch 23, loss_f = 2.24205\n",
      "I0209 21:50:34.624454  6056 caffe.cpp:276] Batch 24, accuracy_c = 0.583333\n",
      "I0209 21:50:34.624584  6056 caffe.cpp:276] Batch 24, accuracy_f = 0.525\n",
      "I0209 21:50:34.624631  6056 caffe.cpp:276] Batch 24, loss_c = 1.37672\n",
      "I0209 21:50:34.624672  6056 caffe.cpp:276] Batch 24, loss_f = 2.10783\n",
      "I0209 21:50:35.235648  6056 caffe.cpp:276] Batch 25, accuracy_c = 0.658333\n",
      "I0209 21:50:35.235695  6056 caffe.cpp:276] Batch 25, accuracy_f = 0.558333\n",
      "I0209 21:50:35.235708  6056 caffe.cpp:276] Batch 25, loss_c = 1.08334\n",
      "I0209 21:50:35.235718  6056 caffe.cpp:276] Batch 25, loss_f = 1.72378\n",
      "I0209 21:50:35.706622  6056 caffe.cpp:276] Batch 26, accuracy_c = 0.6\n",
      "I0209 21:50:35.706670  6056 caffe.cpp:276] Batch 26, accuracy_f = 0.516667\n",
      "I0209 21:50:35.706681  6056 caffe.cpp:276] Batch 26, loss_c = 1.30659\n",
      "I0209 21:50:35.706692  6056 caffe.cpp:276] Batch 26, loss_f = 1.9632\n",
      "I0209 21:50:36.192356  6056 caffe.cpp:276] Batch 27, accuracy_c = 0.525\n",
      "I0209 21:50:36.192404  6056 caffe.cpp:276] Batch 27, accuracy_f = 0.408333\n",
      "I0209 21:50:36.192415  6056 caffe.cpp:276] Batch 27, loss_c = 1.49242\n",
      "I0209 21:50:36.192426  6056 caffe.cpp:276] Batch 27, loss_f = 2.28978\n",
      "I0209 21:50:37.812266  6056 caffe.cpp:276] Batch 28, accuracy_c = 0.616667\n",
      "I0209 21:50:37.812398  6056 caffe.cpp:276] Batch 28, accuracy_f = 0.475\n",
      "I0209 21:50:37.812444  6056 caffe.cpp:276] Batch 28, loss_c = 1.25537\n",
      "I0209 21:50:37.812485  6056 caffe.cpp:276] Batch 28, loss_f = 1.99042\n",
      "I0209 21:50:39.497038  6056 caffe.cpp:276] Batch 29, accuracy_c = 0.525\n",
      "I0209 21:50:39.497089  6056 caffe.cpp:276] Batch 29, accuracy_f = 0.458333\n",
      "I0209 21:50:39.497102  6056 caffe.cpp:276] Batch 29, loss_c = 1.53535\n",
      "I0209 21:50:39.497113  6056 caffe.cpp:276] Batch 29, loss_f = 2.25057\n",
      "I0209 21:50:39.922663  6056 caffe.cpp:276] Batch 30, accuracy_c = 0.591667\n",
      "I0209 21:50:39.922709  6056 caffe.cpp:276] Batch 30, accuracy_f = 0.45\n",
      "I0209 21:50:39.922722  6056 caffe.cpp:276] Batch 30, loss_c = 1.27812\n",
      "I0209 21:50:39.922734  6056 caffe.cpp:276] Batch 30, loss_f = 2.08174\n",
      "I0209 21:50:40.444880  6056 caffe.cpp:276] Batch 31, accuracy_c = 0.558333\n",
      "I0209 21:50:40.444926  6056 caffe.cpp:276] Batch 31, accuracy_f = 0.433333\n",
      "I0209 21:50:40.444938  6056 caffe.cpp:276] Batch 31, loss_c = 1.26688\n",
      "I0209 21:50:40.444949  6056 caffe.cpp:276] Batch 31, loss_f = 2.00404\n",
      "I0209 21:50:40.915761  6056 caffe.cpp:276] Batch 32, accuracy_c = 0.516667\n",
      "I0209 21:50:40.915841  6056 caffe.cpp:276] Batch 32, accuracy_f = 0.4\n",
      "I0209 21:50:40.915856  6056 caffe.cpp:276] Batch 32, loss_c = 1.57104\n",
      "I0209 21:50:40.915868  6056 caffe.cpp:276] Batch 32, loss_f = 2.21979\n",
      "I0209 21:50:41.424378  6056 caffe.cpp:276] Batch 33, accuracy_c = 0.525\n",
      "I0209 21:50:41.424425  6056 caffe.cpp:276] Batch 33, accuracy_f = 0.475\n",
      "I0209 21:50:41.424438  6056 caffe.cpp:276] Batch 33, loss_c = 1.47291\n",
      "I0209 21:50:41.424448  6056 caffe.cpp:276] Batch 33, loss_f = 2.15912\n",
      "I0209 21:50:41.923141  6056 caffe.cpp:276] Batch 34, accuracy_c = 0.525\n",
      "I0209 21:50:41.923188  6056 caffe.cpp:276] Batch 34, accuracy_f = 0.441667\n",
      "I0209 21:50:41.923202  6056 caffe.cpp:276] Batch 34, loss_c = 1.55993\n",
      "I0209 21:50:41.923213  6056 caffe.cpp:276] Batch 34, loss_f = 2.24312\n",
      "I0209 21:50:43.371691  6056 caffe.cpp:276] Batch 35, accuracy_c = 0.6\n",
      "I0209 21:50:43.371836  6056 caffe.cpp:276] Batch 35, accuracy_f = 0.533333\n",
      "I0209 21:50:43.371886  6056 caffe.cpp:276] Batch 35, loss_c = 1.27363\n",
      "I0209 21:50:43.371927  6056 caffe.cpp:276] Batch 35, loss_f = 1.99972\n",
      "I0209 21:50:44.356259  6056 caffe.cpp:276] Batch 36, accuracy_c = 0.616667\n",
      "I0209 21:50:44.356309  6056 caffe.cpp:276] Batch 36, accuracy_f = 0.491667\n",
      "I0209 21:50:44.356323  6056 caffe.cpp:276] Batch 36, loss_c = 1.19329\n",
      "I0209 21:50:44.356336  6056 caffe.cpp:276] Batch 36, loss_f = 1.80672\n",
      "I0209 21:50:44.874171  6056 caffe.cpp:276] Batch 37, accuracy_c = 0.65\n",
      "I0209 21:50:44.874308  6056 caffe.cpp:276] Batch 37, accuracy_f = 0.483333\n",
      "I0209 21:50:44.874325  6056 caffe.cpp:276] Batch 37, loss_c = 1.22774\n",
      "I0209 21:50:44.874337  6056 caffe.cpp:276] Batch 37, loss_f = 1.96005\n",
      "I0209 21:50:45.336626  6056 caffe.cpp:276] Batch 38, accuracy_c = 0.6\n",
      "I0209 21:50:45.336674  6056 caffe.cpp:276] Batch 38, accuracy_f = 0.475\n",
      "I0209 21:50:45.336689  6056 caffe.cpp:276] Batch 38, loss_c = 1.15181\n",
      "I0209 21:50:45.336701  6056 caffe.cpp:276] Batch 38, loss_f = 1.84432\n",
      "I0209 21:50:45.812306  6056 caffe.cpp:276] Batch 39, accuracy_c = 0.616667\n",
      "I0209 21:50:45.812352  6056 caffe.cpp:276] Batch 39, accuracy_f = 0.466667\n",
      "I0209 21:50:45.812366  6056 caffe.cpp:276] Batch 39, loss_c = 1.3195\n",
      "I0209 21:50:45.812379  6056 caffe.cpp:276] Batch 39, loss_f = 2.02446\n",
      "I0209 21:50:46.296108  6056 caffe.cpp:276] Batch 40, accuracy_c = 0.675\n",
      "I0209 21:50:46.296157  6056 caffe.cpp:276] Batch 40, accuracy_f = 0.483333\n",
      "I0209 21:50:46.296172  6056 caffe.cpp:276] Batch 40, loss_c = 1.12161\n",
      "I0209 21:50:46.296185  6056 caffe.cpp:276] Batch 40, loss_f = 1.89372\n",
      "I0209 21:50:46.782691  6056 caffe.cpp:276] Batch 41, accuracy_c = 0.658333\n",
      "I0209 21:50:46.782826  6056 caffe.cpp:276] Batch 41, accuracy_f = 0.491667\n",
      "I0209 21:50:46.782878  6056 caffe.cpp:276] Batch 41, loss_c = 1.12211\n",
      "I0209 21:50:46.782924  6056 caffe.cpp:276] Batch 41, loss_f = 1.8837\n",
      "I0209 21:50:48.851094  6056 caffe.cpp:276] Batch 42, accuracy_c = 0.633333\n",
      "I0209 21:50:48.851222  6056 caffe.cpp:276] Batch 42, accuracy_f = 0.491667\n",
      "I0209 21:50:48.851274  6056 caffe.cpp:276] Batch 42, loss_c = 1.24216\n",
      "I0209 21:50:48.851320  6056 caffe.cpp:276] Batch 42, loss_f = 1.88398\n",
      "I0209 21:50:50.203310  6056 caffe.cpp:276] Batch 43, accuracy_c = 0.6\n",
      "I0209 21:50:50.203357  6056 caffe.cpp:276] Batch 43, accuracy_f = 0.458333\n",
      "I0209 21:50:50.203372  6056 caffe.cpp:276] Batch 43, loss_c = 1.26231\n",
      "I0209 21:50:50.203383  6056 caffe.cpp:276] Batch 43, loss_f = 1.93942\n",
      "I0209 21:50:50.667729  6056 caffe.cpp:276] Batch 44, accuracy_c = 0.558333\n",
      "I0209 21:50:50.667804  6056 caffe.cpp:276] Batch 44, accuracy_f = 0.441667\n",
      "I0209 21:50:50.667820  6056 caffe.cpp:276] Batch 44, loss_c = 1.395\n",
      "I0209 21:50:50.667831  6056 caffe.cpp:276] Batch 44, loss_f = 2.06055\n",
      "I0209 21:50:51.149775  6056 caffe.cpp:276] Batch 45, accuracy_c = 0.616667\n",
      "I0209 21:50:51.149844  6056 caffe.cpp:276] Batch 45, accuracy_f = 0.533333\n",
      "I0209 21:50:51.149858  6056 caffe.cpp:276] Batch 45, loss_c = 1.22169\n",
      "I0209 21:50:51.149869  6056 caffe.cpp:276] Batch 45, loss_f = 1.86042\n",
      "I0209 21:50:51.644913  6056 caffe.cpp:276] Batch 46, accuracy_c = 0.533333\n",
      "I0209 21:50:51.644983  6056 caffe.cpp:276] Batch 46, accuracy_f = 0.475\n",
      "I0209 21:50:51.644996  6056 caffe.cpp:276] Batch 46, loss_c = 1.26032\n",
      "I0209 21:50:51.645007  6056 caffe.cpp:276] Batch 46, loss_f = 1.92126\n",
      "I0209 21:50:52.363219  6056 caffe.cpp:276] Batch 47, accuracy_c = 0.625\n",
      "I0209 21:50:52.363353  6056 caffe.cpp:276] Batch 47, accuracy_f = 0.475\n",
      "I0209 21:50:52.363397  6056 caffe.cpp:276] Batch 47, loss_c = 1.20172\n",
      "I0209 21:50:52.363438  6056 caffe.cpp:276] Batch 47, loss_f = 1.96336\n",
      "I0209 21:50:53.767159  6056 caffe.cpp:276] Batch 48, accuracy_c = 0.533333\n",
      "I0209 21:50:53.767204  6056 caffe.cpp:276] Batch 48, accuracy_f = 0.525\n",
      "I0209 21:50:53.767215  6056 caffe.cpp:276] Batch 48, loss_c = 1.47357\n",
      "I0209 21:50:53.767225  6056 caffe.cpp:276] Batch 48, loss_f = 1.99446\n",
      "I0209 21:50:54.196638  6056 caffe.cpp:276] Batch 49, accuracy_c = 0.7\n",
      "I0209 21:50:54.196683  6056 caffe.cpp:276] Batch 49, accuracy_f = 0.575\n",
      "I0209 21:50:54.196696  6056 caffe.cpp:276] Batch 49, loss_c = 0.893396\n",
      "I0209 21:50:54.196707  6056 caffe.cpp:276] Batch 49, loss_f = 1.44172\n",
      "I0209 21:50:54.687160  6056 caffe.cpp:276] Batch 50, accuracy_c = 0.625\n",
      "I0209 21:50:54.687207  6056 caffe.cpp:276] Batch 50, accuracy_f = 0.583333\n",
      "I0209 21:50:54.687219  6056 caffe.cpp:276] Batch 50, loss_c = 1.10747\n",
      "I0209 21:50:54.687229  6056 caffe.cpp:276] Batch 50, loss_f = 1.57941\n",
      "I0209 21:50:55.193814  6056 caffe.cpp:276] Batch 51, accuracy_c = 0.65\n",
      "I0209 21:50:55.193943  6056 caffe.cpp:276] Batch 51, accuracy_f = 0.525\n",
      "I0209 21:50:55.193989  6056 caffe.cpp:276] Batch 51, loss_c = 1.01944\n",
      "I0209 21:50:55.194106  6056 caffe.cpp:276] Batch 51, loss_f = 1.74785\n",
      "I0209 21:50:56.766379  6056 caffe.cpp:276] Batch 52, accuracy_c = 0.675\n",
      "I0209 21:50:56.766490  6056 caffe.cpp:276] Batch 52, accuracy_f = 0.483333\n",
      "I0209 21:50:56.766530  6056 caffe.cpp:276] Batch 52, loss_c = 1.03959\n",
      "I0209 21:50:56.766566  6056 caffe.cpp:276] Batch 52, loss_f = 1.71298\n",
      "I0209 21:50:57.328750  6056 caffe.cpp:276] Batch 53, accuracy_c = 0.55\n",
      "I0209 21:50:57.328796  6056 caffe.cpp:276] Batch 53, accuracy_f = 0.441667\n",
      "I0209 21:50:57.328807  6056 caffe.cpp:276] Batch 53, loss_c = 1.48853\n",
      "I0209 21:50:57.328822  6056 caffe.cpp:276] Batch 53, loss_f = 1.99819\n",
      "I0209 21:50:57.816726  6056 caffe.cpp:276] Batch 54, accuracy_c = 0.625\n",
      "I0209 21:50:57.816771  6056 caffe.cpp:276] Batch 54, accuracy_f = 0.483333\n",
      "I0209 21:50:57.816782  6056 caffe.cpp:276] Batch 54, loss_c = 1.29099\n",
      "I0209 21:50:57.816793  6056 caffe.cpp:276] Batch 54, loss_f = 1.9826\n",
      "I0209 21:50:58.300135  6056 caffe.cpp:276] Batch 55, accuracy_c = 0.508333\n",
      "I0209 21:50:58.300182  6056 caffe.cpp:276] Batch 55, accuracy_f = 0.45\n",
      "I0209 21:50:58.300195  6056 caffe.cpp:276] Batch 55, loss_c = 1.51319\n",
      "I0209 21:50:58.300205  6056 caffe.cpp:276] Batch 55, loss_f = 2.07088\n",
      "I0209 21:50:59.898226  6056 caffe.cpp:276] Batch 56, accuracy_c = 0.65\n",
      "I0209 21:50:59.898330  6056 caffe.cpp:276] Batch 56, accuracy_f = 0.508333\n",
      "I0209 21:50:59.898367  6056 caffe.cpp:276] Batch 56, loss_c = 1.13463\n",
      "I0209 21:50:59.898401  6056 caffe.cpp:276] Batch 56, loss_f = 1.80365\n",
      "I0209 21:51:00.433899  6056 caffe.cpp:276] Batch 57, accuracy_c = 0.566667\n",
      "I0209 21:51:00.433951  6056 caffe.cpp:276] Batch 57, accuracy_f = 0.491667\n",
      "I0209 21:51:00.433962  6056 caffe.cpp:276] Batch 57, loss_c = 1.40182\n",
      "I0209 21:51:00.433974  6056 caffe.cpp:276] Batch 57, loss_f = 2.01037\n",
      "I0209 21:51:00.923418  6056 caffe.cpp:276] Batch 58, accuracy_c = 0.6\n",
      "I0209 21:51:00.923463  6056 caffe.cpp:276] Batch 58, accuracy_f = 0.458333\n",
      "I0209 21:51:00.923475  6056 caffe.cpp:276] Batch 58, loss_c = 1.26343\n",
      "I0209 21:51:00.923485  6056 caffe.cpp:276] Batch 58, loss_f = 2.02455\n",
      "I0209 21:51:01.467782  6056 caffe.cpp:276] Batch 59, accuracy_c = 0.575\n",
      "I0209 21:51:01.467829  6056 caffe.cpp:276] Batch 59, accuracy_f = 0.5\n",
      "I0209 21:51:01.467840  6056 caffe.cpp:276] Batch 59, loss_c = 1.24002\n",
      "I0209 21:51:01.467851  6056 caffe.cpp:276] Batch 59, loss_f = 1.92878\n",
      "I0209 21:51:02.059063  6056 caffe.cpp:276] Batch 60, accuracy_c = 0.541667\n",
      "I0209 21:51:02.059110  6056 caffe.cpp:276] Batch 60, accuracy_f = 0.441667\n",
      "I0209 21:51:02.059123  6056 caffe.cpp:276] Batch 60, loss_c = 1.4456\n",
      "I0209 21:51:02.059134  6056 caffe.cpp:276] Batch 60, loss_f = 2.07136\n",
      "I0209 21:51:02.589653  6056 caffe.cpp:276] Batch 61, accuracy_c = 0.55\n",
      "I0209 21:51:02.589701  6056 caffe.cpp:276] Batch 61, accuracy_f = 0.366667\n",
      "I0209 21:51:02.589715  6056 caffe.cpp:276] Batch 61, loss_c = 1.54119\n",
      "I0209 21:51:02.589725  6056 caffe.cpp:276] Batch 61, loss_f = 2.10379\n",
      "I0209 21:51:04.302040  6056 caffe.cpp:276] Batch 62, accuracy_c = 0.625\n",
      "I0209 21:51:04.302172  6056 caffe.cpp:276] Batch 62, accuracy_f = 0.45\n",
      "I0209 21:51:04.302218  6056 caffe.cpp:276] Batch 62, loss_c = 1.23838\n",
      "I0209 21:51:04.302258  6056 caffe.cpp:276] Batch 62, loss_f = 1.98688\n",
      "I0209 21:51:05.726982  6056 caffe.cpp:276] Batch 63, accuracy_c = 0.65\n",
      "I0209 21:51:05.727035  6056 caffe.cpp:276] Batch 63, accuracy_f = 0.533333\n",
      "I0209 21:51:05.727051  6056 caffe.cpp:276] Batch 63, loss_c = 1.1023\n",
      "I0209 21:51:05.727064  6056 caffe.cpp:276] Batch 63, loss_f = 1.89552\n",
      "I0209 21:51:06.217546  6056 caffe.cpp:276] Batch 64, accuracy_c = 0.65\n",
      "I0209 21:51:06.217593  6056 caffe.cpp:276] Batch 64, accuracy_f = 0.483333\n",
      "I0209 21:51:06.217604  6056 caffe.cpp:276] Batch 64, loss_c = 1.07824\n",
      "I0209 21:51:06.217615  6056 caffe.cpp:276] Batch 64, loss_f = 1.7568\n",
      "I0209 21:51:06.697160  6056 caffe.cpp:276] Batch 65, accuracy_c = 0.508333\n",
      "I0209 21:51:06.697206  6056 caffe.cpp:276] Batch 65, accuracy_f = 0.416667\n",
      "I0209 21:51:06.697219  6056 caffe.cpp:276] Batch 65, loss_c = 1.50004\n",
      "I0209 21:51:06.697230  6056 caffe.cpp:276] Batch 65, loss_f = 2.15349\n",
      "I0209 21:51:07.206712  6056 caffe.cpp:276] Batch 66, accuracy_c = 0.591667\n",
      "I0209 21:51:07.206763  6056 caffe.cpp:276] Batch 66, accuracy_f = 0.475\n",
      "I0209 21:51:07.206776  6056 caffe.cpp:276] Batch 66, loss_c = 1.27818\n",
      "I0209 21:51:07.206789  6056 caffe.cpp:276] Batch 66, loss_f = 2.01168\n",
      "I0209 21:51:08.364171  6056 caffe.cpp:276] Batch 67, accuracy_c = 0.558333\n",
      "I0209 21:51:08.364302  6056 caffe.cpp:276] Batch 67, accuracy_f = 0.45\n",
      "I0209 21:51:08.364347  6056 caffe.cpp:276] Batch 67, loss_c = 1.29462\n",
      "I0209 21:51:08.364387  6056 caffe.cpp:276] Batch 67, loss_f = 1.93866\n",
      "I0209 21:51:09.914321  6056 caffe.cpp:276] Batch 68, accuracy_c = 0.566667\n",
      "I0209 21:51:09.914459  6056 caffe.cpp:276] Batch 68, accuracy_f = 0.475\n",
      "I0209 21:51:09.914506  6056 caffe.cpp:276] Batch 68, loss_c = 1.28034\n",
      "I0209 21:51:09.914547  6056 caffe.cpp:276] Batch 68, loss_f = 1.90065\n",
      "I0209 21:51:11.017827  6056 caffe.cpp:276] Batch 69, accuracy_c = 0.625\n",
      "I0209 21:51:11.017874  6056 caffe.cpp:276] Batch 69, accuracy_f = 0.541667\n",
      "I0209 21:51:11.017885  6056 caffe.cpp:276] Batch 69, loss_c = 1.2026\n",
      "I0209 21:51:11.017896  6056 caffe.cpp:276] Batch 69, loss_f = 1.81557\n",
      "I0209 21:51:11.819829  6056 caffe.cpp:276] Batch 70, accuracy_c = 0.591667\n",
      "I0209 21:51:11.819878  6056 caffe.cpp:276] Batch 70, accuracy_f = 0.408333\n",
      "I0209 21:51:11.819891  6056 caffe.cpp:276] Batch 70, loss_c = 1.34386\n",
      "I0209 21:51:11.819901  6056 caffe.cpp:276] Batch 70, loss_f = 2.07409\n",
      "I0209 21:51:12.472046  6056 caffe.cpp:276] Batch 71, accuracy_c = 0.566667\n",
      "I0209 21:51:12.472143  6056 caffe.cpp:276] Batch 71, accuracy_f = 0.425\n",
      "I0209 21:51:12.472159  6056 caffe.cpp:276] Batch 71, loss_c = 1.41081\n",
      "I0209 21:51:12.472170  6056 caffe.cpp:276] Batch 71, loss_f = 2.06535\n",
      "I0209 21:51:13.226531  6056 caffe.cpp:276] Batch 72, accuracy_c = 0.541667\n",
      "I0209 21:51:13.226578  6056 caffe.cpp:276] Batch 72, accuracy_f = 0.35\n",
      "I0209 21:51:13.226591  6056 caffe.cpp:276] Batch 72, loss_c = 1.57192\n",
      "I0209 21:51:13.226603  6056 caffe.cpp:276] Batch 72, loss_f = 2.34934\n",
      "I0209 21:51:13.804786  6056 caffe.cpp:276] Batch 73, accuracy_c = 0.533333\n",
      "I0209 21:51:13.804836  6056 caffe.cpp:276] Batch 73, accuracy_f = 0.383333\n",
      "I0209 21:51:13.804848  6056 caffe.cpp:276] Batch 73, loss_c = 1.56926\n",
      "I0209 21:51:13.804859  6056 caffe.cpp:276] Batch 73, loss_f = 2.43531\n",
      "I0209 21:51:15.298882  6056 caffe.cpp:276] Batch 74, accuracy_c = 0.583333\n",
      "I0209 21:51:15.299212  6056 caffe.cpp:276] Batch 74, accuracy_f = 0.458333\n",
      "I0209 21:51:15.299268  6056 caffe.cpp:276] Batch 74, loss_c = 1.29319\n",
      "I0209 21:51:15.299311  6056 caffe.cpp:276] Batch 74, loss_f = 2.11461\n",
      "I0209 21:51:16.934481  6056 caffe.cpp:276] Batch 75, accuracy_c = 0.508333\n",
      "I0209 21:51:16.934526  6056 caffe.cpp:276] Batch 75, accuracy_f = 0.416667\n",
      "I0209 21:51:16.934538  6056 caffe.cpp:276] Batch 75, loss_c = 1.43003\n",
      "I0209 21:51:16.934550  6056 caffe.cpp:276] Batch 75, loss_f = 2.08653\n",
      "I0209 21:51:17.393234  6056 caffe.cpp:276] Batch 76, accuracy_c = 0.608333\n",
      "I0209 21:51:17.393283  6056 caffe.cpp:276] Batch 76, accuracy_f = 0.541667\n",
      "I0209 21:51:17.393296  6056 caffe.cpp:276] Batch 76, loss_c = 1.17359\n",
      "I0209 21:51:17.393306  6056 caffe.cpp:276] Batch 76, loss_f = 1.87334\n",
      "I0209 21:51:17.884064  6056 caffe.cpp:276] Batch 77, accuracy_c = 0.566667\n",
      "I0209 21:51:17.884112  6056 caffe.cpp:276] Batch 77, accuracy_f = 0.425\n",
      "I0209 21:51:17.884125  6056 caffe.cpp:276] Batch 77, loss_c = 1.2982\n",
      "I0209 21:51:17.884136  6056 caffe.cpp:276] Batch 77, loss_f = 2.05621\n",
      "I0209 21:51:18.379428  6056 caffe.cpp:276] Batch 78, accuracy_c = 0.591667\n",
      "I0209 21:51:18.379477  6056 caffe.cpp:276] Batch 78, accuracy_f = 0.508333\n",
      "I0209 21:51:18.379489  6056 caffe.cpp:276] Batch 78, loss_c = 1.2869\n",
      "I0209 21:51:18.379500  6056 caffe.cpp:276] Batch 78, loss_f = 1.92742\n",
      "I0209 21:51:19.988908  6056 caffe.cpp:276] Batch 79, accuracy_c = 0.591667\n",
      "I0209 21:51:19.988996  6056 caffe.cpp:276] Batch 79, accuracy_f = 0.5\n",
      "I0209 21:51:19.989027  6056 caffe.cpp:276] Batch 79, loss_c = 1.30715\n",
      "I0209 21:51:19.989053  6056 caffe.cpp:276] Batch 79, loss_f = 1.89987\n",
      "I0209 21:51:20.506973  6056 caffe.cpp:276] Batch 80, accuracy_c = 0.625\n",
      "I0209 21:51:20.507020  6056 caffe.cpp:276] Batch 80, accuracy_f = 0.508333\n",
      "I0209 21:51:20.507032  6056 caffe.cpp:276] Batch 80, loss_c = 1.17426\n",
      "I0209 21:51:20.507043  6056 caffe.cpp:276] Batch 80, loss_f = 1.79784\n",
      "I0209 21:51:21.105623  6056 caffe.cpp:276] Batch 81, accuracy_c = 0.641667\n",
      "I0209 21:51:21.105670  6056 caffe.cpp:276] Batch 81, accuracy_f = 0.466667\n",
      "I0209 21:51:21.105684  6056 caffe.cpp:276] Batch 81, loss_c = 1.16358\n",
      "I0209 21:51:21.105695  6056 caffe.cpp:276] Batch 81, loss_f = 2.02367\n",
      "I0209 21:51:21.658231  6056 caffe.cpp:276] Batch 82, accuracy_c = 0.575\n",
      "I0209 21:51:21.658279  6056 caffe.cpp:276] Batch 82, accuracy_f = 0.416667\n",
      "I0209 21:51:21.658293  6056 caffe.cpp:276] Batch 82, loss_c = 1.35587\n",
      "I0209 21:51:21.658305  6056 caffe.cpp:276] Batch 82, loss_f = 2.04268\n",
      "I0209 21:51:22.207744  6056 caffe.cpp:276] Batch 83, accuracy_c = 0.558333\n",
      "I0209 21:51:22.207792  6056 caffe.cpp:276] Batch 83, accuracy_f = 0.5\n",
      "I0209 21:51:22.207805  6056 caffe.cpp:276] Batch 83, loss_c = 1.29628\n",
      "I0209 21:51:22.207818  6056 caffe.cpp:276] Batch 83, loss_f = 1.94546\n",
      "I0209 21:51:23.504048  6056 caffe.cpp:276] Batch 84, accuracy_c = 0.616667\n",
      "I0209 21:51:23.504179  6056 caffe.cpp:276] Batch 84, accuracy_f = 0.475\n",
      "I0209 21:51:23.504226  6056 caffe.cpp:276] Batch 84, loss_c = 1.34527\n",
      "I0209 21:51:23.504266  6056 caffe.cpp:276] Batch 84, loss_f = 1.91829\n",
      "I0209 21:51:24.739851  6056 caffe.cpp:276] Batch 85, accuracy_c = 0.625\n",
      "I0209 21:51:24.739900  6056 caffe.cpp:276] Batch 85, accuracy_f = 0.508333\n",
      "I0209 21:51:24.739914  6056 caffe.cpp:276] Batch 85, loss_c = 1.17583\n",
      "I0209 21:51:24.739925  6056 caffe.cpp:276] Batch 85, loss_f = 1.86739\n",
      "I0209 21:51:25.318712  6056 caffe.cpp:276] Batch 86, accuracy_c = 0.616667\n",
      "I0209 21:51:25.318763  6056 caffe.cpp:276] Batch 86, accuracy_f = 0.491667\n",
      "I0209 21:51:25.318775  6056 caffe.cpp:276] Batch 86, loss_c = 1.3802\n",
      "I0209 21:51:25.318788  6056 caffe.cpp:276] Batch 86, loss_f = 1.97776\n",
      "I0209 21:51:25.825978  6056 caffe.cpp:276] Batch 87, accuracy_c = 0.55\n",
      "I0209 21:51:25.826026  6056 caffe.cpp:276] Batch 87, accuracy_f = 0.483333\n",
      "I0209 21:51:25.826040  6056 caffe.cpp:276] Batch 87, loss_c = 1.31545\n",
      "I0209 21:51:25.826050  6056 caffe.cpp:276] Batch 87, loss_f = 1.89413\n",
      "I0209 21:51:26.572443  6056 caffe.cpp:276] Batch 88, accuracy_c = 0.608333\n",
      "I0209 21:51:26.572505  6056 caffe.cpp:276] Batch 88, accuracy_f = 0.466667\n",
      "I0209 21:51:26.572563  6056 caffe.cpp:276] Batch 88, loss_c = 1.18898\n",
      "I0209 21:51:26.572578  6056 caffe.cpp:276] Batch 88, loss_f = 1.93586\n",
      "I0209 21:51:27.096377  6056 caffe.cpp:276] Batch 89, accuracy_c = 0.491667\n",
      "I0209 21:51:27.096424  6056 caffe.cpp:276] Batch 89, accuracy_f = 0.45\n",
      "I0209 21:51:27.096438  6056 caffe.cpp:276] Batch 89, loss_c = 1.58335\n",
      "I0209 21:51:27.096449  6056 caffe.cpp:276] Batch 89, loss_f = 2.32136\n",
      "I0209 21:51:27.875152  6056 caffe.cpp:276] Batch 90, accuracy_c = 0.591667\n",
      "I0209 21:51:27.875280  6056 caffe.cpp:276] Batch 90, accuracy_f = 0.475\n",
      "I0209 21:51:27.875326  6056 caffe.cpp:276] Batch 90, loss_c = 1.21125\n",
      "I0209 21:51:27.875367  6056 caffe.cpp:276] Batch 90, loss_f = 1.96809\n",
      "I0209 21:51:29.255524  6056 caffe.cpp:276] Batch 91, accuracy_c = 0.6\n",
      "I0209 21:51:29.255571  6056 caffe.cpp:276] Batch 91, accuracy_f = 0.483333\n",
      "I0209 21:51:29.255584  6056 caffe.cpp:276] Batch 91, loss_c = 1.31428\n",
      "I0209 21:51:29.255595  6056 caffe.cpp:276] Batch 91, loss_f = 2.04019\n",
      "I0209 21:51:29.747339  6056 caffe.cpp:276] Batch 92, accuracy_c = 0.566667\n",
      "I0209 21:51:29.747383  6056 caffe.cpp:276] Batch 92, accuracy_f = 0.466667\n",
      "I0209 21:51:29.747395  6056 caffe.cpp:276] Batch 92, loss_c = 1.47626\n",
      "I0209 21:51:29.747406  6056 caffe.cpp:276] Batch 92, loss_f = 2.08074\n",
      "I0209 21:51:30.311664  6056 caffe.cpp:276] Batch 93, accuracy_c = 0.625\n",
      "I0209 21:51:30.311718  6056 caffe.cpp:276] Batch 93, accuracy_f = 0.5\n",
      "I0209 21:51:30.311730  6056 caffe.cpp:276] Batch 93, loss_c = 1.34933\n",
      "I0209 21:51:30.311741  6056 caffe.cpp:276] Batch 93, loss_f = 2.03268\n",
      "I0209 21:51:30.873801  6056 caffe.cpp:276] Batch 94, accuracy_c = 0.583333\n",
      "I0209 21:51:30.873847  6056 caffe.cpp:276] Batch 94, accuracy_f = 0.45\n",
      "I0209 21:51:30.873860  6056 caffe.cpp:276] Batch 94, loss_c = 1.3105\n",
      "I0209 21:51:30.873872  6056 caffe.cpp:276] Batch 94, loss_f = 2.03242\n",
      "I0209 21:51:31.397632  6056 caffe.cpp:276] Batch 95, accuracy_c = 0.541667\n",
      "I0209 21:51:31.397681  6056 caffe.cpp:276] Batch 95, accuracy_f = 0.383333\n",
      "I0209 21:51:31.397693  6056 caffe.cpp:276] Batch 95, loss_c = 1.52124\n",
      "I0209 21:51:31.397704  6056 caffe.cpp:276] Batch 95, loss_f = 2.25461\n",
      "I0209 21:51:31.970181  6056 caffe.cpp:276] Batch 96, accuracy_c = 0.583333\n",
      "I0209 21:51:31.970227  6056 caffe.cpp:276] Batch 96, accuracy_f = 0.425\n",
      "I0209 21:51:31.970239  6056 caffe.cpp:276] Batch 96, loss_c = 1.3091\n",
      "I0209 21:51:31.970250  6056 caffe.cpp:276] Batch 96, loss_f = 2.05635\n",
      "I0209 21:51:33.153580  6056 caffe.cpp:276] Batch 97, accuracy_c = 0.508333\n",
      "I0209 21:51:33.153712  6056 caffe.cpp:276] Batch 97, accuracy_f = 0.391667\n",
      "I0209 21:51:33.153759  6056 caffe.cpp:276] Batch 97, loss_c = 1.49602\n",
      "I0209 21:51:33.153798  6056 caffe.cpp:276] Batch 97, loss_f = 2.25582\n",
      "I0209 21:51:34.934065  6056 caffe.cpp:276] Batch 98, accuracy_c = 0.583333\n",
      "I0209 21:51:34.934201  6056 caffe.cpp:276] Batch 98, accuracy_f = 0.475\n",
      "I0209 21:51:34.934252  6056 caffe.cpp:276] Batch 98, loss_c = 1.3184\n",
      "I0209 21:51:34.934296  6056 caffe.cpp:276] Batch 98, loss_f = 2.08152\n",
      "I0209 21:51:36.122551  6056 caffe.cpp:276] Batch 99, accuracy_c = 0.566667\n",
      "I0209 21:51:36.122622  6056 caffe.cpp:276] Batch 99, accuracy_f = 0.466667\n",
      "I0209 21:51:36.122635  6056 caffe.cpp:276] Batch 99, loss_c = 1.35976\n",
      "I0209 21:51:36.122647  6056 caffe.cpp:276] Batch 99, loss_f = 2.04259\n",
      "I0209 21:51:36.857341  6056 caffe.cpp:276] Batch 100, accuracy_c = 0.65\n",
      "I0209 21:51:36.857388  6056 caffe.cpp:276] Batch 100, accuracy_f = 0.5\n",
      "I0209 21:51:36.857399  6056 caffe.cpp:276] Batch 100, loss_c = 1.2032\n",
      "I0209 21:51:36.857411  6056 caffe.cpp:276] Batch 100, loss_f = 1.81621\n",
      "I0209 21:51:37.500938  6056 caffe.cpp:276] Batch 101, accuracy_c = 0.566667\n",
      "I0209 21:51:37.500988  6056 caffe.cpp:276] Batch 101, accuracy_f = 0.458333\n",
      "I0209 21:51:37.500999  6056 caffe.cpp:276] Batch 101, loss_c = 1.23601\n",
      "I0209 21:51:37.501011  6056 caffe.cpp:276] Batch 101, loss_f = 2.0434\n",
      "I0209 21:51:37.980728  6056 caffe.cpp:276] Batch 102, accuracy_c = 0.55\n",
      "I0209 21:51:37.980775  6056 caffe.cpp:276] Batch 102, accuracy_f = 0.458333\n",
      "I0209 21:51:37.980787  6056 caffe.cpp:276] Batch 102, loss_c = 1.38389\n",
      "I0209 21:51:37.980829  6056 caffe.cpp:276] Batch 102, loss_f = 2.1307\n",
      "I0209 21:51:38.662528  6056 caffe.cpp:276] Batch 103, accuracy_c = 0.6\n",
      "I0209 21:51:38.662657  6056 caffe.cpp:276] Batch 103, accuracy_f = 0.483333\n",
      "I0209 21:51:38.662705  6056 caffe.cpp:276] Batch 103, loss_c = 1.29626\n",
      "I0209 21:51:38.662746  6056 caffe.cpp:276] Batch 103, loss_f = 1.98581\n",
      "I0209 21:51:40.472566  6056 caffe.cpp:276] Batch 104, accuracy_c = 0.525\n",
      "I0209 21:51:40.472694  6056 caffe.cpp:276] Batch 104, accuracy_f = 0.441667\n",
      "I0209 21:51:40.472743  6056 caffe.cpp:276] Batch 104, loss_c = 1.51151\n",
      "I0209 21:51:40.472784  6056 caffe.cpp:276] Batch 104, loss_f = 2.18927\n",
      "I0209 21:51:41.744681  6056 caffe.cpp:276] Batch 105, accuracy_c = 0.641667\n",
      "I0209 21:51:41.744729  6056 caffe.cpp:276] Batch 105, accuracy_f = 0.516667\n",
      "I0209 21:51:41.744742  6056 caffe.cpp:276] Batch 105, loss_c = 1.28531\n",
      "I0209 21:51:41.744753  6056 caffe.cpp:276] Batch 105, loss_f = 1.85721\n",
      "I0209 21:51:42.221966  6056 caffe.cpp:276] Batch 106, accuracy_c = 0.583333\n",
      "I0209 21:51:42.222014  6056 caffe.cpp:276] Batch 106, accuracy_f = 0.5\n",
      "I0209 21:51:42.222028  6056 caffe.cpp:276] Batch 106, loss_c = 1.3037\n",
      "I0209 21:51:42.222038  6056 caffe.cpp:276] Batch 106, loss_f = 1.93413\n",
      "I0209 21:51:42.711958  6056 caffe.cpp:276] Batch 107, accuracy_c = 0.516667\n",
      "I0209 21:51:42.712005  6056 caffe.cpp:276] Batch 107, accuracy_f = 0.433333\n",
      "I0209 21:51:42.712018  6056 caffe.cpp:276] Batch 107, loss_c = 1.52674\n",
      "I0209 21:51:42.712029  6056 caffe.cpp:276] Batch 107, loss_f = 2.34733\n",
      "I0209 21:51:43.214400  6056 caffe.cpp:276] Batch 108, accuracy_c = 0.6\n",
      "I0209 21:51:43.214445  6056 caffe.cpp:276] Batch 108, accuracy_f = 0.525\n",
      "I0209 21:51:43.214457  6056 caffe.cpp:276] Batch 108, loss_c = 1.26797\n",
      "I0209 21:51:43.214468  6056 caffe.cpp:276] Batch 108, loss_f = 1.94358\n",
      "I0209 21:51:43.811425  6056 caffe.cpp:276] Batch 109, accuracy_c = 0.691667\n",
      "I0209 21:51:43.811542  6056 caffe.cpp:276] Batch 109, accuracy_f = 0.6\n",
      "I0209 21:51:43.811586  6056 caffe.cpp:276] Batch 109, loss_c = 1.03498\n",
      "I0209 21:51:43.811627  6056 caffe.cpp:276] Batch 109, loss_f = 1.67721\n",
      "I0209 21:51:45.904353  6056 caffe.cpp:276] Batch 110, accuracy_c = 0.55\n",
      "I0209 21:51:45.904886  6056 caffe.cpp:276] Batch 110, accuracy_f = 0.4\n",
      "I0209 21:51:45.904953  6056 caffe.cpp:276] Batch 110, loss_c = 1.49889\n",
      "I0209 21:51:45.904995  6056 caffe.cpp:276] Batch 110, loss_f = 2.34173\n",
      "I0209 21:51:47.024848  6056 caffe.cpp:276] Batch 111, accuracy_c = 0.533333\n",
      "I0209 21:51:47.024898  6056 caffe.cpp:276] Batch 111, accuracy_f = 0.458333\n",
      "I0209 21:51:47.024911  6056 caffe.cpp:276] Batch 111, loss_c = 1.31386\n",
      "I0209 21:51:47.024922  6056 caffe.cpp:276] Batch 111, loss_f = 1.93705\n",
      "I0209 21:51:47.548310  6056 caffe.cpp:276] Batch 112, accuracy_c = 0.575\n",
      "I0209 21:51:47.548360  6056 caffe.cpp:276] Batch 112, accuracy_f = 0.475\n",
      "I0209 21:51:47.548373  6056 caffe.cpp:276] Batch 112, loss_c = 1.51489\n",
      "I0209 21:51:47.548384  6056 caffe.cpp:276] Batch 112, loss_f = 2.27097\n",
      "I0209 21:51:48.053467  6056 caffe.cpp:276] Batch 113, accuracy_c = 0.583333\n",
      "I0209 21:51:48.053516  6056 caffe.cpp:276] Batch 113, accuracy_f = 0.475\n",
      "I0209 21:51:48.053530  6056 caffe.cpp:276] Batch 113, loss_c = 1.31976\n",
      "I0209 21:51:48.053541  6056 caffe.cpp:276] Batch 113, loss_f = 2.00185\n",
      "I0209 21:51:48.514304  6056 caffe.cpp:276] Batch 114, accuracy_c = 0.575\n",
      "I0209 21:51:48.514353  6056 caffe.cpp:276] Batch 114, accuracy_f = 0.408333\n",
      "I0209 21:51:48.514366  6056 caffe.cpp:276] Batch 114, loss_c = 1.28521\n",
      "I0209 21:51:48.514377  6056 caffe.cpp:276] Batch 114, loss_f = 2.13997\n",
      "I0209 21:51:49.065521  6056 caffe.cpp:276] Batch 115, accuracy_c = 0.483333\n",
      "I0209 21:51:49.065587  6056 caffe.cpp:276] Batch 115, accuracy_f = 0.4\n",
      "I0209 21:51:49.065601  6056 caffe.cpp:276] Batch 115, loss_c = 1.54404\n",
      "I0209 21:51:49.065611  6056 caffe.cpp:276] Batch 115, loss_f = 2.23454\n",
      "I0209 21:51:49.541870  6056 caffe.cpp:276] Batch 116, accuracy_c = 0.6\n",
      "I0209 21:51:49.541918  6056 caffe.cpp:276] Batch 116, accuracy_f = 0.491667\n",
      "I0209 21:51:49.541930  6056 caffe.cpp:276] Batch 116, loss_c = 1.38414\n",
      "I0209 21:51:49.541941  6056 caffe.cpp:276] Batch 116, loss_f = 2.02665\n",
      "I0209 21:51:50.548003  6056 caffe.cpp:276] Batch 117, accuracy_c = 0.516667\n",
      "I0209 21:51:50.548141  6056 caffe.cpp:276] Batch 117, accuracy_f = 0.441667\n",
      "I0209 21:51:50.548187  6056 caffe.cpp:276] Batch 117, loss_c = 1.43551\n",
      "I0209 21:51:50.548228  6056 caffe.cpp:276] Batch 117, loss_f = 2.14327\n",
      "I0209 21:51:52.005429  6056 caffe.cpp:276] Batch 118, accuracy_c = 0.508333\n",
      "I0209 21:51:52.005482  6056 caffe.cpp:276] Batch 118, accuracy_f = 0.475\n",
      "I0209 21:51:52.005497  6056 caffe.cpp:276] Batch 118, loss_c = 1.57973\n",
      "I0209 21:51:52.005511  6056 caffe.cpp:276] Batch 118, loss_f = 2.33789\n",
      "I0209 21:51:52.502737  6056 caffe.cpp:276] Batch 119, accuracy_c = 0.666667\n",
      "I0209 21:51:52.502787  6056 caffe.cpp:276] Batch 119, accuracy_f = 0.475\n",
      "I0209 21:51:52.502801  6056 caffe.cpp:276] Batch 119, loss_c = 1.10304\n",
      "I0209 21:51:52.502812  6056 caffe.cpp:276] Batch 119, loss_f = 1.82247\n",
      "I0209 21:51:53.112720  6056 caffe.cpp:276] Batch 120, accuracy_c = 0.6\n",
      "I0209 21:51:53.112766  6056 caffe.cpp:276] Batch 120, accuracy_f = 0.533333\n",
      "I0209 21:51:53.112779  6056 caffe.cpp:276] Batch 120, loss_c = 1.28572\n",
      "I0209 21:51:53.112792  6056 caffe.cpp:276] Batch 120, loss_f = 1.86844\n",
      "I0209 21:51:53.601454  6056 caffe.cpp:276] Batch 121, accuracy_c = 0.625\n",
      "I0209 21:51:53.601505  6056 caffe.cpp:276] Batch 121, accuracy_f = 0.475\n",
      "I0209 21:51:53.601518  6056 caffe.cpp:276] Batch 121, loss_c = 1.18893\n",
      "I0209 21:51:53.601531  6056 caffe.cpp:276] Batch 121, loss_f = 1.84244\n",
      "I0209 21:51:54.059787  6056 caffe.cpp:276] Batch 122, accuracy_c = 0.641667\n",
      "I0209 21:51:54.059835  6056 caffe.cpp:276] Batch 122, accuracy_f = 0.491667\n",
      "I0209 21:51:54.059850  6056 caffe.cpp:276] Batch 122, loss_c = 1.21976\n",
      "I0209 21:51:54.059862  6056 caffe.cpp:276] Batch 122, loss_f = 1.9922\n",
      "I0209 21:51:54.775974  6056 caffe.cpp:276] Batch 123, accuracy_c = 0.641667\n",
      "I0209 21:51:54.776108  6056 caffe.cpp:276] Batch 123, accuracy_f = 0.466667\n",
      "I0209 21:51:54.776161  6056 caffe.cpp:276] Batch 123, loss_c = 1.20546\n",
      "I0209 21:51:54.776207  6056 caffe.cpp:276] Batch 123, loss_f = 1.89668\n",
      "I0209 21:51:56.177244  6056 caffe.cpp:276] Batch 124, accuracy_c = 0.666667\n",
      "I0209 21:51:56.177299  6056 caffe.cpp:276] Batch 124, accuracy_f = 0.483333\n",
      "I0209 21:51:56.179561  6056 caffe.cpp:276] Batch 124, loss_c = 1.14073\n",
      "I0209 21:51:56.179580  6056 caffe.cpp:276] Batch 124, loss_f = 1.92724\n",
      "I0209 21:51:56.654567  6056 caffe.cpp:276] Batch 125, accuracy_c = 0.641667\n",
      "I0209 21:51:56.654614  6056 caffe.cpp:276] Batch 125, accuracy_f = 0.5\n",
      "I0209 21:51:56.654626  6056 caffe.cpp:276] Batch 125, loss_c = 1.13129\n",
      "I0209 21:51:56.654638  6056 caffe.cpp:276] Batch 125, loss_f = 1.84166\n",
      "I0209 21:51:57.147133  6056 caffe.cpp:276] Batch 126, accuracy_c = 0.575\n",
      "I0209 21:51:57.147179  6056 caffe.cpp:276] Batch 126, accuracy_f = 0.433333\n",
      "I0209 21:51:57.147192  6056 caffe.cpp:276] Batch 126, loss_c = 1.41583\n",
      "I0209 21:51:57.147202  6056 caffe.cpp:276] Batch 126, loss_f = 2.08744\n",
      "I0209 21:51:57.866493  6056 caffe.cpp:276] Batch 127, accuracy_c = 0.583333\n",
      "I0209 21:51:57.866623  6056 caffe.cpp:276] Batch 127, accuracy_f = 0.491667\n",
      "I0209 21:51:57.866668  6056 caffe.cpp:276] Batch 127, loss_c = 1.22094\n",
      "I0209 21:51:57.866709  6056 caffe.cpp:276] Batch 127, loss_f = 1.8393\n",
      "I0209 21:51:59.402984  6056 caffe.cpp:276] Batch 128, accuracy_c = 0.591667\n",
      "I0209 21:51:59.403120  6056 caffe.cpp:276] Batch 128, accuracy_f = 0.466667\n",
      "I0209 21:51:59.403164  6056 caffe.cpp:276] Batch 128, loss_c = 1.41109\n",
      "I0209 21:51:59.403206  6056 caffe.cpp:276] Batch 128, loss_f = 2.1273\n",
      "I0209 21:52:00.067623  6056 caffe.cpp:276] Batch 129, accuracy_c = 0.6\n",
      "I0209 21:52:00.067672  6056 caffe.cpp:276] Batch 129, accuracy_f = 0.55\n",
      "I0209 21:52:00.067684  6056 caffe.cpp:276] Batch 129, loss_c = 1.10254\n",
      "I0209 21:52:00.067694  6056 caffe.cpp:276] Batch 129, loss_f = 1.6848\n",
      "I0209 21:52:00.580080  6056 caffe.cpp:276] Batch 130, accuracy_c = 0.575\n",
      "I0209 21:52:00.580127  6056 caffe.cpp:276] Batch 130, accuracy_f = 0.441667\n",
      "I0209 21:52:00.580139  6056 caffe.cpp:276] Batch 130, loss_c = 1.34401\n",
      "I0209 21:52:00.580150  6056 caffe.cpp:276] Batch 130, loss_f = 1.96803\n",
      "I0209 21:52:01.089668  6056 caffe.cpp:276] Batch 131, accuracy_c = 0.558333\n",
      "I0209 21:52:01.089716  6056 caffe.cpp:276] Batch 131, accuracy_f = 0.483333\n",
      "I0209 21:52:01.089728  6056 caffe.cpp:276] Batch 131, loss_c = 1.23258\n",
      "I0209 21:52:01.089740  6056 caffe.cpp:276] Batch 131, loss_f = 2.04374\n",
      "I0209 21:52:01.625224  6056 caffe.cpp:276] Batch 132, accuracy_c = 0.625\n",
      "I0209 21:52:01.625265  6056 caffe.cpp:276] Batch 132, accuracy_f = 0.566667\n",
      "I0209 21:52:01.625277  6056 caffe.cpp:276] Batch 132, loss_c = 1.19137\n",
      "I0209 21:52:01.625288  6056 caffe.cpp:276] Batch 132, loss_f = 1.60863\n",
      "^C\n",
      "CPU times: user 708 ms, sys: 84 ms, total: 792 ms\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!$CAFFE_ROOT/build/tools/caffe test -model cnn_test.prototxt -weights cnn_snapshot_iter_150000.caffemodel -iterations 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The model achieved near 58% accuracy on the 20 coarse labels and 47% accuracy on fine labels.\n",
    "This means that upon showing the neural network a picture it had never seen, it will correctly classify it in one of the 20 coarse categories 58% of the time or it will classify it correctly in the fine categories 47% of the time right, and ignoring the coarse label. This is amazing, but the neural network for sure could be fine tuned with better solver parameters. \n",
    "\n",
    "It would  be also possible to have two more loss layers on top of the existing loss, to recombine the predictions made and synchronize with the fact that coarse and fine labels influence on each other and are related.\n",
    "\n",
    "This neural network training could be compared to the results listed here: http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#494c5356524332303132207461736b2031\n",
    "\n",
    "Let's convert the notebook to github markdown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook custom-cifar-100.ipynb to markdown\n",
      "[NbConvertApp] Writing 1036426 bytes to custom-cifar-100.md\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to markdown custom-cifar-100.ipynb \n",
    "!mv custom-cifar-100.md README.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
